From e148e8223a517f5ec08ed572fcf601510ffcec67 Mon Sep 17 00:00:00 2001
From: Prasad Mujumdar <prasadm@cloudera.com>
Date: Tue, 30 Apr 2013 02:22:55 -0700
Subject: [PATCH 102/121]  CDH-11882: Capture parser read entities for the describe table operation

---
 .../java/org/apache/hadoop/hive/conf/HiveConf.java |    2 +-
 .../hadoop/hive/ql/parse/DDLSemanticAnalyzer.java  |   15 ++++++++++++++-
 .../hive/ql/parse/ImportSemanticAnalyzer.java      |    2 +-
 .../hadoop/hive/ql/parse/LoadSemanticAnalyzer.java |    2 +-
 .../hadoop/hive/ql/parse/SemanticAnalyzer.java     |    2 +-
 5 files changed, 18 insertions(+), 5 deletions(-)

diff --git a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index 8f0fb58..1585555 100644
--- a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -677,7 +677,7 @@ public class HiveConf extends Configuration {
     HIVE_DRIVER_RUN_HOOKS("hive.exec.driver.run.hooks", ""),
     HIVE_DDL_OUTPUT_FORMAT("hive.ddl.output.format", null),
     HIVE_ENTITY_SEPARATOR("hive.entity.separator", "@"),
-    HIVE_ENITITY_CAPTURE_INPUT_URI("hive.entity.capture.input.URI", false),
+    HIVE_EXTENDED_ENITITY_CAPTURE("hive.entity.capture.input.URI", false),
 
     HIVE_SERVER2_THRIFT_MIN_WORKER_THREADS("hive.server2.thrift.min.worker.threads", 5),
     HIVE_SERVER2_THRIFT_MAX_WORKER_THREADS("hive.server2.thrift.max.worker.threads", 100),
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
index fab1bd2..4041194 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
@@ -1693,6 +1693,19 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
       descTblDesc.setFormatted(descOptions == HiveParser.KW_FORMATTED);
       descTblDesc.setExt(descOptions == HiveParser.KW_EXTENDED);
     }
+
+    // store the read entity for the table being described
+    if (conf.getBoolVar(ConfVars.HIVE_EXTENDED_ENITITY_CAPTURE)) {
+      Table table;
+      // table name could be db.tab format
+      if (tableName.contains(".")) {
+        String[] tokens = tableName.split("\\.");
+        table = new Table (tokens[0], tokens[1]);
+      } else {
+        table = new Table (db.getCurrentDatabase(), tableName);
+      }
+    inputs.add(new ReadEntity(table));
+    }
     rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(),
         descTblDesc), conf));
     setFetchTask(createFetchTask(DescTableDesc.getSchema()));
@@ -2971,7 +2984,7 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
   }
 
   private void saveInputLocationEntity(String location) {
-    if (conf.getBoolVar(ConfVars.HIVE_ENITITY_CAPTURE_INPUT_URI) &&
+    if (conf.getBoolVar(ConfVars.HIVE_EXTENDED_ENITITY_CAPTURE) &&
         (location != null)) {
       inputs.add(new ReadEntity(location));
     }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java
index 461844b..8948d22 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java
@@ -267,7 +267,7 @@ public class ImportSemanticAnalyzer extends BaseSemanticAnalyzer {
           }
         }
         rootTasks.add(t);
-        if (conf.getBoolVar(ConfVars.HIVE_ENITITY_CAPTURE_INPUT_URI)) {
+        if (conf.getBoolVar(ConfVars.HIVE_EXTENDED_ENITITY_CAPTURE)) {
           inputs.add(new ReadEntity(fromURI.toString(), "hdfs".equals(fromURI.getScheme())));
         }
       }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
index 4582e6d..9400acb 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java
@@ -191,7 +191,7 @@ public class LoadSemanticAnalyzer extends BaseSemanticAnalyzer {
       throw new SemanticException(ErrorMsg.INVALID_PATH.getMsg(fromTree, e
           .getMessage()), e);
     }
-    if (conf.getBoolVar(ConfVars.HIVE_ENITITY_CAPTURE_INPUT_URI)) {
+    if (conf.getBoolVar(ConfVars.HIVE_EXTENDED_ENITITY_CAPTURE)) {
       inputs.add(new ReadEntity(fromURI.toString(), isLocal));
     }
 
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
index 4d0bed3..87aa9b0 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java
@@ -8764,7 +8764,7 @@ public class SemanticAnalyzer extends BaseSemanticAnalyzer {
       }
     }
 
-    if (conf.getBoolVar(ConfVars.HIVE_ENITITY_CAPTURE_INPUT_URI) &&
+    if (conf.getBoolVar(ConfVars.HIVE_EXTENDED_ENITITY_CAPTURE) &&
           (location != null)) {
       inputs.add(new ReadEntity(location));
     }
-- 
1.7.0.4

