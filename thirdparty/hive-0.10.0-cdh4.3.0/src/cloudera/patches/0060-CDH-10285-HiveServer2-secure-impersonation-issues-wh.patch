From 179520efdcdf56b97167da5bff4ac773461505b2 Mon Sep 17 00:00:00 2001
From: Prasad Mujumdar <prasadm@cloudera.com>
Date: Mon, 4 Feb 2013 12:14:32 -0800
Subject: [PATCH 060/121] CDH-10285: HiveServer2 secure impersonation issues when used with secure remote metastore

---
 .../org/apache/hadoop/hive/ql/metadata/Hive.java   |   24 ++
 .../hive/service/auth/KerberosSaslHelper.java      |    4 +-
 .../apache/hive/service/auth/PlainSaslHelper.java  |    5 +-
 .../org/apache/hive/service/cli/CLIService.java    |   47 +++-
 .../hive/service/cli/EmbeddedCLIServiceClient.java |    6 +
 .../org/apache/hive/service/cli/ICLIService.java   |    4 +
 .../cli/operation/AddResourceOperation.java        |    4 +-
 .../cli/operation/DeleteResourceOperation.java     |    4 +-
 .../hive/service/cli/operation/DfsOperation.java   |    4 +-
 .../cli/operation/ExecuteStatementOperation.java   |    6 +-
 .../cli/operation/GetCatalogsOperation.java        |    4 +-
 .../service/cli/operation/GetColumnsOperation.java |    4 +-
 .../cli/operation/GetFunctionsOperation.java       |    4 +-
 .../service/cli/operation/GetSchemasOperation.java |    4 +-
 .../cli/operation/GetTableTypesOperation.java      |    4 +-
 .../service/cli/operation/GetTablesOperation.java  |    4 +-
 .../cli/operation/GetTypeInfoOperation.java        |    4 +-
 .../cli/operation/HiveCommandOperation.java        |    4 +-
 .../service/cli/operation/MetadataOperation.java   |    4 +-
 .../hive/service/cli/operation/Operation.java      |    8 +-
 .../service/cli/operation/OperationManager.java    |   18 +-
 .../hive/service/cli/operation/SQLOperation.java   |    4 +-
 .../hive/service/cli/operation/SetOperation.java   |    4 +-
 .../hive/service/cli/session/HiveSession.java      |  352 +++++++-------------
 .../hive/service/cli/session/HiveSessionImpl.java  |  295 ++++++++++++++++
 .../cli/session/HiveSessionImplwithUGI.java        |  137 ++++++++
 .../hive/service/cli/session/HiveSessionProxy.java |   87 +++++
 .../hive/service/cli/session/SessionManager.java   |   17 +-
 .../hive/service/cli/thrift/ThriftCLIService.java  |   19 +-
 .../service/cli/thrift/ThriftCLIServiceClient.java |    9 +
 .../hadoop/hive/shims/HadoopShimsSecure.java       |   20 ++
 .../hive/thrift/HadoopThriftAuthBridge20S.java     |    1 +
 .../org/apache/hadoop/hive/shims/HadoopShims.java  |   24 ++
 33 files changed, 841 insertions(+), 298 deletions(-)
 create mode 100644 service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
 create mode 100644 service/src/java/org/apache/hive/service/cli/session/HiveSessionImplwithUGI.java
 create mode 100644 service/src/java/org/apache/hive/service/cli/session/HiveSessionProxy.java

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index d44621f..3e7b30b 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -177,6 +177,10 @@ public class Hive {
     return db;
   }
 
+  public static void set(Hive hive) {
+    hiveDB.set(hive);
+  }
+
   public static void closeCurrent() {
     hiveDB.remove();
   }
@@ -2265,6 +2269,26 @@ public class Hive {
     }
   }
 
+  public String getDelegationToken(String owner, String renewer)
+    throws HiveException{
+    try {
+      return getMSC().getDelegationToken(owner, renewer);
+    } catch(Exception e) {
+      LOG.error(StringUtils.stringifyException(e));
+      throw new HiveException(e);
+    }
+  }
+
+  public void cancelDelegationToken(String tokenStrForm)
+    throws HiveException {
+    try {
+      getMSC().cancelDelegationToken(tokenStrForm);
+    }  catch(Exception e) {
+      LOG.error(StringUtils.stringifyException(e));
+      throw new HiveException(e);
+    }
+  }
+
   private static String[] getQualifiedNames(String qualifiedName) {
     return qualifiedName.split("\\.");
   }
diff --git a/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java b/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java
index b8796fe..379dafb 100644
--- a/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java
+++ b/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 
 import javax.security.sasl.SaslException;
 
-import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.shims.ShimLoader;
 import org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge;
 import org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge.Server;
@@ -47,8 +46,7 @@ public class KerberosSaslHelper {
     @Override
     public TProcessor getProcessor(TTransport trans) {
       TProcessor sqlProcessor = new TCLIService.Processor<Iface>(service);
-      return service.getHiveConf().getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_KERBEROS_IMPERSONATION) ?
-          saslServer.wrapProcessor(sqlProcessor) : saslServer.wrapNonAssumingProcessor(sqlProcessor);
+      return saslServer.wrapNonAssumingProcessor(sqlProcessor);
     }
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java b/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java
index 8f2d6bb..0f0f2e9 100644
--- a/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java
+++ b/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java
@@ -97,21 +97,18 @@ public class PlainSaslHelper {
   private static class SQLPlainProcessorFactory extends TProcessorFactory {
     private final ThriftCLIService service;
     private final HiveConf conf;
-    private final boolean doAsEnabled;
 
     public SQLPlainProcessorFactory(ThriftCLIService service) {
       super(null);
       this.service = service;
       this.conf = service.getHiveConf();
-      this.doAsEnabled = conf.getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_KERBEROS_IMPERSONATION);
     }
 
     // Note that we do not do this in KerberosSaslHelper because we get the ipaddress differently in case of Sasl.
     @Override
     public TProcessor getProcessor(TTransport trans) {
       // Note that we do not wrap the processor for kerberos. And handle it a bit differently.
-      TProcessor baseProcessor = new TSetIpAddressProcessor<Iface>(service);
-      return doAsEnabled ? new TUGIContainingProcessor(baseProcessor, conf) : baseProcessor;
+      return new TSetIpAddressProcessor<Iface>(service);
     }
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/CLIService.java b/src/service/src/java/org/apache/hive/service/cli/CLIService.java
index 8a2230d..05f2b27 100644
--- a/src/service/src/java/org/apache/hive/service/cli/CLIService.java
+++ b/src/service/src/java/org/apache/hive/service/cli/CLIService.java
@@ -22,11 +22,16 @@ import java.io.IOException;
 import java.util.List;
 import java.util.Map;
 
+import javax.security.auth.login.LoginException;
+
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;
 import org.apache.hadoop.hive.metastore.IMetaStoreClient;
+import org.apache.hadoop.hive.ql.metadata.Hive;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.shims.ShimLoader;
 import org.apache.hive.service.CompositeService;
 import org.apache.hive.service.ServiceException;
 import org.apache.hive.service.auth.HiveAuthFactory;
@@ -44,6 +49,7 @@ public class CLIService extends CompositeService implements ICLIService {
   private HiveConf hiveConf;
   private SessionManager sessionManager;
   private IMetaStoreClient metastoreClient;
+  private String serverUserName = null;
 
 
   public CLIService() {
@@ -58,8 +64,12 @@ public class CLIService extends CompositeService implements ICLIService {
     addService(sessionManager);
     try {
       HiveAuthFactory.loginFromKeytab(hiveConf);
+      serverUserName = ShimLoader.getHadoopShims().
+          getShortUserName(ShimLoader.getHadoopShims().getUGIForConf(hiveConf));
     } catch (IOException e) {
       throw new ServiceException("Unable to login to kerberos with given principal/keytab", e);
+    } catch (LoginException e) {
+      throw new ServiceException("Unable to login to kerberos with given principal/keytab", e);
     }
     super.init(hiveConf);
   }
@@ -92,7 +102,20 @@ public class CLIService extends CompositeService implements ICLIService {
   @Override
   public SessionHandle openSession(String username, String password, Map<String, String> configuration)
       throws HiveSQLException {
-    SessionHandle sessionHandle = sessionManager.openSession(username, password, configuration);
+    SessionHandle sessionHandle = sessionManager.openSession(username, password, configuration, false, null);
+    LOG.info(sessionHandle + ": openSession()");
+    sessionManager.clearThreadLocals();
+    return sessionHandle;
+  }
+
+  /* (non-Javadoc)
+   * @see org.apache.hive.service.cli.ICLIService#openSession(java.lang.String, java.lang.String, java.util.Map)
+   */
+  @Override
+  public SessionHandle openSessionWithImpersonation(String username, String password, Map<String, String> configuration,
+       String delegationToken) throws HiveSQLException {
+    SessionHandle sessionHandle = sessionManager.openSession(username, password, configuration,
+          true, delegationToken);
     LOG.info(sessionHandle + ": openSession()");
     sessionManager.clearThreadLocals();
     return sessionHandle;
@@ -312,8 +335,30 @@ public class CLIService extends CompositeService implements ICLIService {
     try {
       HiveSession session = sessionManager.getSession(sessionHandle);
       session.setUserName(userName);
+      sessionManager.setUserName(userName);
     } catch (HiveSQLException e) {
       LOG.error("Unable to set userName in sessions", e);
     }
   }
+
+  // obtain delegation token for the give user from metastore
+  public synchronized String getDelegationTokenFromMetaStore(String owner)
+      throws HiveSQLException, UnsupportedOperationException, LoginException, IOException {
+    if (!hiveConf.getBoolVar(HiveConf.ConfVars.METASTORE_USE_THRIFT_SASL) ||
+        !hiveConf.getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_KERBEROS_IMPERSONATION)) {
+      throw new UnsupportedOperationException(
+        "delegation token is can only be obtained for a secure remote metastore");
+    }
+
+    try {
+      Hive.closeCurrent();
+      return Hive.get(hiveConf).getDelegationToken(owner, owner);
+    } catch (HiveException e) {
+      if (e.getCause() instanceof UnsupportedOperationException) {
+        throw (UnsupportedOperationException)e.getCause();
+      } else {
+        throw new HiveSQLException("Error connect metastore to setup impersonation", e);
+      }
+    }
+  }
 }
diff --git a/src/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java b/src/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
index 34a0a85..38d64c8 100644
--- a/src/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
+++ b/src/service/src/java/org/apache/hive/service/cli/EmbeddedCLIServiceClient.java
@@ -42,6 +42,12 @@ public class EmbeddedCLIServiceClient extends CLIServiceClient {
     return cliService.openSession(username, password, configuration);
   }
 
+  @Override
+  public SessionHandle openSessionWithImpersonation(String username, String password,
+      Map<String, String> configuration, String delegationToken) throws HiveSQLException {
+    throw new HiveSQLException("Impersonated session is not supported in the embedded mode");
+  }
+
   /* (non-Javadoc)
    * @see org.apache.hive.service.cli.CLIServiceClient#closeSession(org.apache.hive.service.cli.SessionHandle)
    */
diff --git a/src/service/src/java/org/apache/hive/service/cli/ICLIService.java b/src/service/src/java/org/apache/hive/service/cli/ICLIService.java
index b2f5416..7e863b5 100644
--- a/src/service/src/java/org/apache/hive/service/cli/ICLIService.java
+++ b/src/service/src/java/org/apache/hive/service/cli/ICLIService.java
@@ -29,6 +29,10 @@ public interface ICLIService {
       Map<String, String> configuration)
       throws HiveSQLException;
 
+  public abstract SessionHandle openSessionWithImpersonation(String username, String password,
+      Map<String, String> configuration, String delegationToken)
+      throws HiveSQLException;
+
   public abstract void closeSession(SessionHandle sessionHandle)
       throws HiveSQLException;
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/AddResourceOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/AddResourceOperation.java
index fe0c6db..3bf0ac5 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/AddResourceOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/AddResourceOperation.java
@@ -21,7 +21,7 @@ package org.apache.hive.service.cli.operation;
 import java.util.Map;
 
 import org.apache.hadoop.hive.ql.processors.AddResourceProcessor;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * HiveAddResourceOperation.
@@ -29,7 +29,7 @@ import org.apache.hive.service.cli.session.HiveSession;
  */
 public class AddResourceOperation extends HiveCommandOperation {
 
-  protected AddResourceOperation(HiveSession parentSession, String statement,
+  protected AddResourceOperation(HiveSessionImpl parentSession, String statement,
       Map<String, String> confOverlay) {
     super(parentSession, statement, confOverlay);
     setCommandProcessor(new AddResourceProcessor());
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/DeleteResourceOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/DeleteResourceOperation.java
index 496bba9..d992f5f 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/DeleteResourceOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/DeleteResourceOperation.java
@@ -21,7 +21,7 @@ package org.apache.hive.service.cli.operation;
 import java.util.Map;
 
 import org.apache.hadoop.hive.ql.processors.DeleteResourceProcessor;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * HiveDeleteResourceOperation.
@@ -29,7 +29,7 @@ import org.apache.hive.service.cli.session.HiveSession;
  */
 public class DeleteResourceOperation extends HiveCommandOperation {
 
-  protected DeleteResourceOperation(HiveSession parentSession, String statement,
+  protected DeleteResourceOperation(HiveSessionImpl parentSession, String statement,
       Map<String, String> confOverlay) {
     super(parentSession, statement, confOverlay);
     setCommandProcessor(new DeleteResourceProcessor());
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/DfsOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/DfsOperation.java
index a8b8ed4..d0c9a1f 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/DfsOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/DfsOperation.java
@@ -21,7 +21,7 @@ package org.apache.hive.service.cli.operation;
 import java.util.Map;
 
 import org.apache.hadoop.hive.ql.processors.DfsProcessor;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * HiveDfsCommandOperation.
@@ -29,7 +29,7 @@ import org.apache.hive.service.cli.session.HiveSession;
  */
 public class DfsOperation extends HiveCommandOperation {
 
-  protected DfsOperation(HiveSession parentSession, String statement,
+  protected DfsOperation(HiveSessionImpl parentSession, String statement,
       Map<String, String> confOverlay) {
     super(parentSession, statement, confOverlay);
     setCommandProcessor(new DfsProcessor(parentSession.getHiveConf()));
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java
index 9a1da59..463d3b6 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java
@@ -23,13 +23,13 @@ import java.util.HashMap;
 import java.util.Map;
 
 import org.apache.hive.service.cli.OperationType;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 public abstract class ExecuteStatementOperation extends Operation {
   protected String statement = null;
   protected Map<String, String> confOverlay = new HashMap<String, String>();
 
-  public ExecuteStatementOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay) {
+  public ExecuteStatementOperation(HiveSessionImpl parentSession, String statement, Map<String, String> confOverlay) {
     super(parentSession, OperationType.EXECUTE_STATEMENT);
     this.statement = statement;
     this.confOverlay = confOverlay;
@@ -40,7 +40,7 @@ public abstract class ExecuteStatementOperation extends Operation {
   }
 
   public static ExecuteStatementOperation newExecuteStatementOperation(
-      HiveSession parentSession, String statement, Map<String, String> confOverlay) {
+      HiveSessionImpl parentSession, String statement, Map<String, String> confOverlay) {
     String[] tokens = statement.trim().split("\\s+");
     String command = tokens[0].toLowerCase();
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetCatalogsOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetCatalogsOperation.java
index 581e69c..5d477e7 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetCatalogsOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetCatalogsOperation.java
@@ -24,7 +24,7 @@ import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetCatalogsOperation.
@@ -36,7 +36,7 @@ public class GetCatalogsOperation extends MetadataOperation {
 
   private final RowSet rowSet = new RowSet();
 
-  protected GetCatalogsOperation(HiveSession parentSession) {
+  protected GetCatalogsOperation(HiveSessionImpl parentSession) {
     super(parentSession, OperationType.GET_CATALOGS);
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetColumnsOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetColumnsOperation.java
index af87a90..497477f 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetColumnsOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetColumnsOperation.java
@@ -33,7 +33,7 @@ import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
 import org.apache.hive.service.cli.Type;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetColumnsOperation.
@@ -103,7 +103,7 @@ public class GetColumnsOperation extends MetadataOperation {
 
   private final RowSet rowSet = new RowSet();
 
-  protected GetColumnsOperation(HiveSession parentSession, String catalogName, String schemaName,
+  protected GetColumnsOperation(HiveSessionImpl parentSession, String catalogName, String schemaName,
       String tableName, String columnName) {
     super(parentSession, OperationType.GET_COLUMNS);
     this.catalogName = catalogName;
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetFunctionsOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetFunctionsOperation.java
index 4d0f295..50dd146 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetFunctionsOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetFunctionsOperation.java
@@ -31,7 +31,7 @@ import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.CLIServiceUtils;
 import org.apache.hive.service.cli.TableSchema;
 import org.apache.hive.service.cli.Type;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetFunctionsOperation.
@@ -58,7 +58,7 @@ public class GetFunctionsOperation extends MetadataOperation {
 
   private final RowSet rowSet = new RowSet();
 
-  public GetFunctionsOperation(HiveSession parentSession,
+  public GetFunctionsOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName, String functionName) {
     super(parentSession, OperationType.GET_FUNCTIONS);
     this.catalogName = catalogName;
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetSchemasOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetSchemasOperation.java
index 6970f35..7db45d4 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetSchemasOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetSchemasOperation.java
@@ -25,7 +25,7 @@ import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetSchemasOperation.
@@ -41,7 +41,7 @@ public class GetSchemasOperation extends MetadataOperation {
 
   private RowSet rowSet;
 
-  protected GetSchemasOperation(HiveSession parentSession,
+  protected GetSchemasOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName) {
     super(parentSession, OperationType.GET_SCHEMAS);
     this.catalogName = catalogName;
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetTableTypesOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetTableTypesOperation.java
index eaf867e..9ff66dc 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetTableTypesOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetTableTypesOperation.java
@@ -25,7 +25,7 @@ import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetTableTypesOperation.
@@ -38,7 +38,7 @@ public class GetTableTypesOperation extends MetadataOperation {
 
   private RowSet rowSet;
 
-  protected GetTableTypesOperation(HiveSession parentSession) {
+  protected GetTableTypesOperation(HiveSessionImpl parentSession) {
     super(parentSession, OperationType.GET_TABLE_TYPES);
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java
index df8b5b3..59ecabd 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java
@@ -29,7 +29,7 @@ import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetTablesOperation.
@@ -51,7 +51,7 @@ public class GetTablesOperation extends MetadataOperation {
   .addStringColumn("TABLE_TYPE", "The table type, e.g. \"TABLE\", \"VIEW\", etc.")
   .addStringColumn("REMARKS", "Comments about the table.");
 
-  protected GetTablesOperation(HiveSession parentSession,
+  protected GetTablesOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName, String tableName,
       List<String> tableTypes) {
     super(parentSession, OperationType.GET_TABLES);
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/GetTypeInfoOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/GetTypeInfoOperation.java
index 2daa9cd..45e11bd 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/GetTypeInfoOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/GetTypeInfoOperation.java
@@ -25,7 +25,7 @@ import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
 import org.apache.hive.service.cli.Type;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * GetTypeInfoOperation.
@@ -73,7 +73,7 @@ public class GetTypeInfoOperation extends MetadataOperation {
 
   private final RowSet rowSet = new RowSet();
 
-  protected GetTypeInfoOperation(HiveSession parentSession) {
+  protected GetTypeInfoOperation(HiveSessionImpl parentSession) {
     super(parentSession, OperationType.GET_TYPE_INFO);
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java
index 60148cb..bc5c3d3 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/HiveCommandOperation.java
@@ -39,7 +39,7 @@ import org.apache.hive.service.cli.HiveSQLException;
 import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * HiveCommandOperation.
@@ -57,7 +57,7 @@ public abstract class HiveCommandOperation extends ExecuteStatementOperation {
   private BufferedReader resultReader;
 
 
-  protected HiveCommandOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay) {
+  protected HiveCommandOperation(HiveSessionImpl parentSession, String statement, Map<String, String> confOverlay) {
     super(parentSession, statement, confOverlay);
     setupSessionIO(parentSession.getSessionState());
   }
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java
index 8dc82ab..e685758 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java
@@ -22,7 +22,7 @@ import org.apache.hive.service.cli.HiveSQLException;
 import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * MetadataOperation.
@@ -34,7 +34,7 @@ public abstract class MetadataOperation extends Operation {
   protected static TableSchema RESULT_SET_SCHEMA;
   private static final char SEARCH_STRING_ESCAPE = '\\';
 
-  protected MetadataOperation(HiveSession parentSession, OperationType opType) {
+  protected MetadataOperation(HiveSessionImpl parentSession, OperationType opType) {
     super(parentSession, opType);
     setHasResultSet(true);
   }
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/Operation.java b/src/service/src/java/org/apache/hive/service/cli/operation/Operation.java
index b354ac9..c8df560 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/Operation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/Operation.java
@@ -27,12 +27,12 @@ import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.OperationType;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 
 
 public abstract class Operation {
-  private final HiveSession parentSession;
+  private final HiveSessionImpl parentSession;
   private OperationState state = OperationState.INITIALIZED;
   private final OperationHandle opHandle;
   private HiveConf configuration;
@@ -40,7 +40,7 @@ public abstract class Operation {
   public static final long DEFAULT_FETCH_MAX_ROWS = 100;
   protected boolean hasResultSet;
 
-  protected Operation(HiveSession parentSession, OperationType opType) {
+  protected Operation(HiveSessionImpl parentSession, OperationType opType) {
     super();
     this.parentSession = parentSession;
     opHandle = new OperationHandle(opType);
@@ -54,7 +54,7 @@ public abstract class Operation {
     return new HiveConf(configuration);
   }
 
-  public HiveSession getParentSession() {
+  public HiveSessionImpl getParentSession() {
     return parentSession;
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java b/src/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
index 9c6bef0..d96a421 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/OperationManager.java
@@ -30,7 +30,7 @@ import org.apache.hive.service.cli.OperationHandle;
 import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * OperationManager.
@@ -65,7 +65,7 @@ public class OperationManager extends AbstractService {
     super.stop();
   }
 
-  public ExecuteStatementOperation newExecuteStatementOperation(HiveSession parentSession,
+  public ExecuteStatementOperation newExecuteStatementOperation(HiveSessionImpl parentSession,
       String statement, Map<String, String> confOverlay) {
     ExecuteStatementOperation executeStatementOperation = ExecuteStatementOperation
         .newExecuteStatementOperation(parentSession, statement, confOverlay);
@@ -73,26 +73,26 @@ public class OperationManager extends AbstractService {
     return executeStatementOperation;
   }
 
-  public GetTypeInfoOperation newGetTypeInfoOperation(HiveSession parentSession) {
+  public GetTypeInfoOperation newGetTypeInfoOperation(HiveSessionImpl parentSession) {
     GetTypeInfoOperation operation = new GetTypeInfoOperation(parentSession);
     addOperation(operation);
     return operation;
   }
 
-  public GetCatalogsOperation newGetCatalogsOperation(HiveSession parentSession) {
+  public GetCatalogsOperation newGetCatalogsOperation(HiveSessionImpl parentSession) {
     GetCatalogsOperation operation = new GetCatalogsOperation(parentSession);
     addOperation(operation);
     return operation;
   }
 
-  public GetSchemasOperation newGetSchemasOperation(HiveSession parentSession,
+  public GetSchemasOperation newGetSchemasOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName) {
     GetSchemasOperation operation = new GetSchemasOperation(parentSession, catalogName, schemaName);
     addOperation(operation);
     return operation;
   }
 
-  public MetadataOperation newGetTablesOperation(HiveSession parentSession,
+  public MetadataOperation newGetTablesOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName, String tableName,
       List<String> tableTypes) {
     MetadataOperation operation =
@@ -101,13 +101,13 @@ public class OperationManager extends AbstractService {
     return operation;
   }
 
-  public GetTableTypesOperation newGetTableTypesOperation(HiveSession parentSession) {
+  public GetTableTypesOperation newGetTableTypesOperation(HiveSessionImpl parentSession) {
     GetTableTypesOperation operation = new GetTableTypesOperation(parentSession);
     addOperation(operation);
     return operation;
   }
 
-  public GetColumnsOperation newGetColumnsOperation(HiveSession parentSession,
+  public GetColumnsOperation newGetColumnsOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName, String tableName, String columnName) {
     GetColumnsOperation operation = new GetColumnsOperation(parentSession,
         catalogName, schemaName, tableName, columnName);
@@ -115,7 +115,7 @@ public class OperationManager extends AbstractService {
     return operation;
   }
 
-  public GetFunctionsOperation newGetFunctionsOperation(HiveSession parentSession,
+  public GetFunctionsOperation newGetFunctionsOperation(HiveSessionImpl parentSession,
       String catalogName, String schemaName, String functionName) {
     GetFunctionsOperation operation = new GetFunctionsOperation(parentSession,
         catalogName, schemaName, functionName);
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java
index f3a48a2..cd0ecd7 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java
@@ -47,7 +47,7 @@ import org.apache.hive.service.cli.HiveSQLException;
 import org.apache.hive.service.cli.OperationState;
 import org.apache.hive.service.cli.RowSet;
 import org.apache.hive.service.cli.TableSchema;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * SQLOperation.
@@ -62,7 +62,7 @@ public class SQLOperation extends ExecuteStatementOperation {
   private SerDe serde = null;
 
 
-  public SQLOperation(HiveSession parentSession, String statement, Map<String, String> confOverlay) {
+  public SQLOperation(HiveSessionImpl parentSession, String statement, Map<String, String> confOverlay) {
     // TODO: call setRemoteUser in ExecuteStatementOperation or higher.
     super(parentSession, statement, confOverlay);
   }
diff --git a/src/service/src/java/org/apache/hive/service/cli/operation/SetOperation.java b/src/service/src/java/org/apache/hive/service/cli/operation/SetOperation.java
index bf6969a..e2c5bfb 100644
--- a/src/service/src/java/org/apache/hive/service/cli/operation/SetOperation.java
+++ b/src/service/src/java/org/apache/hive/service/cli/operation/SetOperation.java
@@ -21,7 +21,7 @@ package org.apache.hive.service.cli.operation;
 import java.util.Map;
 
 import org.apache.hadoop.hive.ql.processors.SetProcessor;
-import org.apache.hive.service.cli.session.HiveSession;
+import org.apache.hive.service.cli.session.HiveSessionImpl;
 
 /**
  * HiveSetCommandOperation.
@@ -29,7 +29,7 @@ import org.apache.hive.service.cli.session.HiveSession;
  */
 public class SetOperation extends HiveCommandOperation {
 
-  protected SetOperation(HiveSession parentSession, String statement,
+  protected SetOperation(HiveSessionImpl parentSession, String statement,
       Map<String, String> confOverlay) {
     super(parentSession, statement, confOverlay);
     setCommandProcessor(new SetProcessor());
diff --git a/src/service/src/java/org/apache/hive/service/cli/session/HiveSession.java b/src/service/src/java/org/apache/hive/service/cli/session/HiveSession.java
index 1f43bb0..14feb13 100644
--- a/src/service/src/java/org/apache/hive/service/cli/session/HiveSession.java
+++ b/src/service/src/java/org/apache/hive/service/cli/session/HiveSession.java
@@ -18,265 +18,139 @@
 
 package org.apache.hive.service.cli.session;
 
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.apache.hadoop.hive.conf.HiveConf;
-import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;
 import org.apache.hadoop.hive.metastore.IMetaStoreClient;
-import org.apache.hadoop.hive.metastore.api.MetaException;
 import org.apache.hadoop.hive.ql.session.SessionState;
 import org.apache.hive.service.cli.GetInfoType;
 import org.apache.hive.service.cli.GetInfoValue;
 import org.apache.hive.service.cli.HiveSQLException;
 import org.apache.hive.service.cli.OperationHandle;
 import org.apache.hive.service.cli.SessionHandle;
-import org.apache.hive.service.cli.operation.ExecuteStatementOperation;
-import org.apache.hive.service.cli.operation.GetCatalogsOperation;
-import org.apache.hive.service.cli.operation.GetColumnsOperation;
-import org.apache.hive.service.cli.operation.GetFunctionsOperation;
-import org.apache.hive.service.cli.operation.GetSchemasOperation;
-import org.apache.hive.service.cli.operation.GetTableTypesOperation;
-import org.apache.hive.service.cli.operation.GetTypeInfoOperation;
-import org.apache.hive.service.cli.operation.MetadataOperation;
 import org.apache.hive.service.cli.operation.OperationManager;
 
-/**
- * HiveSession.
- *
- */
-public class HiveSession {
-
-  private final SessionHandle sessionHandle = new SessionHandle();
-  private String username;
-  private final String password;
-  private final Map<String, String> sessionConf = new HashMap<String, String>();
-  private final HiveConf hiveConf = new HiveConf();
-  private final SessionState sessionState;
-
-  private static final String FETCH_WORK_SERDE_CLASS =
-      "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe";
-
-  private SessionManager sessionManager;
-  private OperationManager operationManager;
-  private IMetaStoreClient metastoreClient = null;
-  private String ipAddress;
-
-  public HiveSession(String username, String password, Map<String, String> sessionConf, String ipAddress) {
-    this.username = username;
-    this.password = password;
-    this.ipAddress = ipAddress;
-
-    if (sessionConf != null) {
-      sessionConf.putAll(sessionConf);
-    }
-
-    sessionState = new SessionState(hiveConf);
-  }
-
-  private SessionManager getSessionManager() {
-    return sessionManager;
-  }
-
-  public void setSessionManager(SessionManager sessionManager) {
-    this.sessionManager = sessionManager;
-  }
-
-  private OperationManager getOperationManager() {
-    return operationManager;
-  }
-
-  public void setOperationManager(OperationManager operationManager) {
-    this.operationManager = operationManager;
-  }
-
-  private synchronized void acquire() {
-    SessionState.start(sessionState);
-  }
-
-  private synchronized void release() {
-    assert sessionState != null;
-    // no need to release sessionState...
-  }
-
-  public SessionHandle getSessionHandle() {
-    return sessionHandle;
-  }
-
-  public String getUsername() {
-    return username;
-  }
-
-  public String getPassword() {
-    return password;
-  }
-
-  public HiveConf getHiveConf() {
-    hiveConf.setVar(HiveConf.ConfVars.HIVEFETCHOUTPUTSERDE, FETCH_WORK_SERDE_CLASS);
-    return hiveConf;
-  }
-
-  public IMetaStoreClient getMetaStoreClient() throws HiveSQLException {
-    if (metastoreClient == null) {
-      try {
-        metastoreClient = new HiveMetaStoreClient(getHiveConf());
-      } catch (MetaException e) {
-        throw new HiveSQLException(e);
-      }
-    }
-    return metastoreClient;
-  }
-
-  public GetInfoValue getInfo(GetInfoType getInfoType)
-      throws HiveSQLException {
-    acquire();
-    try {
-      switch (getInfoType) {
-      case CLI_SERVER_NAME:
-        return new GetInfoValue("Hive");
-      case CLI_DBMS_NAME:
-        return new GetInfoValue("Apache Hive");
-      case CLI_DBMS_VER:
-        return new GetInfoValue("0.10.0");
-      case CLI_MAX_COLUMN_NAME_LEN:
-        return new GetInfoValue(128);
-      case CLI_MAX_SCHEMA_NAME_LEN:
-        return new GetInfoValue(128);
-      case CLI_MAX_TABLE_NAME_LEN:
-        return new GetInfoValue(128);
-      case CLI_TXN_CAPABLE:
-      default:
-        throw new HiveSQLException("Unrecognized GetInfoType value: " + getInfoType.toString());
-      }
-    } finally {
-      release();
-    }
-  }
-
-  public OperationHandle executeStatement(String statement, Map<String, String> confOverlay)
-      throws HiveSQLException {
-    acquire();
-    try {
-      ExecuteStatementOperation operation = getOperationManager()
-          .newExecuteStatementOperation(this, statement, confOverlay);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
-
-  public OperationHandle getTypeInfo()
-      throws HiveSQLException {
-    acquire();
-    try {
-      GetTypeInfoOperation operation = getOperationManager().newGetTypeInfoOperation(this);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
-
-  public OperationHandle getCatalogs()
-      throws HiveSQLException {
-    acquire();
-    try {
-      GetCatalogsOperation operation = getOperationManager().newGetCatalogsOperation(this);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
-
+public interface HiveSession {
+  /**
+   * Set the session manager for the session
+   * @param sessionManager
+   */
+  public void setSessionManager(SessionManager sessionManager);
+
+  /**
+   * Set operation manager for the session
+   * @param operationManager
+   */
+  public void setOperationManager(OperationManager operationManager);
+
+  public SessionHandle getSessionHandle();
+
+  public String getUsername();
+
+  public String getPassword();
+
+  public HiveConf getHiveConf();
+
+  public IMetaStoreClient getMetaStoreClient() throws HiveSQLException;
+
+  /**
+   * getInfo operation handler
+   * @param getInfoType
+   * @return
+   * @throws HiveSQLException
+   */
+  public GetInfoValue getInfo(GetInfoType getInfoType) throws HiveSQLException;
+
+  /**
+   * execute operation handler
+   * @param statement
+   * @param confOverlay
+   * @return
+   * @throws HiveSQLException
+   */
+  public OperationHandle executeStatement(String statement,
+      Map<String, String> confOverlay) throws HiveSQLException;
+
+  /**
+   * getTypeInfo operation handler
+   * @return
+   * @throws HiveSQLException
+   */
+  public OperationHandle getTypeInfo() throws HiveSQLException;
+
+  /**
+   * getCatalogs operation handler
+   * @return
+   * @throws HiveSQLException
+   */
+  public OperationHandle getCatalogs() throws HiveSQLException;
+
+  /**
+   * getSchemas operation handler
+   * @param catalogName
+   * @param schemaName
+   * @return
+   * @throws HiveSQLException
+   */
   public OperationHandle getSchemas(String catalogName, String schemaName)
-      throws HiveSQLException {
-      acquire();
-    try {
-      GetSchemasOperation operation =
-          getOperationManager().newGetSchemasOperation(this, catalogName, schemaName);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
-
-  public OperationHandle getTables(String catalogName, String schemaName, String tableName,
-      List<String> tableTypes)
-      throws HiveSQLException {
-      acquire();
-    try {
-      MetadataOperation operation =
-          getOperationManager().newGetTablesOperation(this, catalogName, schemaName, tableName, tableTypes);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
-
-  public OperationHandle getTableTypes()
-      throws HiveSQLException {
-      acquire();
-    try {
-      GetTableTypesOperation operation = getOperationManager().newGetTableTypesOperation(this);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
-
+      throws HiveSQLException;
+
+  /**
+   * getTables operation handler
+   * @param catalogName
+   * @param schemaName
+   * @param tableName
+   * @param tableTypes
+   * @return
+   * @throws HiveSQLException
+   */
+  public OperationHandle getTables(String catalogName, String schemaName,
+      String tableName, List<String> tableTypes) throws HiveSQLException;
+
+  /**
+   * getTableTypes operation handler
+   * @return
+   * @throws HiveSQLException
+   */
+  public OperationHandle getTableTypes() throws HiveSQLException ;
+
+  /**
+   * getColumns operation handler
+   * @param catalogName
+   * @param schemaName
+   * @param tableName
+   * @param columnName
+   * @return
+   * @throws HiveSQLException
+   */
   public OperationHandle getColumns(String catalogName, String schemaName,
-      String tableName, String columnName)  throws HiveSQLException {
-    acquire();
-    try {
-    GetColumnsOperation operation = getOperationManager().newGetColumnsOperation(this,
-        catalogName, schemaName, tableName, columnName);
-    operation.run();
-    return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
+      String tableName, String columnName)  throws HiveSQLException;
 
-  public OperationHandle getFunctions(String catalogName, String schemaName, String functionName)
-      throws HiveSQLException {
-    acquire();
-    try {
-      GetFunctionsOperation operation = getOperationManager()
-          .newGetFunctionsOperation(this, catalogName, schemaName, functionName);
-      operation.run();
-      return operation.getHandle();
-    } finally {
-      release();
-    }
-  }
+  /**
+   * getFunctions operation handler
+   * @param catalogName
+   * @param schemaName
+   * @param functionName
+   * @return
+   * @throws HiveSQLException
+   */
+  public OperationHandle getFunctions(String catalogName, String schemaName,
+      String functionName) throws HiveSQLException;
 
-  public void close() throws HiveSQLException {
-    return;
-  }
+  /**
+   * close the session
+   * @throws HiveSQLException
+   */
+  public void close() throws HiveSQLException;
 
-  public SessionState getSessionState() {
-    return sessionState;
-  }
+  public SessionState getSessionState();
 
-  public String getIpAddress() {
-    return ipAddress;
-  }
+  public String getIpAddress();
 
-  public String setIpAddress(String ipAddress) {
-    return this.ipAddress = ipAddress;
-  }
+  public String setIpAddress(String ipAddress);
 
-  public void setUserName(String userName) {
-    this.username = userName;
-  }
+  public String getUserName();
 
-  public String getUserName() {
-    return username;
-  }
+  public void setUserName(String userName);
 }
diff --git a/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java b/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
new file mode 100644
index 0000000..7e33600
--- /dev/null
+++ b/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java
@@ -0,0 +1,295 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.service.cli.session;
+
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.HiveMetaStoreClient;
+import org.apache.hadoop.hive.metastore.IMetaStoreClient;
+import org.apache.hadoop.hive.metastore.api.MetaException;
+import org.apache.hadoop.hive.ql.session.SessionState;
+import org.apache.hive.service.cli.GetInfoType;
+import org.apache.hive.service.cli.GetInfoValue;
+import org.apache.hive.service.cli.HiveSQLException;
+import org.apache.hive.service.cli.OperationHandle;
+import org.apache.hive.service.cli.SessionHandle;
+import org.apache.hive.service.cli.operation.ExecuteStatementOperation;
+import org.apache.hive.service.cli.operation.GetCatalogsOperation;
+import org.apache.hive.service.cli.operation.GetColumnsOperation;
+import org.apache.hive.service.cli.operation.GetFunctionsOperation;
+import org.apache.hive.service.cli.operation.GetSchemasOperation;
+import org.apache.hive.service.cli.operation.GetTableTypesOperation;
+import org.apache.hive.service.cli.operation.GetTypeInfoOperation;
+import org.apache.hive.service.cli.operation.MetadataOperation;
+import org.apache.hive.service.cli.operation.OperationManager;
+
+/**
+ * HiveSession
+ *
+ */
+public class HiveSessionImpl implements HiveSession {
+
+  private final SessionHandle sessionHandle = new SessionHandle();
+  private String username;
+  private final String password;
+  private final Map<String, String> sessionConf = new HashMap<String, String>();
+  private final HiveConf hiveConf = new HiveConf();
+  private final SessionState sessionState;
+
+  private static final String FETCH_WORK_SERDE_CLASS =
+      "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe";
+
+  private SessionManager sessionManager;
+  private OperationManager operationManager;
+  private IMetaStoreClient metastoreClient = null;
+  private String ipAddress;
+
+  public HiveSessionImpl(String username, String password, Map<String, String> sessionConf, String ipAddress) {
+    this.username = username;
+    this.password = password;
+    this.ipAddress = ipAddress;
+
+    if (sessionConf != null) {
+      for (Map.Entry<String, String> entry : sessionConf.entrySet()) {
+        hiveConf.set(entry.getKey(), entry.getValue());
+      }
+    }
+
+    sessionState = new SessionState(hiveConf);
+  }
+
+  private SessionManager getSessionManager() {
+    return sessionManager;
+  }
+
+  public void setSessionManager(SessionManager sessionManager) {
+    this.sessionManager = sessionManager;
+  }
+
+  private OperationManager getOperationManager() {
+    return operationManager;
+  }
+
+  public void setOperationManager(OperationManager operationManager) {
+    this.operationManager = operationManager;
+  }
+
+  protected synchronized void acquire() throws HiveSQLException {
+    SessionState.start(sessionState);
+  }
+
+  protected synchronized void release() {
+    assert sessionState != null;
+    // no need to release sessionState...
+  }
+
+  public SessionHandle getSessionHandle() {
+    return sessionHandle;
+  }
+
+  public String getUsername() {
+    return username;
+  }
+
+  public String getPassword() {
+    return password;
+  }
+
+  public HiveConf getHiveConf() {
+    hiveConf.setVar(HiveConf.ConfVars.HIVEFETCHOUTPUTSERDE, FETCH_WORK_SERDE_CLASS);
+    return hiveConf;
+  }
+
+  public IMetaStoreClient getMetaStoreClient() throws HiveSQLException {
+    if (metastoreClient == null) {
+      try {
+        metastoreClient = new HiveMetaStoreClient(getHiveConf());
+      } catch (MetaException e) {
+        throw new HiveSQLException(e);
+      }
+    }
+    return metastoreClient;
+  }
+
+  public GetInfoValue getInfo(GetInfoType getInfoType)
+      throws HiveSQLException {
+    acquire();
+    try {
+      switch (getInfoType) {
+      case CLI_SERVER_NAME:
+        return new GetInfoValue("Hive");
+      case CLI_DBMS_NAME:
+        return new GetInfoValue("Apache Hive");
+      case CLI_DBMS_VER:
+        return new GetInfoValue("0.10.0");
+      case CLI_MAX_COLUMN_NAME_LEN:
+        return new GetInfoValue(128);
+      case CLI_MAX_SCHEMA_NAME_LEN:
+        return new GetInfoValue(128);
+      case CLI_MAX_TABLE_NAME_LEN:
+        return new GetInfoValue(128);
+      case CLI_TXN_CAPABLE:
+      default:
+        throw new HiveSQLException("Unrecognized GetInfoType value: " + getInfoType.toString());
+      }
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle executeStatement(String statement, Map<String, String> confOverlay)
+      throws HiveSQLException {
+    acquire();
+    try {
+      ExecuteStatementOperation operation = getOperationManager()
+          .newExecuteStatementOperation(this, statement, confOverlay);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getTypeInfo()
+      throws HiveSQLException {
+    acquire();
+    try {
+      GetTypeInfoOperation operation = getOperationManager().newGetTypeInfoOperation(this);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getCatalogs()
+      throws HiveSQLException {
+    acquire();
+    try {
+      GetCatalogsOperation operation = getOperationManager().newGetCatalogsOperation(this);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getSchemas(String catalogName, String schemaName)
+      throws HiveSQLException {
+      acquire();
+    try {
+      GetSchemasOperation operation =
+          getOperationManager().newGetSchemasOperation(this, catalogName, schemaName);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getTables(String catalogName, String schemaName, String tableName,
+      List<String> tableTypes)
+      throws HiveSQLException {
+      acquire();
+    try {
+      MetadataOperation operation =
+          getOperationManager().newGetTablesOperation(this, catalogName, schemaName, tableName, tableTypes);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getTableTypes()
+      throws HiveSQLException {
+      acquire();
+    try {
+      GetTableTypesOperation operation = getOperationManager().newGetTableTypesOperation(this);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getColumns(String catalogName, String schemaName,
+      String tableName, String columnName)  throws HiveSQLException {
+    acquire();
+    try {
+    GetColumnsOperation operation = getOperationManager().newGetColumnsOperation(this,
+        catalogName, schemaName, tableName, columnName);
+    operation.run();
+    return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public OperationHandle getFunctions(String catalogName, String schemaName, String functionName)
+      throws HiveSQLException {
+    acquire();
+    try {
+      GetFunctionsOperation operation = getOperationManager()
+          .newGetFunctionsOperation(this, catalogName, schemaName, functionName);
+      operation.run();
+      return operation.getHandle();
+    } finally {
+      release();
+    }
+  }
+
+  public void close() throws HiveSQLException {
+    try {
+      acquire();
+      /**
+       *  For metadata operations like getTables(), getColumns() etc,
+       * the session allocates a private metastore handler which should be
+       * closed at the end of the session
+       */
+      if (metastoreClient != null) {
+        metastoreClient.close();
+      }
+    } finally {
+      release();
+    }
+  }
+
+  public SessionState getSessionState() {
+    return sessionState;
+  }
+
+  public String getIpAddress() {
+    return ipAddress;
+  }
+
+  public String setIpAddress(String ipAddress) {
+    return this.ipAddress = ipAddress;
+  }
+
+  public String getUserName() {
+    return username;
+  }
+  public void setUserName(String userName) {
+    this.username = userName;
+  }
+}
diff --git a/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionImplwithUGI.java b/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionImplwithUGI.java
new file mode 100644
index 0000000..f54c6ca
--- /dev/null
+++ b/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionImplwithUGI.java
@@ -0,0 +1,137 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.service.cli.session;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.hadoop.hive.ql.metadata.Hive;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.shims.ShimLoader;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hive.service.cli.HiveSQLException;
+
+/**
+ *
+ * HiveSessionImplwithUGI.
+ * HiveSession with connecting user's UGI and delegation token if required
+ */
+public class HiveSessionImplwithUGI extends HiveSessionImpl {
+  public static final String HS2TOKEN = "HiveServer2ImpersonationToken";
+
+  private UserGroupInformation sessionUgi = null;
+  private String delegationTokenStr = null;
+  private Hive sessionHive = null;
+
+  public HiveSessionImplwithUGI(String username, String password, Map<String, String> sessionConf,
+      String ipAddress, String delegationToken) throws HiveSQLException {
+    super(username, password, sessionConf, ipAddress);
+    setSessionUGI(username);
+    setDelegationToken(delegationToken);
+  }
+
+  // setup appropriate UGI for the session
+  public void setSessionUGI(String owner) throws HiveSQLException {
+    if (owner == null) {
+      throw new HiveSQLException("No username provided for impersonation");
+    }
+    if (ShimLoader.getHadoopShims().isSecurityEnabled()) {
+      try {
+        sessionUgi = ShimLoader.getHadoopShims().createProxyUser(owner);
+      } catch (IOException e) {
+        throw new HiveSQLException("Couldn't setup proxy user", e);
+      }
+    } else {
+      sessionUgi = ShimLoader.getHadoopShims().createRemoteUser(owner, null);
+    }
+  }
+
+  public UserGroupInformation getSessionUgi() {
+    return this.sessionUgi;
+  }
+
+  public String getDelegationToken () {
+    return this.delegationTokenStr;
+  }
+
+  @Override
+  protected synchronized void acquire() throws HiveSQLException {
+    super.acquire();
+    // if we have a metastore connection with impersonation, then set it first
+    if (sessionHive != null) {
+      Hive.set(sessionHive);
+    }
+  }
+
+  /**
+   * close the file systems for the session
+   * cancel the session's delegation token and close the metastore connection
+   */
+  @Override
+  public void close() throws HiveSQLException {
+    try {
+    acquire();
+    ShimLoader.getHadoopShims().closeAllForUGI(sessionUgi);
+    cancelDelegationToken();
+    } finally {
+      release();
+      super.close();
+    }
+  }
+
+  /**
+   * Enable delegation token for the session
+   * save the token string and set the token.signature in hive conf. The metastore client uses
+   * this token.signature to determine where to use kerberos or delegation token
+   * @throws HiveException
+   * @throws IOException
+   */
+  private void setDelegationToken(String delegationTokenStr) throws HiveSQLException {
+    this.delegationTokenStr = delegationTokenStr;
+    if (delegationTokenStr != null) {
+      getHiveConf().set("hive.metastore.token.signature", HS2TOKEN);
+      try {
+        ShimLoader.getHadoopShims().setTokenStr(sessionUgi, delegationTokenStr, HS2TOKEN);
+      } catch (IOException e) {
+        throw new HiveSQLException("Couldn't setup delegation token in the ugi", e);
+      }
+      // create a new metastore connection using the delegation token
+      Hive.set(null);
+      try {
+        sessionHive = Hive.get(getHiveConf());
+      } catch (HiveException e) {
+        throw new HiveSQLException("Failed to setup metastore connection", e);
+      }
+    }
+  }
+
+  // If the session has a delegation token obtained from the metastore, then cancel it
+  private void cancelDelegationToken() throws HiveSQLException {
+    if (delegationTokenStr != null) {
+      try {
+        Hive.get(getHiveConf()).cancelDelegationToken(delegationTokenStr);
+      } catch (HiveException e) {
+        throw new HiveSQLException("Couldn't cancel delegation token", e);
+      }
+      // close the metastore connection created with this delegation token
+      Hive.closeCurrent();
+    }
+  }
+
+}
diff --git a/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionProxy.java b/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionProxy.java
new file mode 100644
index 0000000..76f18a9
--- /dev/null
+++ b/src/service/src/java/org/apache/hive/service/cli/session/HiveSessionProxy.java
@@ -0,0 +1,87 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hive.service.cli.session;
+
+/**
+ * Proxy wrapper on HiveSession to execute operations
+ * by impersonating given user
+ */
+import java.lang.reflect.InvocationHandler;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.lang.reflect.Proxy;
+import java.lang.reflect.UndeclaredThrowableException;
+import java.security.PrivilegedActionException;
+import java.security.PrivilegedExceptionAction;
+
+import org.apache.hadoop.hive.shims.ShimLoader;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.hive.service.cli.HiveSQLException;
+
+public class HiveSessionProxy implements InvocationHandler {
+  private final HiveSession base;
+  private final UserGroupInformation ugi;
+
+  public HiveSessionProxy(HiveSession hiveSession, UserGroupInformation ugi) {
+    this.base = hiveSession;
+    this.ugi = ugi;
+  }
+
+  public static HiveSession getProxy(HiveSession hiveSession, UserGroupInformation ugi)
+      throws IllegalArgumentException, HiveSQLException {
+    return (HiveSession)Proxy.newProxyInstance(HiveSession.class.getClassLoader(),
+        new Class<?>[] {HiveSession.class},
+        new HiveSessionProxy(hiveSession, ugi));
+  }
+
+  @Override
+  public Object invoke(Object arg0, final Method method, final Object[] args)
+      throws Throwable {
+    try {
+      return ShimLoader.getHadoopShims().doAs(ugi,
+        new PrivilegedExceptionAction<Object> () {
+          @Override
+          public Object run() throws HiveSQLException {
+            try {
+              return method.invoke(base, args);
+            } catch (InvocationTargetException e) {
+              if (e.getCause() instanceof HiveSQLException) {
+                throw (HiveSQLException)e.getCause();
+              } else {
+                throw new RuntimeException(e.getCause());
+              }
+            } catch (IllegalArgumentException e) {
+              throw new RuntimeException(e);
+            } catch (IllegalAccessException e) {
+              throw new RuntimeException(e);
+            }
+          }
+        });
+    } catch (UndeclaredThrowableException e) {
+      Throwable innerException = e.getCause();
+      if (innerException instanceof PrivilegedActionException) {
+        throw innerException.getCause();
+      } else {
+        throw e.getCause();
+      }
+    }
+  }
+
+}
+
diff --git a/src/service/src/java/org/apache/hive/service/cli/session/SessionManager.java b/src/service/src/java/org/apache/hive/service/cli/session/SessionManager.java
index 3741dd2..56a2b33 100644
--- a/src/service/src/java/org/apache/hive/service/cli/session/SessionManager.java
+++ b/src/service/src/java/org/apache/hive/service/cli/session/SessionManager.java
@@ -64,9 +64,20 @@ public class SessionManager extends CompositeService {
     super.stop();
   }
 
-  public SessionHandle openSession(String username, String password, Map<String, String> sessionConf) {
-    HiveSession session = new HiveSession(threadLocalUserName.get(), password, sessionConf,
-                                threadLocalIpAddress.get());
+  public SessionHandle openSession(String username, String password, Map<String, String> sessionConf,
+          boolean withImpersonation, String delegationToken) throws HiveSQLException {
+    HiveSession session;
+    if (username == null) {
+      username = threadLocalUserName.get();
+    }
+
+    if (withImpersonation) {
+          HiveSessionImplwithUGI hiveSessionUgi = new HiveSessionImplwithUGI(username, password, sessionConf,
+              threadLocalIpAddress.get(), delegationToken);
+          session = (HiveSession)HiveSessionProxy.getProxy(hiveSessionUgi, hiveSessionUgi.getSessionUgi());
+    } else {
+      session = new HiveSessionImpl(username, password, sessionConf, threadLocalIpAddress.get());
+    }
 
     session.setSessionManager(this);
     session.setOperationManager(operationManager);
diff --git a/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java b/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java
index a8c9d8b..709709e 100644
--- a/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java
+++ b/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIService.java
@@ -75,6 +75,7 @@ public class ThriftCLIService extends AbstractService implements TCLIService.Ifa
   private int maxWorkerThreads;
 
 
+
   public ThriftCLIService(CLIService cliService) {
     super("ThriftCLIService");
     this.cliService = cliService;
@@ -118,10 +119,20 @@ public class ThriftCLIService extends AbstractService implements TCLIService.Ifa
       } else {
         userName = req.getUsername();
       }
-      SessionHandle sessionHandle = cliService
-          .openSession(userName, req.getPassword(), req.getConfiguration());
-      if (userName != null) {
-        cliService.setUserName(sessionHandle, userName);
+      SessionHandle sessionHandle = null;
+      if (cliService.getHiveConf().
+          getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_KERBEROS_IMPERSONATION)) {
+        String delegationTokenStr = null;
+        try {
+          delegationTokenStr = cliService.getDelegationTokenFromMetaStore(userName);
+        } catch (UnsupportedOperationException e) {
+          // The delegation token is not applicable in the given deployment mode
+        }
+        sessionHandle = cliService.openSessionWithImpersonation(userName, req.getPassword(),
+              req.getConfiguration(), delegationTokenStr);
+      } else {
+        sessionHandle = cliService.openSession(userName, req.getPassword(),
+              req.getConfiguration());
       }
       // Cannot break the b/w compatibility of API to accept ipAddress as another parameter in
       // openSession call. Hence making this call
diff --git a/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java b/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java
index b29b405..5eb6157 100644
--- a/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java
+++ b/src/service/src/java/org/apache/hive/service/cli/thrift/ThriftCLIServiceClient.java
@@ -75,6 +75,15 @@ public class ThriftCLIServiceClient extends CLIServiceClient {
    * @see org.apache.hive.service.cli.ICLIService#closeSession(org.apache.hive.service.cli.SessionHandle)
    */
   @Override
+  public SessionHandle openSessionWithImpersonation(String username, String password,
+      Map<String, String> configuration, String delegationToken) throws HiveSQLException {
+    throw new HiveSQLException("open with impersonation operation is not supported in the client");
+  }
+
+  /* (non-Javadoc)
+   * @see org.apache.hive.service.cli.ICLIService#closeSession(org.apache.hive.service.cli.SessionHandle)
+   */
+  @Override
   public void closeSession(SessionHandle sessionHandle) throws HiveSQLException {
     try {
       TCloseSessionReq req = new TCloseSessionReq(sessionHandle.toTSessionHandle());
diff --git a/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java b/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
index cae0d82..bf2d099 100644
--- a/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
+++ b/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
@@ -39,6 +39,7 @@ import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.PathFilter;
 import org.apache.hadoop.hdfs.MiniDFSCluster;
 import org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil;
+import org.apache.hadoop.hive.thrift.DelegationTokenIdentifier;
 import org.apache.hadoop.hive.thrift.DelegationTokenSelector;
 import org.apache.hadoop.http.HtmlQuoting;
 import org.apache.hadoop.io.Text;
@@ -539,11 +540,30 @@ public abstract class HadoopShimsSecure implements HadoopShims {
   }
 
   @Override
+  public void setTokenStr(UserGroupInformation ugi, String tokenStr, String tokenService) throws IOException {
+    Token<DelegationTokenIdentifier> delegationToken = new Token<DelegationTokenIdentifier>();
+    delegationToken.decodeFromUrlString(tokenStr);
+    delegationToken.setService(new Text(tokenService));
+    ugi.addToken(delegationToken);
+  }
+
+  @Override
   public <T> T doAs(UserGroupInformation ugi, PrivilegedExceptionAction<T> pvea) throws IOException, InterruptedException {
     return ugi.doAs(pvea);
   }
 
   @Override
+  public UserGroupInformation createProxyUser(String userName) throws IOException {
+    return UserGroupInformation.createProxyUser(
+        userName, UserGroupInformation.getLoginUser());
+  }
+
+  @Override
+  public boolean isSecurityEnabled() {
+    return UserGroupInformation.isSecurityEnabled();
+  }
+
+  @Override
   public UserGroupInformation createRemoteUser(String userName, List<String> groupNames) {
     return UserGroupInformation.createRemoteUser(userName);
   }
diff --git a/src/shims/src/common-secure/java/org/apache/hadoop/hive/thrift/HadoopThriftAuthBridge20S.java b/src/shims/src/common-secure/java/org/apache/hadoop/hive/thrift/HadoopThriftAuthBridge20S.java
index bee9a8b..777226f 100644
--- a/src/shims/src/common-secure/java/org/apache/hadoop/hive/thrift/HadoopThriftAuthBridge20S.java
+++ b/src/shims/src/common-secure/java/org/apache/hadoop/hive/thrift/HadoopThriftAuthBridge20S.java
@@ -550,6 +550,7 @@ import static org.apache.hadoop.fs.CommonConfigurationKeys.HADOOP_SECURITY_AUTHE
            if (useProxy) {
              clientUgi = UserGroupInformation.createProxyUser(
                endUser, UserGroupInformation.getLoginUser());
+             remoteUser.set(clientUgi.getShortUserName());
              return clientUgi.doAs(new PrivilegedExceptionAction<Boolean>() {
                  public Boolean run() {
                    try {
diff --git a/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java b/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
index 5e2de5c..b361b34 100644
--- a/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
+++ b/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
@@ -226,6 +226,12 @@ public interface HadoopShims {
   public boolean isSecureShimImpl();
 
   /**
+   * Return true if the hadoop configuration has security enabled
+   * @return
+   */
+  public boolean isSecurityEnabled();
+
+  /**
    * Get the string form of the token given a token signature.
    * The signature is used as the value of the "service" field in the token for lookup.
    * Ref: AbstractDelegationTokenSelector in Hadoop. If there exists such a token
@@ -242,6 +248,16 @@ public interface HadoopShims {
    */
   String getTokenStrForm(String tokenSignature) throws IOException;
 
+  /**
+   * Add a delegation token to the given ugi
+   * @param ugi
+   * @param tokenStr
+   * @param tokenService
+   * @throws IOException
+   */
+  void setTokenStr(UserGroupInformation ugi, String tokenStr, String tokenService)
+    throws IOException;
+
 
   enum JobTrackerState { INITIALIZING, RUNNING };
 
@@ -296,6 +312,13 @@ public interface HadoopShims {
   public void loginUserFromKeytab(String principal, String keytabFile) throws IOException;
 
   /**
+   * Create the proxy ugi for the given userid
+   * @param userName
+   * @return
+   */
+  UserGroupInformation createProxyUser(String userName) throws IOException;
+
+  /**
    * InputSplitShim.
    *
    */
@@ -355,4 +378,5 @@ public interface HadoopShims {
     RecordReader getRecordReader(JobConf job, InputSplitShim split, Reporter reporter,
         Class<RecordReader<K, V>> rrClass) throws IOException;
   }
+
 }
-- 
1.7.0.4

