From c35db653ce60964fa30700709f7efe0f82fe6eb3 Mon Sep 17 00:00:00 2001
From: Brock Noland <brock@cloudera.com>
Date: Tue, 26 Mar 2013 13:16:44 -0500
Subject: [PATCH 078/121] CDH-10672: Hive Driver calls System.exit() which causes HiveServer to exit

---
 ql/src/java/org/apache/hadoop/hive/ql/Driver.java  |   16 +++++++++-------
 .../org/apache/hadoop/hive/ql/exec/ExecDriver.java |   16 +++++++++++++++-
 .../org/apache/hadoop/hive/ql/exec/MapRedTask.java |   12 +++++++++++-
 .../hadoop/hive/ql/exec/MapredLocalTask.java       |   11 ++++++++++-
 .../java/org/apache/hadoop/hive/ql/exec/Task.java  |    3 +++
 .../test/queries/clientnegative/driver_suicide.q   |    5 +++++
 .../results/clientnegative/driver_suicide.q.out    |    6 ++++++
 7 files changed, 59 insertions(+), 10 deletions(-)
 create mode 100644 ql/src/test/queries/clientnegative/driver_suicide.q
 create mode 100644 ql/src/test/results/clientnegative/driver_suicide.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
index a41bb90..96fbd91 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/Driver.java
@@ -1167,7 +1167,7 @@ public class Driver implements CommandProcessor {
         if (exitVal != 0) {
           if (tsk.ifRetryCmdWhenFail()) {
             if (running.size() != 0) {
-              taskCleanup();
+              taskCleanup(running);
             }
             // in case we decided to run everything in local mode, restore the
             // the jobtracker setting to its initial value
@@ -1212,7 +1212,7 @@ public class Driver implements CommandProcessor {
             SQLState = "08S01";
             console.printError(errorMessage);
             if (running.size() != 0) {
-              taskCleanup();
+              taskCleanup(running);
             }
             // in case we decided to run everything in local mode, restore the
             // the jobtracker setting to its initial value
@@ -1378,11 +1378,13 @@ public class Driver implements CommandProcessor {
    * Cleans up remaining tasks in case of failure
    */
 
-  public void taskCleanup() {
-    // The currently existing Shutdown hooks will be automatically called,
-    // killing the map-reduce processes.
-    // The non MR processes will be killed as well.
-    System.exit(9);
+  public void taskCleanup(Map<TaskResult, TaskRunner> running) {
+    for (Map.Entry<TaskResult, TaskRunner> entry : running.entrySet()) {
+      if (entry.getKey().isRunning()) {
+        entry.getValue().getTask().shutdown();
+      }
+    }
+    running.clear();
   }
 
   /**
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
index 8eef395..40f1305 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
@@ -106,6 +106,8 @@ public class ExecDriver extends Task<MapredWork> implements Serializable, Hadoop
 
   protected static transient final Log LOG = LogFactory.getLog(ExecDriver.class);
 
+  private RunningJob rj;
+
   /**
    * Constructor when invoked from QL.
    */
@@ -357,7 +359,6 @@ public class ExecDriver extends Task<MapredWork> implements Serializable, Hadoop
       initializeFiles("tmpfiles", addedFiles);
     }
     int returnVal = 0;
-    RunningJob rj = null;
     boolean noName = StringUtils.isEmpty(HiveConf.getVar(job, HiveConf.ConfVars.HADOOPJOBNAME));
 
     if (noName) {
@@ -987,4 +988,17 @@ public class ExecDriver extends Task<MapredWork> implements Serializable, Hadoop
   public void logPlanProgress(SessionState ss) throws IOException {
     ss.getHiveHistory().logPlanProgress(queryPlan);
   }
+
+  @Override
+  public void shutdown() {
+    super.shutdown();
+    if (rj != null) {
+      try {
+        rj.killJob();
+      } catch (Exception e) {
+        LOG.warn("failed to kill job " + rj.getID(), e);
+      }
+      rj = null;
+    }
+  }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
index 4c8831f..7e8a49a 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapRedTask.java
@@ -69,6 +69,8 @@ public class MapRedTask extends ExecDriver implements Serializable {
   private transient long totalInputFileSize;
   private transient long totalInputNumFiles;
 
+  private Process executor;
+
   public MapRedTask() {
     super();
   }
@@ -210,7 +212,6 @@ public class MapRedTask extends ExecDriver implements Serializable {
       }
 
       LOG.info("Executing: " + cmdLine);
-      Process executor = null;
 
       // Inherit Java system variables
       String hadoopOpts;
@@ -551,4 +552,13 @@ public class MapRedTask extends ExecDriver implements Serializable {
   public Operator<? extends OperatorDesc> getReducer() {
     return getWork().getReducer();
   }
+
+  @Override
+  public void shutdown() {
+    super.shutdown();
+    if (executor != null) {
+      executor.destroy();
+      executor = null;
+    }
+  }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
index 5d2017d..d8ba9d9 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/MapredLocalTask.java
@@ -77,6 +77,8 @@ public class MapredLocalTask extends Task<MapredLocalWork> implements Serializab
   // will pass this context throught
   private final ExecMapperContext execContext = new ExecMapperContext();
 
+  private Process executor;
+
   public MapredLocalTask() {
     super();
   }
@@ -155,7 +157,6 @@ public class MapredLocalTask extends Task<MapredLocalWork> implements Serializab
       }
 
       LOG.info("Executing: " + cmdLine);
-      Process executor = null;
 
       // Inherit Java system variables
       String hadoopOpts;
@@ -462,4 +463,12 @@ public class MapredLocalTask extends Task<MapredLocalWork> implements Serializab
     return StageType.MAPREDLOCAL;
   }
 
+  @Override
+  public void shutdown() {
+    super.shutdown();
+    if (executor != null) {
+      executor.destroy();
+      executor = null;
+    }
+  }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
index b380a69..4e64343 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/Task.java
@@ -512,6 +512,9 @@ public abstract class Task<T extends Serializable> implements Serializable, Node
     return jobID;
   }
 
+  public void shutdown() {
+  }
+
   public List<FieldSchema> getResultSchema() {
     return null;
   }
diff --git a/src/ql/src/test/queries/clientnegative/driver_suicide.q b/src/ql/src/test/queries/clientnegative/driver_suicide.q
new file mode 100644
index 0000000..3977f8b
--- /dev/null
+++ b/src/ql/src/test/queries/clientnegative/driver_suicide.q
@@ -0,0 +1,5 @@
+CREATE TABLE SAMPLETABLE(IP STRING , showtime BIGINT ) partitioned by (ds string,ipz int) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\040';
+
+ALTER TABLE SAMPLETABLE add Partition(ds='sf') location '/user/hive/warehouse' Partition(ipz=100) location '/user/hive/warehouse';
+
+drop table SAMPLETABLE;
\ No newline at end of file
diff --git a/src/ql/src/test/results/clientnegative/driver_suicide.q.out b/src/ql/src/test/results/clientnegative/driver_suicide.q.out
new file mode 100644
index 0000000..5d38b35
--- /dev/null
+++ b/src/ql/src/test/results/clientnegative/driver_suicide.q.out
@@ -0,0 +1,6 @@
+PREHOOK: query: CREATE TABLE SAMPLETABLE(IP STRING , showtime BIGINT ) partitioned by (ds string,ipz int) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\040'
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE SAMPLETABLE(IP STRING , showtime BIGINT ) partitioned by (ds string,ipz int) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\040'
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@SAMPLETABLE
+FAILED: SemanticException [Error 10214]: Invalid partition spec specified table is partitioned but partition spec is not specified or does not fully match table partitioning: {ds=sf}
-- 
1.7.0.4

