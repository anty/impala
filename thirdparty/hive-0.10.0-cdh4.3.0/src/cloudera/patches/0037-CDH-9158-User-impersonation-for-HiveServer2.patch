From faad66b9eb238e66388861415a2dfa1046f3c78b Mon Sep 17 00:00:00 2001
From: Prasad Mujumdar <prasadm@cloudera.com>
Date: Wed, 23 Jan 2013 00:14:56 -0800
Subject: [PATCH 037/121] CDH-9158: User-impersonation for HiveServer2

---
 .../java/org/apache/hadoop/hive/conf/HiveConf.java |    7 +-
 .../hive/service/auth/KerberosSaslHelper.java      |    4 +-
 .../apache/hive/service/auth/PlainSaslHelper.java  |    9 +++-
 .../hive/service/auth/TUGIContainingProcessor.java |   65 ++++++++++++++++++++
 .../hadoop/hive/shims/HadoopShimsSecure.java       |    4 +-
 .../org/apache/hadoop/hive/shims/HadoopShims.java  |    4 +-
 6 files changed, 84 insertions(+), 9 deletions(-)
 create mode 100644 service/src/java/org/apache/hive/service/auth/TUGIContainingProcessor.java

diff --git a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index f8f7d24..a4ddef7 100644
--- a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -677,10 +677,11 @@ public class HiveConf extends Configuration {
     HIVE_SERVER2_KERBEROS_PRINCIPAL("hive.server2.authentication.kerberos.principal", ""),
     HIVE_SERVER2_PLAIN_LDAP_URL("hive.server2.authentication.ldap.url", null),
     HIVE_SERVER2_PLAIN_LDAP_BASEDN("hive.server2.authentication.ldap.baseDN", null),
+    HIVE_SERVER2_KERBEROS_IMPERSONATION("hive.server2.enable.impersonation", false),
     HIVE_SERVER2_CUSTOM_AUTHENTICATION_CLASS("hive.server2.custom.authentication.class", null),
 
     HIVE_CONF_RESTRICTED_LIST("hive.conf.restricted.list", null),
-      
+
     // If this is set all move tasks at the end of a multi-insert query will only begin once all
     // outputs are ready
     HIVE_MULTI_INSERT_MOVE_TASKS_SHARE_DEPENDENCIES(
@@ -1042,7 +1043,7 @@ public class HiveConf extends Configuration {
     if (auxJars == null) {
       auxJars = this.get(ConfVars.HIVEAUXJARS.varname);
     }
-    
+
     // setup list of conf vars that are not allowed to change runtime
     String restrictListStr = this.get(ConfVars.HIVE_CONF_RESTRICTED_LIST.toString());
     if (restrictListStr != null) {
@@ -1053,7 +1054,7 @@ public class HiveConf extends Configuration {
     restrictList.add(ConfVars.HIVE_CONF_RESTRICTED_LIST.toString());
   }
 
-  
+
   /**
    * Apply system properties to this object if the property name is defined in ConfVars
    * and the value is non-null and not an empty string.
diff --git a/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java b/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java
index 379dafb..b8796fe 100644
--- a/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java
+++ b/src/service/src/java/org/apache/hive/service/auth/KerberosSaslHelper.java
@@ -21,6 +21,7 @@ import java.io.IOException;
 
 import javax.security.sasl.SaslException;
 
+import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hadoop.hive.shims.ShimLoader;
 import org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge;
 import org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge.Server;
@@ -46,7 +47,8 @@ public class KerberosSaslHelper {
     @Override
     public TProcessor getProcessor(TTransport trans) {
       TProcessor sqlProcessor = new TCLIService.Processor<Iface>(service);
-      return saslServer.wrapNonAssumingProcessor(sqlProcessor);
+      return service.getHiveConf().getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_KERBEROS_IMPERSONATION) ?
+          saslServer.wrapProcessor(sqlProcessor) : saslServer.wrapNonAssumingProcessor(sqlProcessor);
     }
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java b/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java
index 70934d7..8f2d6bb 100644
--- a/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java
+++ b/src/service/src/java/org/apache/hive/service/auth/PlainSaslHelper.java
@@ -28,6 +28,7 @@ import javax.security.auth.callback.UnsupportedCallbackException;
 import javax.security.sasl.AuthorizeCallback;
 import javax.security.sasl.SaslException;
 
+import org.apache.hadoop.hive.conf.HiveConf;
 import org.apache.hive.service.auth.PlainSaslServer.ExternalAuthenticationCallback;
 import org.apache.hive.service.auth.PlainSaslServer.SaslPlainProvider;
 import org.apache.hive.service.cli.thrift.TCLIService.Iface;
@@ -95,16 +96,22 @@ public class PlainSaslHelper {
 
   private static class SQLPlainProcessorFactory extends TProcessorFactory {
     private final ThriftCLIService service;
+    private final HiveConf conf;
+    private final boolean doAsEnabled;
+
     public SQLPlainProcessorFactory(ThriftCLIService service) {
       super(null);
       this.service = service;
+      this.conf = service.getHiveConf();
+      this.doAsEnabled = conf.getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_KERBEROS_IMPERSONATION);
     }
 
     // Note that we do not do this in KerberosSaslHelper because we get the ipaddress differently in case of Sasl.
     @Override
     public TProcessor getProcessor(TTransport trans) {
       // Note that we do not wrap the processor for kerberos. And handle it a bit differently.
-      return new TSetIpAddressProcessor<Iface>(service);
+      TProcessor baseProcessor = new TSetIpAddressProcessor<Iface>(service);
+      return doAsEnabled ? new TUGIContainingProcessor(baseProcessor, conf) : baseProcessor;
     }
   }
 
diff --git a/src/service/src/java/org/apache/hive/service/auth/TUGIContainingProcessor.java b/src/service/src/java/org/apache/hive/service/auth/TUGIContainingProcessor.java
new file mode 100644
index 0000000..12250ec
--- /dev/null
+++ b/src/service/src/java/org/apache/hive/service/auth/TUGIContainingProcessor.java
@@ -0,0 +1,65 @@
+package org.apache.hive.service.auth;
+
+import java.io.IOException;
+import java.security.PrivilegedExceptionAction;
+import java.util.ArrayList;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.hive.shims.HadoopShims;
+import org.apache.hadoop.hive.shims.ShimLoader;
+import org.apache.hadoop.security.UserGroupInformation;
+import org.apache.thrift.TException;
+import org.apache.thrift.TProcessor;
+import org.apache.thrift.protocol.TProtocol;
+import org.apache.thrift.transport.TSaslServerTransport;
+
+public class TUGIContainingProcessor implements TProcessor{
+
+  private final TProcessor wrapped;
+  private final HadoopShims shim;
+  private final boolean isFsCacheDisabled;
+
+  public TUGIContainingProcessor(TProcessor wrapped, Configuration conf) {
+    this.wrapped = wrapped;
+    this.isFsCacheDisabled = conf.getBoolean(String.format("fs.%s.impl.disable.cache",
+      FileSystem.getDefaultUri(conf).getScheme()), false);
+    this.shim = ShimLoader.getHadoopShims();
+  }
+
+  @Override
+  public boolean process(final TProtocol in, final TProtocol out) throws TException {
+    UserGroupInformation clientUgi = null;
+
+    try {
+      clientUgi = shim.createRemoteUser(((TSaslServerTransport)in.getTransport()).
+          getSaslServer().getAuthorizationID(), new ArrayList<String>());
+      return shim.doAs(clientUgi, new PrivilegedExceptionAction<Boolean>() {
+        public Boolean run() {
+          try {
+            return wrapped.process(in, out);
+          } catch (TException te) {
+            throw new RuntimeException(te);
+          }
+        }
+      });
+    }
+    catch (RuntimeException rte) {
+      if (rte.getCause() instanceof TException) {
+        throw (TException)rte.getCause();
+      }
+      throw rte;
+    } catch (InterruptedException ie) {
+      throw new RuntimeException(ie); // unexpected!
+    } catch (IOException ioe) {
+      throw new RuntimeException(ioe); // unexpected!
+    }
+    finally {
+      // cleanup the filesystem handles at the end if they are cached
+      // clientUgi will be null if createRemoteUser() fails
+      if (clientUgi != null && !isFsCacheDisabled) {
+        shim.closeAllForUGI(clientUgi);
+      }
+    }
+  }
+}
diff --git a/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java b/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
index 9959aca..f17b83e 100644
--- a/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
+++ b/src/shims/src/common-secure/java/org/apache/hadoop/hive/shims/HadoopShimsSecure.java
@@ -538,8 +538,8 @@ public abstract class HadoopShimsSecure implements HadoopShims {
   }
 
   @Override
-  public void doAs(UserGroupInformation ugi, PrivilegedExceptionAction<Void> pvea) throws IOException, InterruptedException {
-    ugi.doAs(pvea);
+  public <T> T doAs(UserGroupInformation ugi, PrivilegedExceptionAction<T> pvea) throws IOException, InterruptedException {
+    return ugi.doAs(pvea);
   }
 
   @Override
diff --git a/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java b/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
index e7d6619..9f6da62 100644
--- a/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
+++ b/src/shims/src/common/java/org/apache/hadoop/hive/shims/HadoopShims.java
@@ -192,15 +192,15 @@ public interface HadoopShims {
   public void closeAllForUGI(UserGroupInformation ugi);
 
   public UserGroupInformation getUGIForConf(Configuration conf) throws LoginException, IOException;
-
   /**
    * Used by metastore server to perform requested rpc in client context.
+   * @param <T>
    * @param ugi
    * @param pvea
    * @throws IOException
    * @throws InterruptedException
    */
-  public void doAs(UserGroupInformation ugi, PrivilegedExceptionAction<Void> pvea) throws
+  public <T> T doAs(UserGroupInformation ugi, PrivilegedExceptionAction<T> pvea) throws
     IOException, InterruptedException;
 
   /**
-- 
1.7.0.4

