From 87bf290eb819fa2e8b459ae4a7c03a138b77f1dd Mon Sep 17 00:00:00 2001
From: Johnny Zhang <xiaoyuz@cloudera>
Date: Fri, 26 Apr 2013 12:47:31 -0700
Subject: [PATCH 098/121] CDH-5841 Adapt HIVE-2670 for running e2e tests against CDH4

---
 build.xml                                    |   29 +
 e2e/build.xml                                |  198 +++++
 e2e/conf/default.conf                        |   64 ++
 e2e/conf/existing_deployer.conf              |   39 +
 e2e/conf/testpropertiesfile.conf             |   21 +
 e2e/deployers/HiveExistingClusterDeployer.pm |  325 ++++++++
 e2e/drivers/TestDriverHive.pm                |  383 ++++++++++
 e2e/drivers/TestDriverHiveCmdLine.pm         |  179 +++++
 e2e/drivers/Util.pm                          |  208 ++++++
 e2e/harness.tar                              |  Bin 0 -> 92160 bytes
 e2e/scripts/create_test_db.sql               |    5 +
 e2e/tests/cmdline.conf                       |   56 ++
 e2e/tests/nightly.conf                       | 1018 ++++++++++++++++++++++++++
 e2e/tools/generate/generate_data.pl          |  582 +++++++++++++++
 e2e/tools/test/floatpostprocessor.pl         |  111 +++
 15 files changed, 3218 insertions(+), 0 deletions(-)
 create mode 100644 e2e/build.xml
 create mode 100644 e2e/conf/default.conf
 create mode 100644 e2e/conf/existing_deployer.conf
 create mode 100644 e2e/conf/testpropertiesfile.conf
 create mode 100644 e2e/deployers/HiveExistingClusterDeployer.pm
 create mode 100644 e2e/drivers/TestDriverHive.pm
 create mode 100644 e2e/drivers/TestDriverHiveCmdLine.pm
 create mode 100644 e2e/drivers/Util.pm
 create mode 100644 e2e/harness.tar
 create mode 100644 e2e/scripts/create_test_db.sql
 create mode 100644 e2e/tests/cmdline.conf
 create mode 100644 e2e/tests/nightly.conf
 create mode 100644 e2e/tools/generate/generate_data.pl
 create mode 100644 e2e/tools/test/floatpostprocessor.pl

diff --git a/src/build.xml b/src/build.xml
index 048abc6..922ee23 100644
--- a/src/build.xml
+++ b/src/build.xml
@@ -85,6 +85,7 @@
   <property name="checkstyle.build.dir" location="${build.dir.hive}/checkstyle"/>
   <property name="rat.build.dir" location="${build.dir.hive}/rat"/>
   <property name="md5sum.format" value="{0}  {1}"/>
+  <property name="test.e2e.dir" value="${basedir}/e2e"/>
 
   <!-- Ignore Postgres upgrade scripts unless 'include.postgres' is true -->
   <condition property="metastore.excludes"
@@ -969,6 +970,34 @@
   </target>
 
   <!-- ================================================================== -->
+  <!-- test-e2e                                                         -->
+  <!-- ================================================================== -->
+
+  <target name="test-e2e-deploy">
+    <ant dir="${test.e2e.dir}" target="deploy"/>
+  </target>
+
+  <target name="test-e2e-deploy-local">
+    <ant dir="${test.e2e.dir}" target="deploy-local"/>
+  </target>
+
+  <target name="test-e2e-undeploy">
+    <ant dir="${test.e2e.dir}" target="undeploy"/>
+  </target>
+
+  <target name="test-e2e-undeploy-local">
+    <ant dir="${test.e2e.dir}" target="undeploy-local"/>
+  </target>
+
+  <target name="test-e2e-test">
+    <ant dir="${test.e2e.dir}" target="test"/>
+  </target>
+
+  <target name="test-e2e-test-local">
+    <ant dir="${test.e2e.dir}" target="test-local"/>
+  </target>
+
+  <!-- ================================================================== -->
   <!-- Findbugs                                                         -->
   <!-- ================================================================== -->
   
diff --git a/src/e2e/build.xml b/src/e2e/build.xml
new file mode 100644
index 0000000..8e9204e
--- /dev/null
+++ b/src/e2e/build.xml
@@ -0,0 +1,198 @@
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+
+<project name="TestHarnessHiveTests" default="test">
+
+  <property name="hive.dir" value="${basedir}/.."/>
+
+  <property name="tar.name" value="${basedir}/hivetests.tar"/>
+  <property name="tar.dir" value="${basedir}/tar"/>
+  <property name="test.src" value="${basedir}/tests"/>
+  <property name="driver.src" value="${basedir}/drivers"/>
+  <property name="deployer.src" value="${basedir}/deployers"/>
+  <property name="conf.src" value="${basedir}/conf"/>
+  <property name="tool.src" value="${basedir}/tools"/>
+
+  <property name="harness.dir" value="${basedir}"/>
+  <property name="harness.tar" value="${harness.dir}/harness.tar"/>
+
+  <property name="test.location" value="${basedir}/testdist"/>
+  <property name="benchmark.location" value="${test.location}/benchmarks"/>
+
+
+  <!-- Build an archive to use in the tests -->
+  <target name="tar" description="Create tar file with hive modules">
+    <mkdir dir="${tar.dir}"/>
+    <mkdir dir="${tar.dir}/tests"/>
+    <mkdir dir="${tar.dir}/drivers"/>
+    <mkdir dir="${tar.dir}/deployers"/>
+    <mkdir dir="${tar.dir}/conf"/>
+    <mkdir dir="${tar.dir}/libexec"/>
+
+    <copy todir="${tar.dir}/tests">
+        <fileset dir="${test.src}">
+        </fileset>
+    </copy>
+
+    <copy todir="${tar.dir}">
+      <fileset dir="${driver.src}">
+        <exclude name="TestDriverScript.pm"/>
+      </fileset>
+      <fileset dir="${deployer.src}"/>
+    </copy>
+
+
+    <copy todir="${tar.dir}/conf">
+      <fileset dir="${conf.src}"/>
+    </copy>
+
+    <copy todir="${tar.dir}/libexec">
+      <fileset dir="${tool.src}/test"/>
+      <fileset dir="${tool.src}/generate"/>
+    </copy>
+
+    <tar destfile="${tar.name}" basedir="${tar.dir}"/>
+  </target>
+
+  <!-- Check that the necessary properties are setup -->
+  <target name="property-check">
+    <fail message="Please set the property harness.hadoop.home to the path of your hadoop installation"
+      unless="harness.hadoop.home"/>
+  </target>
+
+  <!-- Prep the test area -->
+  <target name="init-test">
+    <mkdir dir="${test.location}"/>
+    <mkdir dir="${benchmark.location}"/>
+
+    <untar src="${tar.name}" dest="${test.location}"/>
+    <untar src="${harness.tar}" dest="${test.location}"/>
+
+    <chmod perm="ugo+x" type="file">
+      <fileset dir="${test.location}/libexec" />
+      <fileset file="${test.location}/test_harness.pl"/>
+    </chmod>
+
+  </target>
+
+
+  <!-- By default this runs in mapred mode on a cluster.  To run it in local
+  mode set -Dharness.exec.mode=local -->
+
+  <target name="test-base" depends="property-check, tar, init-test">
+    <!-- If they have not specified tests to run then null it out -->
+    <property name="tests.to.run" value=""/>
+    <property name="harness.hive.home" value="../../src/build/dist/"/>
+
+    <exec executable="./test_harness.pl" dir="${test.location}" failonerror="true">
+      <env key="HARNESS_ROOT" value="."/>
+      <env key="PH_LOCAL" value="."/>
+      <env key="PH_OUT" value="."/>
+      <env key="PH_ROOT" value="."/>
+      <env key="PH_METASTORE_HOST" value="${harness.metastore.host}"/>
+      <env key="PH_METASTORE_THRIFT" value="${harness.metastore.thrift}"/>
+      <env key="HADOOP_HOME" value="${harness.hadoop.home}"/>
+      <env key="PH_HIVE_HOME" value="${harness.hive.home}"/>
+      <arg line="${tests.to.run}"/>
+      <arg value="${test.location}/tests/nightly.conf"/>
+      <arg value="${test.location}/tests/cmdline.conf"/>
+    </exec>
+  </target>
+
+  <target name="test">
+    <antcall target="test-base">
+      <param name="harness.conf.file" value="${basedir}/conf/default.conf"/>
+    </antcall>
+  </target>
+
+  <target name="test-local">
+    <antcall target="test-base">
+      <param name="harness.conf.file" value="${basedir}/conf/local.conf"/>
+    </antcall>
+  </target>
+
+  <target name="deploy-base" depends="property-check, tar, init-test">
+    <exec executable="./test_harness.pl" dir="${test.location}" failonerror="true">
+      <env key="HARNESS_ROOT" value="."/>
+      <env key="PH_LOCAL" value="."/>
+      <env key="PH_OUT" value="."/>
+      <env key="PH_ROOT" value="."/>
+      <env key="PH_METASTORE_HOST" value="${harness.metastore.host}"/>
+      <env key="PH_METASTORE_THRIFT" value="${harness.metastore.thrift}"/>
+      <env key="PH_LOAD_HIVE_ONLY" value="${harness.load.hive.only}"/>
+      <env key="HADOOP_HOME" value="${harness.hadoop.home}"/>
+      <env key="PH_HIVE_HOME" value="${harness.hive.home}"/>
+
+      <arg value="-deploycfg"/>
+      <arg value="${deploy.conf}"/>
+      <arg value="${deploy.opt}"/>
+      <!-- Give a bogus test so it just does the deployment -->
+      <arg value="-t"/>
+      <arg value="NoSuchTest"/>
+      <arg value="${test.location}/tests/nightly.conf"/>
+    </exec>
+  </target>
+
+  <target name="deploy">
+    <antcall target="deploy-base">
+      <param name="deploy.opt" value="-deploy"/>
+      <param name="deploy.conf"
+        value="${test.location}/conf/existing_deployer.conf"/>
+      <param name="harness.conf.file" value="${basedir}/conf/default.conf"/>
+    </antcall>
+  </target>
+
+  <target name="undeploy">
+    <antcall target="deploy-base">
+      <param name="deploy.opt" value="-undeploy"/>
+      <param name="deploy.conf"
+        value="${test.location}/conf/existing_deployer.conf"/>
+      <param name="harness.conf.file" value="${basedir}/conf/default.conf"/>
+    </antcall>
+  </target>
+
+  <target name="deploy-local">
+    <antcall target="deploy-base">
+      <param name="deploy.opt" value="-deploy"/>
+      <param name="deploy.conf"
+        value="${test.location}/conf/local_deployer.conf"/>
+      <param name="harness.conf.file" value="${basedir}/conf/local.conf"/>
+    </antcall>
+  </target>
+
+  <target name="undeploy-local">
+    <antcall target="deploy-base">
+      <param name="deploy.opt" value="-undeploy"/>
+      <param name="deploy.conf"
+        value="${test.location}/conf/local_deployer.conf"/>
+      <param name="harness.conf.file" value="${basedir}/conf/local.conf"/>
+    </antcall>
+  </target>
+
+  <target name="deploy-test" depends="deploy, test"/>
+
+  <target name="deploy-test-undeploy" depends="deploy, test, undeploy"/>
+
+  <target name="clean">
+    <delete dir="${test.location}"/>
+    <delete file="${tar.name}"/>
+    <delete dir="${tar.dir}"/>
+  </target>
+
+</project>
+
+
diff --git a/src/e2e/conf/default.conf b/src/e2e/conf/default.conf
new file mode 100644
index 0000000..fd5a7cb
--- /dev/null
+++ b/src/e2e/conf/default.conf
@@ -0,0 +1,64 @@
+############################################################################           
+#  Licensed to the Apache Software Foundation (ASF) under one or more                  
+#  contributor license agreements.  See the NOTICE file distributed with               
+#  this work for additional information regarding copyright ownership.                 
+#  The ASF licenses this file to You under the Apache License, Version 2.0             
+#  (the "License"); you may not use this file except in compliance with                
+#  the License.  You may obtain a copy of the License at                               
+#                                                                                      
+#      http://www.apache.org/licenses/LICENSE-2.0                                      
+#                                                                                      
+#  Unless required by applicable law or agreed to in writing, software                 
+#  distributed under the License is distributed on an "AS IS" BASIS,                   
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.            
+#  See the License for the specific language governing permissions and                 
+#  limitations under the License.                                                      
+                                                                                       
+my $me = `whoami`;
+chomp $me;
+
+# The contents of this file can be rewritten to fit your installation.
+# Also, you can define the following environment variables and set things up as in the test setup
+# PH_ROOT           Root directory where test harness is installed
+# PH_LOCAL          Root directory for input and output for local mode tests
+# PH_OUT            Root directory where output data will be stored (on local disk, not HDFS)
+# PH_HOST           Host for the metadata server
+# PH_PORT           Port for the metadata server
+# PH_PASSWD         Password for the metadata db
+# PH_THRIFT         URI for metadata thrift server
+
+$cfg = {
+    #HIVE
+    'hive_data_dir'    => '/user/hive/tests/data',
+    'metastore_host'   => $ENV{'PH_METASTORE_HOST'},
+    'metastore_port'   => $ENV{'PH_METASTORE_PORT'},
+    'metastore_db'     => 'hivemetastoredb',
+    'metastore_driver' => 'com.mysql.jdbc.Driver',
+    'metastore_user'   => 'hive',
+    'metastore_passwd' => $ENV{'PH_METASTORE_PASSWD'},
+    'metastore_thrift' => $ENV{'PH_METASTORE_THRIFT'},
+    'hivehome'          => $ENV{'PH_HIVE_HOME'}
+
+   #LOCAL
+    , 'localinpathbase'   => "$ENV{PH_LOCAL}/in" 
+    , 'localoutpathbase'  => "$ENV{PH_LOCAL}/out/log" 
+    , 'localpathbase'     => "$ENV{PH_LOCAL}/out/hivetest/$me" 
+
+    #TEST
+    , 'benchmarkPath'    => "$ENV{PH_OUT}/benchmarks",
+    'resultsPath'        => "$ENV{PH_OUT}/results",
+
+    # TESTDB
+    'dbuser'         => 'hivetest',
+    'dbhost'         => 'localhost',
+    'dbpasswd'       => 'hivetest',
+    'dbdb'           => 'hivetestdb',
+
+    , 'userhomePath' => "$ENV{HOME}"
+    ,'local.bin'     => '/usr/bin'
+ 
+    ,'logDir'                => "$ENV{PH_OUT}/log" 
+    ,'propertiesFile'     => "./conf/testpropertiesfile.conf"
+    ,'harness.console.level' => 'ERROR'
+
+};
diff --git a/src/e2e/conf/existing_deployer.conf b/src/e2e/conf/existing_deployer.conf
new file mode 100644
index 0000000..d2971a2
--- /dev/null
+++ b/src/e2e/conf/existing_deployer.conf
@@ -0,0 +1,39 @@
+#!/usr/bin/env perl
+
+############################################################################ 
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+###############################################################################
+# Test for TestHarness itself.
+#
+#
+
+$cfg = {
+	'deployer' => 'HiveExistingClusterDeployer',
+	
+	# hadoop values
+	'hadoopconfdir'    => $ENV{'PH_CLUSTER_CONF'},
+	'hadoopbin'        => $ENV{'PH_CLUSTER_BIN'},
+    'load_hive_only'   => $ENV{'PH_LOAD_HIVE_ONLY'},
+    # generate values
+    'gentool' => './libexec/generate_data.pl',
+
+    # hive values
+}
+;
+
+
+
diff --git a/src/e2e/conf/testpropertiesfile.conf b/src/e2e/conf/testpropertiesfile.conf
new file mode 100644
index 0000000..42d0ef3
--- /dev/null
+++ b/src/e2e/conf/testpropertiesfile.conf
@@ -0,0 +1,21 @@
+############################################################################           
+#  Licensed to the Apache Software Foundation (ASF) under one or more                  
+#  contributor license agreements.  See the NOTICE file distributed with               
+#  this work for additional information regarding copyright ownership.                 
+#  The ASF licenses this file to You under the Apache License, Version 2.0             
+#  (the "License"); you may not use this file except in compliance with                
+#  the License.  You may obtain a copy of the License at                               
+#                                                                                      
+#      http://www.apache.org/licenses/LICENSE-2.0                                      
+#                                                                                      
+#  Unless required by applicable law or agreed to in writing, software                 
+#  distributed under the License is distributed on an "AS IS" BASIS,                   
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.            
+#  See the License for the specific language governing permissions and                 
+#  limitations under the License.                                                      
+                                                                                       
+$cfg = {
+     'harness.log'    => './out/harness.log'
+     ,'harness.log.level'    => 'DEBUG'
+     ,'harness.console.level'=> 'INFO'
+};
diff --git a/src/e2e/deployers/HiveExistingClusterDeployer.pm b/src/e2e/deployers/HiveExistingClusterDeployer.pm
new file mode 100644
index 0000000..a114ce2
--- /dev/null
+++ b/src/e2e/deployers/HiveExistingClusterDeployer.pm
@@ -0,0 +1,325 @@
+############################################################################           
+#  Licensed to the Apache Software Foundation (ASF) under one or more                  
+#  contributor license agreements.  See the NOTICE file distributed with               
+#  this work for additional information regarding copyright ownership.                 
+#  The ASF licenses this file to You under the Apache License, Version 2.0             
+#  (the "License"); you may not use this file except in compliance with                
+#  the License.  You may obtain a copy of the License at                               
+#                                                                                      
+#      http://www.apache.org/licenses/LICENSE-2.0                                      
+#                                                                                      
+#  Unless required by applicable law or agreed to in writing, software                 
+#  distributed under the License is distributed on an "AS IS" BASIS,                   
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.            
+#  See the License for the specific language governing permissions and                 
+#  limitations under the License.                                                      
+                                                                                       
+package HiveExistingClusterDeployer;
+
+use IPC::Run qw(run);
+use TestDeployer;
+use Util;
+
+use strict;
+use English;
+
+our @ISA = "TestDeployer";
+
+###########################################################################
+# Class: HiveExistingClusterDeployer
+# Deploy the Pig harness to a cluster and database that already exists.
+
+##############################################################################
+# Sub: new
+# Constructor
+#
+# Paramaters:
+# None
+#
+# Returns:
+# None.
+sub new
+{
+    my $proto = shift;
+    my $class = ref($proto) || $proto;
+    my $self = {};
+
+    bless($self, $class);
+
+    return $self;
+}
+
+##############################################################################
+# Sub: checkPrerequisites
+# Check any prerequisites before a deployment is begun.  For example if a 
+# particular deployment required the use of a database system it could
+# check here that the db was installed and accessible.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub checkPrerequisites
+{
+    my ($self, $cfg, $log) = @_;
+
+    if (! defined $ENV{'HADOOP_HOME'} || $ENV{'HADOOP_HOME'} eq "") {
+        print $log "You must set the environment variable HADOOP_HOME";
+        die "HADOOP_HOME not defined";
+    }
+
+    # Set up values for the metastore
+    Util::setupHiveProperties($cfg, $log);
+    # Run a quick and easy Hadoop command to make sure we can
+    Util::runHadoopCmd($cfg, $log, "fs -ls /");
+
+}
+
+##############################################################################
+# Sub: deploy
+# Deploy any required packages
+# This is a no-op in this case because we're assuming both the cluster and the
+# database already exist
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub deploy
+{
+}
+
+##############################################################################
+# Sub: start
+# Start any software modules that are needed.
+# This is a no-op in this case because we're assuming both the cluster and the
+# database already exist
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub start
+{
+}
+
+##############################################################################
+# Sub: generateData
+# Generate any data needed for this test run.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub generateData
+{
+    my ($self, $cfg, $log) = @_;
+    my @tables = (
+        {
+            'name' => "studenttab10k",
+            'filetype' => "studenttab",
+            'rows' => 10000,
+            'hdfs' => "studenttab10k",
+        }, {
+            'name' => "votertab10k",
+            'filetype' => "votertab",
+            'rows' => 10000,
+            'hdfs' => "votertab10k",
+        }, {
+            'name' => "studentparttab30k",
+            'filetype' => "studentparttab",
+            'rows' => 10000,
+            'hdfs' => "studentparttab30k",
+            'partitions' => ['20110924', '20110925', '20110926']
+        },{
+            'name' => "studentnull10k",
+            'filetype' => "studentnull",
+            'rows' => 10000,
+            'hdfs' => "studentnull10k",
+        },{
+            'name' => "all100k",
+            'filetype' => "allscalars",
+            'rows' => 100000,
+            'hdfs' => "all100k",
+        }
+    );
+
+    
+    if (defined($cfg->{'load_hive_only'}) && $cfg->{'load_hive_only'} == 1) {
+        return $self->hiveMetaOnly($cfg, $log, \@tables);
+    }
+
+    # Create the HDFS directories
+    Util::runHadoopCmd($cfg, $log, "fs -mkdir $cfg->{'hive_data_dir'}");
+
+    foreach my $table (@tables) {
+        print "Generating data for $table->{'name'}\n";
+        # Generate the data
+        my @cmd = ($cfg->{'gentool'}, $table->{'filetype'}, $table->{'rows'},
+            $table->{'name'}, $cfg->{'hive_data_dir'});
+        $self->runCmd($log, \@cmd);
+
+        # Copy the data to HDFS
+        my $hadoop = "fs -mkdir $cfg->{'hive_data_dir'}/$table->{'hdfs'}";
+        Util::runHadoopCmd($cfg, $log, $hadoop);
+
+        if (defined($table->{'partitions'})) {
+            foreach my $part (@{$table->{'partitions'}}) {
+                my $hadoop = "fs -mkdir
+                    $cfg->{'hive_data_dir'}/$table->{'hdfs'}/$table->{'name'}.$part";
+                Util::runHadoopCmd($cfg, $log, $hadoop);
+                my $hadoop = "fs -copyFromLocal $table->{'name'}.$part " .
+                    "$cfg->{'hive_data_dir'}/$table->{'hdfs'}/$table->{'name'}.$part/$table->{'name'}.$part";
+                Util::runHadoopCmd($cfg, $log, $hadoop);
+            }
+        } else {
+            my $hadoop = "fs -copyFromLocal $table->{'name'} ".
+                "$cfg->{'hive_data_dir'}/$table->{'hdfs'}/$table->{'name'}";
+            Util::runHadoopCmd($cfg, $log, $hadoop);
+        }
+
+        print "Loading data into Hive for $table->{'name'}\n";
+        Util::runHiveCmdFromFile($cfg, $log,
+            "./" . $table->{'name'} .  ".hive.sql");
+
+        print "Loading data into MySQL for $table->{'name'}\n";
+        Util::runDbCmd($cfg, $log, $table->{'name'} . ".mysql.sql");
+    }
+
+}
+
+###########################################################################
+# Sub: hiveMetaOnly                                                        
+# Load metadata into Hive, but don't load Mysql or HDFS, as we assume      
+# these have already been loaded.                                          
+#                                                                          
+# Paramaters:                                                              
+# cfg - hash from config file, including deployment config                 
+# log - log file handle                                                    
+#                                                                          
+# Returns:                                                                 
+# None                                                                     
+#                                                                          
+sub hiveMetaOnly
+{
+    my ($self, $cfg, $log, $tables) = @_;
+    foreach my $table (@{$tables}) {
+        print "Generating data for $table->{'name'}\n";
+        # Generate the data
+        my @cmd = ($cfg->{'gentool'}, $table->{'filetype'}, $table->{'rows'},
+            $table->{'name'}, $cfg->{'hive_data_dir'});
+        $self->runCmd($log, \@cmd);
+
+        print "Loading data into Hive for $table->{'name'}\n";
+        Util::runHiveCmdFromFile($cfg, $log, "./" . $table->{'name'} .
+             ".hive.sql");
+    }
+}
+
+##############################################################################
+# Sub: confirmDeployment
+# Run checks to confirm that the deployment was successful.  When this is 
+# done the testing environment should be ready to run.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# Nothing
+# This method should die with an appropriate error message if there is 
+# an issue.
+#
+sub confirmDeployment
+{
+}
+
+##############################################################################
+# Sub: deleteData
+# Remove any data created that will not be removed by undeploying.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub deleteData
+{
+}
+
+##############################################################################
+# Sub: stop
+# Stop any servers or systems that are no longer needed once testing is
+# completed.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub stop
+{
+}
+
+##############################################################################
+# Sub: undeploy
+# Remove any packages that were installed as part of the deployment.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# None
+#
+sub undeploy
+{
+}
+
+##############################################################################
+# Sub: confirmUndeployment
+# Run checks to confirm that the undeployment was successful.  When this is 
+# done anything that must be turned off or removed should be turned off or
+# removed.
+#
+# Paramaters:
+# globalHash - hash from config file, including deployment config
+# log - log file handle
+#
+# Returns:
+# Nothing
+# This method should die with an appropriate error message if there is 
+# an issue.
+#
+sub confirmUndeployment
+{
+    die "$0 INFO : confirmUndeployment is a virtual function!";
+}
+
+sub runCmd($$$)
+{
+    my ($self, $log, $cmd) = @_;
+
+    print $log "Going to run [" . join(" ", @$cmd) . "]\n";
+
+    run($cmd, \undef, $log, $log) or
+        die "Failed running " . join(" ", @$cmd) . "\n";
+}
+
+1;
diff --git a/src/e2e/drivers/TestDriverHive.pm b/src/e2e/drivers/TestDriverHive.pm
new file mode 100644
index 0000000..b1d50ec
--- /dev/null
+++ b/src/e2e/drivers/TestDriverHive.pm
@@ -0,0 +1,383 @@
+package TestDriverHive;
+
+############################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+###############################################################################
+# Test driver for hive nightly tests.
+# 
+#
+
+use TestDriver;
+use IPC::Run; # don't do qw(run), it screws up TestDriver which also has a run method
+use Digest::MD5 qw(md5_hex);
+use Util;
+use File::Path;
+use Cwd;
+
+use strict;
+use English;
+
+our $className= "TestDriver";
+our @ISA = "$className";
+our $ROOT = (defined $ENV{'HARNESS_ROOT'} ? $ENV{'HARNESS_ROOT'} : die "ERROR: You must set environment variable HARNESS_ROOT\n");
+our $toolpath = "$ROOT/libexec";
+
+my $passedStr  = 'passed';
+my $failedStr  = 'failed';
+my $abortedStr = 'aborted';
+my $skippedStr = 'skipped';
+my $dependStr  = 'failed_dependency';
+
+sub new
+{
+    # Call our parent
+    my ($proto) = @_;
+    my $class = ref($proto) || $proto;
+    my $self = $class->SUPER::new;
+
+    bless($self, $class);
+    return $self;
+}
+
+sub replaceParameters
+{
+##!!! Move this to Util.pm
+
+    my ($self, $cmd, $outfile, $testCmd, $log) = @_;
+
+    # $self
+    $cmd =~ s/:LATESTOUTPUTPATH:/$self->{'latestoutputpath'}/g;
+
+    # $outfile
+    $cmd =~ s/:OUTPATH:/$outfile/g;
+
+    # $ENV
+    $cmd =~ s/:HARNESS:/$ENV{HARNESS_ROOT}/g;
+
+    # $testCmd
+    $cmd =~ s/:INPATH:/$testCmd->{'inpathbase'}/g;
+
+    return $cmd;
+}
+
+sub globalSetup
+{
+    my ($self, $globalHash, $log) = @_;
+    my $subName = (caller(0))[3];
+
+    # Set up values for the metastore
+    Util::setupHiveProperties($globalHash, $log);
+
+    # Setup the output path
+    my $me = `whoami`;
+    chomp $me;
+    $globalHash->{'runid'} = $me . "." . time;
+
+    $globalHash->{'localpath'} = $globalHash->{'localpathbase'} . "/" . $globalHash->{'runid'} . "/";
+
+    IPC::Run::run(['mkdir', '-p', $globalHash->{'localpath'}], \undef, $log, $log) or 
+        die "Cannot create localpath directory " . $globalHash->{'localpath'} .
+        " " . "$ERRNO\n";
+
+    IPC::Run::run(['mkdir', '-p', $globalHash->{'benchmarkPath'}], \undef, $log, $log) or 
+        die "Cannot create benchmark directory " .  $globalHash->{'benchmarkPath'} .
+        " " . "$ERRNO\n";
+
+    $globalHash->{'thisResultsPath'} = $globalHash->{'localpath'} . "/"
+        . $globalHash->{'resultsPath'};
+    IPC::Run::run(['mkdir', '-p', $globalHash->{'thisResultsPath'}], \undef, $log, $log) or 
+        die "Cannot create results directory " .  $globalHash->{'thisResultsPath'} .
+        " " . "$ERRNO\n";
+}
+
+sub globalCleanup
+{
+    my ($self, $globalHash, $log) = @_;
+}
+
+
+sub runTest
+{
+    my ($self, $testCmd, $log) = @_;
+
+    my %result;
+
+    my @hivefiles = ();
+    my @outfiles = ();
+    # Write the hive script to a file.
+    $hivefiles[0] = $testCmd->{'localpath'} . $testCmd->{'group'} . "_" .
+        $testCmd->{'num'} . ".0.sql";
+    $outfiles[0] = $testCmd->{'thisResultsPath'} . "/" . $testCmd->{'group'} .
+        "_" .  $testCmd->{'num'} . ".0.out";
+
+    open(FH, "> $hivefiles[0]") or
+        die "Unable to open file $hivefiles[0] to write SQL script, $ERRNO\n";
+    print FH $testCmd->{'sql'} . "\n";
+    close(FH);
+
+    # If the results are written to a table run the command and then 
+    # run a another Hive command to dump the results of the table.
+    if (defined($testCmd->{'result_table'})) {
+        Util::runHiveCmdFromFile($testCmd, $log, $hivefiles[0]);
+        $result{'rc'} = $? >> 8;
+
+        my @results = ();
+        if (ref($testCmd->{'result_table'}) ne 'ARRAY') {
+            $results[0] = $testCmd->{'result_table'};
+        } else {
+            @results = @{$testCmd->{'result_table'}};
+        }
+        for (my $i = 0; $i < @results; $i++) {
+            $hivefiles[$i] = $testCmd->{'localpath'} .
+                $testCmd->{'group'} . "_" .  $testCmd->{'num'} .
+                ".dumptable.$i.sql";
+            $outfiles[$i] = $testCmd->{'thisResultsPath'} . "/" .
+                $testCmd->{'group'} .  "_" .  $testCmd->{'num'} . ".$i.out";
+            open(FH, "> $hivefiles[$i]") or
+                die "Unable to open file $hivefiles[$i] to write SQL " .
+                    "script, $ERRNO\n";
+            print FH "select * from " . $results[$i] .  ";\n";
+            close(FH);
+        }
+    }
+
+    my @originalOutputs = ();
+    my @outputs = ();
+    $result{'originalOutput'} = \@originalOutputs;
+    $result{'output'} = \@outputs;
+
+    for (my $i = 0; $i < @hivefiles; $i++) {
+        my $outfp;
+        open($outfp, "> $outfiles[$i]") or
+            die "Unable to open output file $outfiles[$i], $!\n";
+
+        Util::runHiveCmdFromFile($testCmd, $log, $hivefiles[$i], $outfp);
+
+        # Don't overwrite rc if we set it above
+        $result{'rc'} = $? >> 8 unless defined $result{'rc'};
+        close($outfp);
+
+        $originalOutputs[$i] = $outfiles[$i];
+        $outputs[$i] = 
+            $self->postProcessSingleOutputFile($outfiles[$i], $testCmd, $log);
+    }
+
+    # Compare doesn't get the testCmd hash, so I need to stuff the necessary
+    # info about sorting into the result.
+    if (defined $testCmd->{'sortArgs'} && $testCmd->{'sortArgs'}) {
+        $result{'sortArgs'} = $testCmd->{'sortArgs'};
+    }
+
+    return \%result;
+}
+
+
+
+sub generateBenchmark
+{
+    my ($self, $testCmd, $log) = @_;
+
+    my %result;
+
+    # Write the SQL to a file.
+    my @verifies = ();
+    if (defined $testCmd->{'verify_sql'}) {
+        if (ref($testCmd->{'verify_sql'}) eq "ARRAY") {
+            @verifies = @{$testCmd->{'verify_sql'}};
+        } else {
+            $verifies[0] = $testCmd->{'verify_sql'};
+        }
+    } else {
+        $verifies[0] = $testCmd->{'sql'};
+    }
+
+    my @rcs = ();
+    $result{'rc'} = \@rcs;
+    my @outputs = ();
+    $result{'output'} = \@outputs;
+    for (my $i = 0; $i < @verifies; $i++) {
+        my $sqlfile = $testCmd->{'localpath'} . $testCmd->{'group'} . "_" .
+            $testCmd->{'num'} . ".benchmark.$i.sql";
+        my $outfile = $testCmd->{'benchmarkPath'} . "/" .
+            $testCmd->{'group'} .  "_" .  $testCmd->{'num'} .
+            ".benchmark.$i.out";
+
+        open(FH, "> $sqlfile") or
+            die "Unable to open file $sqlfile to write SQL script, $ERRNO\n";
+        print FH $verifies[$i];
+        close(FH);
+
+        my $outfp;
+        open($outfp, "> $outfile") or
+            die "Unable to open output file $outfile, $!\n";
+
+        Util::runDbCmd($testCmd, $log, $sqlfile, $outfp);
+        $rcs[$i] =  $? >> 8;
+        close($outfp);
+
+        $outputs[$i] = 
+            $self->postProcessSingleOutputFile($outfile, $testCmd, $log, 1);
+    }
+
+    return \%result;
+}
+
+sub compare
+{
+    my ($self, $testResult, $benchmarkResult, $log, $testCmd) = @_;
+
+    # Make sure we have the same number of results from runTest and
+    # generateBenchmark
+    if (scalar(@{$testResult->{'output'}}) != 
+            scalar(@{$benchmarkResult->{'output'}})) {
+        die "runTest returned " .  scalar(@{$testResult->{'output'}}) .
+            " results, but generateBenchmark returned " .
+            scalar(@{$benchmarkResult->{'output'}}) . "\n";
+    }
+
+    my $totalFailures = 0;
+    for (my $i = 0; $i < @{$testResult->{'output'}}; $i++) {
+        # cksum the the two files to see if they are the same
+        my ($testChksm, $benchmarkChksm);
+        IPC::Run::run((['cat', @{$testResult->{'output'}}[$i]], '|',
+            ['cksum']), \$testChksm, $log) or
+            die "$0: error: cannot run cksum on test results\n";
+        IPC::Run::run((['cat', @{$benchmarkResult->{'output'}}[$i]], '|',
+            ['cksum']), \$benchmarkChksm, $log) or
+            die "$0: error: cannot run cksum on benchmark\n";
+
+        chomp $testChksm;
+        chomp $benchmarkChksm;
+        print $log
+            "test cksum: $testChksm\nbenchmark cksum: $benchmarkChksm\n";
+
+        if ($testChksm ne $benchmarkChksm) {
+            print $log "Test output $i checksum does not match benchmark " .
+                "checksum\n";
+            print $log "Test $i checksum = <$testChksm>\n";
+            print $log "Expected $i checksum = <$benchmarkChksm>\n";
+            print $log "RESULTS DIFFER: vimdiff " . cwd .
+                "/" . @{$testResult->{'output'}}[$i] . " " . cwd .
+                "/" . @{$benchmarkResult->{'output'}}[$i] . "\n";
+            $totalFailures++;
+        }
+
+        # Now, check if the sort order is specified
+        if (defined($testResult->{'sortArgs'})) {
+            my @sortChk = ('sort', '-cs');
+            push(@sortChk, @{$testResult->{'sortArgs'}});
+            push(@sortChk, @{$testResult->{'originalOutput'}}[$i]);
+            print $log "Going to run sort check command: " .
+                join(" ", @sortChk) . "\n";
+            IPC::Run::run(\@sortChk, \undef, $log, $log);
+            my $sortrc = $?;
+            if ($sortrc) {
+                print $log "Sort check failed\n";
+                $totalFailures++;
+            }
+        }
+    }
+
+    return $totalFailures == 0;
+}
+
+sub postProcessSingleOutputFile
+{
+    my ($self, $outfile, $testCmd, $log, $isBenchmark) = @_;
+
+    # If requested, process the data to smooth over floating point
+    # differences.
+    if (defined $testCmd->{'floatpostprocess'} &&
+            defined $testCmd->{'delimiter'}) {
+        # Move the file to a temp file and run through the pre-processor.
+        my $tmpfile = "$outfile.tmp";
+        link($outfile, $tmpfile) or
+            die "Unable to create temporary file $tmpfile, $!\n";
+        unlink($outfile) or
+            die "Unable to unlink file $outfile, $!\n";
+        open(IFH, "< $tmpfile") or
+            die "Unable to open file $tmpfile, $!\n";
+        open(OFH, "> $outfile") or
+            die "Unable to open file $outfile, $!\n";
+        my @cmd = ("$toolpath/floatpostprocessor.pl",
+            $testCmd->{'delimiter'});
+        print $log "Going to run [" . join(" ", @cmd) . "]\n";
+        IPC::Run::run(\@cmd, \*IFH, \*OFH, $log) or 
+            die "Failed to run float postprocessor, $!\n"; 
+        close(IFH);
+        close(OFH);
+        unlink($tmpfile);
+    }
+
+    if ($isBenchmark && defined $testCmd->{'nullpostprocess'}) {
+        # Move the file to a temp file and run through the pre-processor.
+        my $tmpfile = "$outfile.tmp";
+        link($outfile, $tmpfile) or
+            die "Unable to create temporary file $tmpfile, $!\n";
+        unlink($outfile) or
+            die "Unable to unlink file $outfile, $!\n";
+        open(IFH, "< $tmpfile") or
+            die "Unable to open file $tmpfile, $!\n";
+        open(OFH, "> $outfile") or
+            die "Unable to open file $outfile, $!\n";
+        my @cmd = ("sed", "s/NULL//g");
+        print $log "Going to run [" . join(" ", @cmd) . "]\n";
+        IPC::Run::run(\@cmd, \*IFH, \*OFH, $log) or 
+            die "Failed to run float postprocessor, $!\n"; 
+        close(IFH);
+        close(OFH);
+        unlink($tmpfile);
+    }
+
+    # Sort the results for the benchmark compare.
+    my $sortfile = "$outfile.sorted";
+    my @cmd = ("sort", $outfile);
+    print $log "Going to run [" . join(" ", @cmd) . "]\n";
+    IPC::Run::run(\@cmd, '>', "$sortfile");
+
+    return $sortfile;
+}
+
+
+
+##############################################################################
+# Count the number of stores in a Pig Latin script, so we know how many files
+# we need to compare.
+#
+sub countStores($$)
+{
+    my ($self, $testCmd) = @_;
+
+    # Special work around for queries with more than one store that are not
+    # actually multiqueries.
+    if (defined $testCmd->{'notmq'}) {
+        return 1;
+    }
+
+    my $count;
+
+    # hope they don't have more than store per line
+    # also note that this won't work if you comment out a store
+    my @q = split(/\n/, $testCmd->{'hive'});
+        for (my $i = 0; $i < @q; $i++) {
+            $count += $q[$i] =~ /store\s+[a-zA-Z][a-zA-Z0-9_]*\s+into/i;
+    }
+
+    return $count;
+}
+
+1;
diff --git a/src/e2e/drivers/TestDriverHiveCmdLine.pm b/src/e2e/drivers/TestDriverHiveCmdLine.pm
new file mode 100644
index 0000000..72980d0
--- /dev/null
+++ b/src/e2e/drivers/TestDriverHiveCmdLine.pm
@@ -0,0 +1,179 @@
+package TestDriverHiveCmdLine;
+
+############################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+###############################################################################
+# Test driver for hive nightly tests.
+# 
+#
+
+use TestDriverHive;
+use IPC::Run; # don't do qw(run), it screws up TestDriver which also has a run method
+use Util;
+use File::Path;
+use Cwd;
+
+use strict;
+use English;
+
+our $className= "TestDriverHive";
+our @ISA = "$className";
+
+sub new
+{
+    # Call our parent
+    my ($proto) = @_;
+    my $class = ref($proto) || $proto;
+    my $self = $class->SUPER::new;
+
+    bless($self, $class);
+    return $self;
+}
+
+sub runTest
+{
+    my ($self, $testCmd, $log) = @_;
+
+    my %result;
+
+    my ($stdout, $stderr);
+
+    # If they provided a hive script in 'sql', write it to a file.
+    my $hivefile = undef;
+    if (defined($testCmd->{'sql'})) {
+        $hivefile = $testCmd->{'localpath'} . $testCmd->{'group'} . "_" .
+            $testCmd->{'num'} . ".sql";
+
+        open(FH, "> $hivefile") or
+            die "Unable to open file $hivefile to write SQL script, $ERRNO\n";
+        print FH $testCmd->{'sql'} . "\n";
+        close(FH);
+    }
+    Util::runHiveCmdFromFile($testCmd, $log, $hivefile, \$stdout, \$stderr, 1);
+    $result{'rc'} = $? >> 8;
+
+    $result{'stdout'} = $stdout;
+    $result{'stderr'} = $stderr;
+
+    return \%result;
+}
+
+
+
+sub generateBenchmark
+{
+    # Intentionally empty
+}
+
+sub compare
+{
+    my ($self, $testResult, $benchmarkResult, $log, $testCmd) = @_;
+
+    my $result = 1;  # until proven wrong...
+
+    # Return Code
+    if (defined $testCmd->{'rc'}) {
+        if ((! defined $testResult->{'rc'}) ||
+                ($testResult->{'rc'} != $testCmd->{'rc'})) {
+            print $log "Check failed: rc = <" . $testCmd->{'rc'} .
+                "> expected, test returned rc = <" . $testResult->{'rc'}
+                . ">\n";
+            $result = 0;
+        }
+    }
+
+    # Standard Out
+    if (defined $testCmd->{'expected_out'}) {
+        if ($testResult->{'stdout'} ne $testCmd->{'expected_out'}) {
+            print $log "Check failed: exact match of <" .
+                $testCmd->{'expected_out'} .
+                "> expected in stdout:<" . $testResult->{'stdout'} 
+                . ">\n";
+            $result = 0;
+        }
+    }
+
+    if (defined $testCmd->{'not_expected_out'}) {
+        if ($testResult->{'stdout'} eq $testCmd->{'not_expected_out'}) {
+            print $log "Check failed: NON-match of <" .
+                $testCmd->{'expected_out'} . "> expected to stdout:<" .
+                $testResult->{'stdout'} . ">\n";
+            $result = 0;
+        }
+    }
+
+    if (defined $testCmd->{'expected_out_regex'}) {
+        if ($testResult->{'stdout'} !~ $testCmd->{'expected_out_regex'}) {
+            print $log "Check failed: regex match of <" . 
+                $testCmd->{'expected_out_regex'} . "> expected in stdout:<" .
+                $testResult->{'stdout'} . ">\n";
+            $result = 0;
+        }
+    }
+
+    if (defined $testCmd->{'not_expected_out_regex'}) {
+        if ($testResult->{'stdout'} =~ $testCmd->{'not_expected_out_regex'}) {
+            print $log "Check failed: regex NON-match of <" . 
+                $testCmd->{'not_expected_out_regex'} .
+                "> expected in stdout:<" . $testResult->{'stdout'} . ">\n";
+            $result = 0;
+        }
+    }
+
+    # Standard Error
+    if (defined $testCmd->{'expected_err'}) {
+        if ($testResult->{'stderr'} ne $testCmd->{'expected_err'}) {
+            print $log "Check failed: exact match of <" .
+                $testCmd->{'expected_err'} .
+                "> expected in stderr:<" . $testResult->{'stderr'} 
+                . ">\n";
+            $result = 0;
+        }
+    }
+
+    if (defined $testCmd->{'not_expected_err'}) {
+        if ($testResult->{'stderr'} eq $testCmd->{'not_expected_err'}) {
+            print $log "Check failed: NON-match of <" .
+                $testCmd->{'expected_err'} . "> expected to stderr:<" .
+                $testResult->{'stderr'} . ">\n";
+            $result = 0;
+        }
+    }
+
+    if (defined $testCmd->{'expected_err_regex'}) {
+        if ($testResult->{'stderr'} !~ $testCmd->{'expected_err_regex'}) {
+            print $log "Check failed: regex match of <" . 
+                $testCmd->{'expected_err_regex'} . "> expected in stderr:<" .
+                $testResult->{'stderr'} . ">\n";
+            $result = 0;
+        }
+    }
+
+    if (defined $testCmd->{'not_expected_err_regex'}) {
+        if ($testResult->{'stderr'} =~ $testCmd->{'not_expected_err_regex'}) {
+            print $log "Check failed: regex NON-match of <" . 
+                $testCmd->{'not_expected_err_regex'} .
+                "> expected in stderr:<" . $testResult->{'stderr'} . ">\n";
+            $result = 0;
+        }
+    }
+
+
+  return $result;
+}
+
+1;
diff --git a/src/e2e/drivers/Util.pm b/src/e2e/drivers/Util.pm
new file mode 100644
index 0000000..9217fc9
--- /dev/null
+++ b/src/e2e/drivers/Util.pm
@@ -0,0 +1,208 @@
+#!/usr/bin/env perl 
+
+############################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+ 
+
+###########################################################################
+# Class: Util
+#
+# A collection of  helper subroutines.
+#
+
+
+package Util;
+
+use IPC::Run qw(run);
+use strict;
+
+##############################################################################
+#  Sub: setupHiveProperties
+#
+#  Assure that necessary values are set in config in order to set Hive
+#  Java properties.
+# 
+#  Returns:
+#  Nothing
+sub  setupHiveProperties($$)
+{
+    my ($cfg, $log) = @_;
+
+    # Set up values for the metastore
+    if (defined($cfg->{'metastore_thrift'}) && $cfg->{'metastore_thrift'} == 1) {
+        if (! defined $cfg->{'metastore_host'} || $cfg->{'metastore_host'} eq "") {
+            print $log "When using thrift, you must set the key " .
+                " 'metastore_host' to the machine your metastore is on\n";
+            die "metastore_host is not set in existing.conf\n";
+        }
+
+        $cfg->{'metastore_connection'} =
+            "jdbc:$cfg->{'metastore_db'}://$cfg->{'metastore_host'}/hivemetastoredb?createDatabaseIfNotExist=true";
+    
+        if (! defined $cfg->{'metastore_passwd'} || $cfg->{'metastore_passwd'} eq "") {
+            $cfg->{'metastore_passwd'} = 'hive';
+        }
+
+        if (! defined $cfg->{'metastore_port'} || $cfg->{'metastore_port'} eq "") {
+            $cfg->{'metastore_port'} = '9933';
+        }
+
+        $cfg->{'metastore_uri'} =
+            "thrift://$cfg->{'metastore_host'}:$cfg->{'metastore_port'}";
+    } else {
+        $cfg->{'metastore_connection'} =
+            "jdbc:derby:;databaseName=metastore_db;create=true";
+        $cfg->{'metastore_driver'} = "org.apache.derby.jdbc.EmbeddedDriver";
+    }
+}
+
+##############################################################################
+#  Sub: runHiveCmdFromFile
+#
+#  Run the provided file using the Hive command line.
+# 
+#  cfg - The configuration file for the test
+#  log - reference to the log file, should be an open file pointer
+#  sql - name of file containing SQL to run.  Optional, if present -f $sql
+#    will be appended to the command.
+#  outfile - open file pointer (or variable reference) to write stdout to for
+#    this test.  Optional, will be written to $log if this value is not
+#    provided.
+#  outfile - open file pointer (or variable reference) to write stderr to for
+#    this test.  Optional, will be written to $log if this value is not
+#    provided.
+#  noFailOnFail - if true, do not fail when the Hive command returns non-zero
+#    value.
+#  Returns:
+#  Nothing
+sub runHiveCmdFromFile($$;$$$$)
+{
+    my ($cfg, $log, $sql, $outfile, $errfile, $noFailOnFail) = @_;
+
+    if (!defined($ENV{'HADOOP_HOME'})) {
+        die "Cannot run hive when HADOOP_HOME environment variable is not set.";
+    }
+
+    $outfile = $log if (!defined($outfile));
+    $errfile = $log if (!defined($errfile));
+
+    my @cmd;
+    if (defined($sql)) {
+        @cmd = ("$cfg->{'hivehome'}/bin/hive", "-f", $sql);
+    } else {
+        @cmd = ("$cfg->{'hivehome'}/bin/hive");
+    }
+
+    # Add all of the modified properties we want to set
+    push(@cmd,
+        ("--hiveconf", "javax.jdo.option.ConnectionURL=$cfg->{'metastore_connection'}",
+         "--hiveconf", "javax.jdo.option.ConnectionDriverName=$cfg->{'metastore_driver'}"));
+
+    if (defined($cfg->{'metastore_thrift'}) && $cfg->{'metastore_thrift'} == 1) {
+        push(@cmd,
+            ("--hiveconf", "hive.metastore.local=false",
+             "--hiveconf", "hive.metastore.uris=thrift://$cfg->{'metastore_host'}:$cfg->{'metastore_port'}",
+             "--hiveconf", "javax.jdo.option.ConnectionPassword=$cfg->{'metastore_passwd'}"));
+    }
+
+    if (defined($cfg->{'additionaljarspath'})) {
+        $ENV{'HIVE_AUX_JARS_PATH'} = $cfg->{'additionaljarspath'};
+    }
+
+    if (defined($cfg->{'hiveconf'})) {
+        foreach my $hc (@{$cfg->{'hiveconf'}}) {
+            push(@cmd, "--hiveconf", $hc);
+        }
+    }
+
+    if (defined($cfg->{'hivecmdargs'})) {
+        push(@cmd, @{$cfg->{'hivecmdargs'}});
+    }
+
+    if (defined($cfg->{'hiveops'})) {
+        $ENV{'HIVE_OPTS'} = join(" ", @{$cfg->{'hiveops'}});
+    }
+
+    $ENV{'HIVE_HOME'} = $cfg->{'hivehome'};
+
+    my $envStr;
+    for my $k (keys(%ENV)) {
+        $envStr .= $k . "=" . $ENV{$k} . " " if ($k =~ /HADOOP/ || $k =~ /HIVE/);
+    }
+    $envStr .= " ";
+    print $log "Going to run hive command [" . join(" ", @cmd) .
+        "] with environment set to [$envStr]\n";
+    my $runrc = run(\@cmd, \undef, $outfile, $errfile);
+    my $rc = $? >> 8;
+
+    return $runrc if $runrc; # success
+
+    if (defined($noFailOnFail) && $noFailOnFail) {
+        return $rc;
+    } else {
+        die "Failed running hive command [" . join(" ", @cmd) . "]\n";
+    }
+}
+
+##############################################################################
+#  Sub: runHadoopCmd
+#
+#  Run the provided hadoop command
+# 
+#  Returns:
+#  Nothing
+sub runHadoopCmd($$$)
+{
+    my ($cfg, $log, $c) = @_;
+
+    my @cmd = ("$ENV{'HADOOP_HOME'}/bin/hadoop");
+    push(@cmd, split(' ', $c));
+
+    print $log "Going to run [" . join(" ", @cmd) . "]\n";
+
+    run(\@cmd, \undef, $log, $log) or
+        die "Failed running " . join(" ", @cmd) . "\n";
+}
+
+##############################################################################
+#  Sub: runDbCmd
+#
+#  Run the provided mysql command
+# 
+#  Returns:
+#  Nothing
+sub runDbCmd($$$;$)
+{
+    my ($cfg, $log, $sqlfile, $outfile) = @_;
+
+    $outfile = $log if (!defined($outfile));
+
+    open(SQL, "< $sqlfile") or die "Unable to open $sqlfile for reading, $!\n";
+
+    my @cmd = ('mysql', '-u', $cfg->{'dbuser'}, '-D', $cfg->{'dbdb'},
+        '-h', $cfg->{'dbhost'}, "--password=$cfg->{'dbpasswd'}",
+        "--skip-column-names");
+
+    print $log "Going to run [" . join(" ", @cmd) . "] passing in [$sqlfile]\n";
+
+    run(\@cmd, \*SQL, $outfile, $log) or
+        die "Failed running " . join(" ", @cmd) . "\n";
+    close(SQL);
+}
+
+
+
+1;
diff --git a/src/e2e/harness.tar b/src/e2e/harness.tar
new file mode 100644
index 0000000000000000000000000000000000000000..7980b033b865c625d43df8cc3d799948ad616405
GIT binary patch
literal 92160
zcmeHQ`(GQ$k<YL2SF{Bii7ZdAv%bTIHRj>v&IS(Q&E>Oph(H5YtOu)+j5$L7_WORT
zs(X4y;$a)@dheucj5O1a>gwvM>Z<DM?RJ`Udk<e-q`x%h&su*N#b;@8@%u-Q+#ei2
zi-o^#>HCL|9=oNb@4x&0@xzDTJ^Zu7kEQPy|KJu!0Zg&Ye%h;biw{5JcX4o^(Zp|2
zW$GS3f&%?#a>}`vjpGE=Rd>CP>%B|d+F9)wf2y66-g&K?xUEjVU9a^Towlp2Rkvmw
zekNVlX(z7Jb*&DH41Cz`ai`tuHjer|lxk`pu6Ei@l2+30rSr~JlSDe)**(}^-*hL9
zX5#9NR4W0V^G5Gop=Gw)d)G+ad8hl{ouK7fz1|>fwWe#d@t~!Uc9YXux87)<0*teZ
zZsYV_&vnk*NjH7hI78os58FN9*sEI})>JzZsDPQjcKSB(2uFsxS@#nfCW0Q$FXmci
zyA@U_S<%wW6L*28TD1$;?(|$gB@Qqk=_mPkoSgMA5J25JYc^`_<75~boZ=zzbB6&D
zJ~rAp>eW!cCgXOU6Tz@`?rOapbb~+G?kGOK-FLm-+491|`T6;LO~`D%(>+}<>PQz}
zf(~}7n{!1pUJH_M_u2xV`GW1fZa0%Ob=~BbexnO=Ji2hTGfc{H?FfY0teunmg`j2W
z0O{vlkYf9E)}?;!6uW1;F^TI^B7yiR0x84=KvT80E3H-CcD3Z5uT{6Jv&Ba7o9+H(
z`{2jj*9Yz|Yy10aI|tjFRkyqE)^~R{why*<ckpY=t?m5P{pa@1#;i-QxUh<ok7r$u
z5<_W_;*xr9aj;##Og)5Lb%Z!QOO6{SjbosqecG>`ChoNJA?dcc=+2UEtC4a^q=3IZ
z05RKbHd>9ItkyJIS=LJqih=6aKA61r&6mBH1hKy75Vs>a{ABVTnKGK1oH`&U@LiF`
zfzgo(zPhOX*GpIGC28+nt=q<gl^j@d?WmR}^OIBCJ$Kgad}!2@)U}h3J$KS?ACoDj
z%S7~_T$(hK;~p@c;$64XavRUxoITyb?~Uh`>0kOu_hQyfpEQzYJ#E)oNs3?XeoG(B
zJekn88iD~~wjwbAQ@7tf1Qqq0JuppK9dme3h2;Qm_xtV2G(kV?U7RIolad@i8ZG`v
z+I9Il18fr1A<Z9Sl<5r}tmD1*KtLLGw0hiWroP4g8Bmot-;qiUM}S<~Z{W?G(;}Pg
z`T>9{H0A4Qa|a-N2sV!Sn1ao?1BC^ImrV&U+r>%{$|oY-QG!`bDPtRLP&OLjU_)^T
zfi5Px*<?YK>$g-I;}@H4c1};FDy2ntR!M^GfkNu&tH;J5qEHS@h#k&PPEJy?P?jF|
zp2+u&=i5&v@10`Zv$I;a)^hcus*ZWiz3Zes88w7Y7@}eXfQIrL9$9l)DOQ_I`$wSS
z^U2G}iPnXi24!PxD-MGD1VfQ$$4!hL&$`J;MGMThfBw_TS{cy%35r}^Vbl}g*lAjs
z<}*?Ut7ASVC*;Z8>Sfu(U%raEir#u?uY3O*1C)2CNl)e>Y8~{_#`3F3kKLr#@3yfB
z0Lqies}an|P6A?q&;V<Puxj)i*n%flU=q^B08&;E6Yjhqe`B+Hu)q6PKLLhF!~f*O
z)IbwqmLXA+98%wvujW>>9xF4h0isAw8g0NBp%>*wgN&+jzMAWH&WDXR5Tvj_umb%H
z7S$6yHKW*wFQOPI4`Zcz29(yiU20w@P~yNlWd){L#lS*~)jrg?>cQSo;)oixH6V4B
zPN;qibR>18PsnZG>4#dguWJYM1!_~aZgUtY|28HM;(vAsPVW~6HUh`*H;&eof+10a
zh#^a58A2MNLVg<OR-sUUCxDGgXCQhs)_XU%ntV)-`@KY$!Iaw~zw7jS!s5uys9<HI
zO?&;5lljSsXR$ycc$eDR<<8ox%_~sN#B?U41RC~rx%2wf;qKPq*7oMhjVeo#Zf)(6
z;!RwkgRmf3?<DCRzpFKyhk{<R7r;M?MY^9HlX(-AqXcYQv?feuO$8GK8RWV#O9&TP
z!R<q=<YQ3L2L5y#XR;+j9T8=|hNl~=;u>{#+)Y5ubrF2B*Wf!@=^}{_@C!1!NGjHV
z^f{w+aSK@h!>S%Z%3)P-Y@!W>YGkv@5jvGp5cDi+<MT>HB~}sqOAda<37w~|((asB
zW@cSkGz-dozAn!^Da}kyOh6XY8;Prw44#u3_LkHO$jg-73mi$eiwzm%0Lc+*swYS5
zlE^!!TH6DiP!^Gi3=+I9IK0cKrlilH8bj^TkwP&6F|oTqa;P%5`t#!3k&_s77;5F$
z&{se|h6}|FXwbRCq&Q#}Kd^6nSHl8L65E+3peG?vPj1-DzC#y6Rp{;DW}0f$??h1(
zROc}_uT_J)g`iB&^W@@b3Hni{`>kNp4Z3mXlvMG!F{{2}qyAY$l!vpPd^p4&o~90y
z3Q7f>h9hj4-edbzJ02!1u{5HQQ1=b0FNYF0yyD9E-w4J6j(7i>V#M;GA*sP*1Qe<I
zD0(<Nt3f`^LG#8R<43+@^44Lbi}$yZF4zc)vDHr^V&iwU;qZ8oO63_W=I>sK{`(VI
z1IO=R4|3CdN{MIvqhLv%E%+xTzAZ4hdY+=lE913+wiHvKCf`ii{pH8a{muJbAfqNK
zKPb?Ysv2BtCQrGHGJ)!)e^DW;k;}c)4Vrv)EtsA0?L*?;Cl@f%b-JLOj8V+WciY$U
z@gdE4_Vl#d>7UtmXn3#+L8<IxQw@U%TB-NDV*EgN*uT?sC;fn7bQ{>m)5>z(g3Q7{
zvZsYQ54A3-`^od|)Q)@oTGKyeYhv@m?$1PJu37NVi?G#HlH_gyc7~+cyq2SDL9Pt$
zwV^49I1E~)Vg63bfwK0f-+-DNbZk|Ev1RYKU@n5deGev$zhx+hZER*t_^M_OlDCzl
zN(Nxc@yN=T&W@iKE+xu*!y@|is>igA7m7sI*%ft>{0pIrtMcsR#K0Sp3Em7=5u)Ln
zVq2h~t3pdkPlduB{42muTt63F(>Mt!{w|?eqNAE)gmCP~h-J`R0^7giuu;fW${;>M
zsWixMMJnX8JO!3#+$B^n?DHyNqnF`@?Oth#3Ed#Ld7u{K#S5Z*Vj>#3ly)osa_K^O
z;g3^`-~IcOg;OnLlcAMk{7Rj&G<7vOf&ZdzW=d{8%;>y>GA39W!ZB_0LaV~3Xp&cM
zsNlqM-`n5*Y3*Rsz1n>Bd~?6*VC@_H40|?M>dsHl?K(Gbs=;Al(Vdg_xbZR*0M@=q
zM!$zA18Mi5!r@h?-MkP+)K6jiL~Gcg$p%90FEs2ndgas|zr%XQZunaMF|duyZ8iem
zAk91|PR1G7cx6UOruZ(lERZbhePnO}0gOcM*p9e}J>Y1lUSSXoA9j9JZUqB@v2JeF
z52J)%%Po3-mwnOtkvB+PMbFd(cU1zP2)N*$ON~>ruB2}+-F~f+CY#+ZWX#H{Tbgxi
z@Y1bAU4^xX4;+^0KmW;Al=xq_#i|QZF_<`RPcc|UvVoagdNTQ2xJLh9^!c)LIx4q+
zz~9aO|A&hYA1&tn|L*a3OG{(_e?Z^}zf3(?=%?L<qegonX@8)9tvOWE+*vjh3r7Ai
zFfs3r4B}xN6d*wo<Dh_uPQLUj>5QLoP{24SfOJ55_+14B6nW?u{KnYV>6Kh|ko1$-
z9JoF2(XY9bp&9B2rcL7n4%dXy0rN!JoU8WF&N^NA-eJmtE8)~NvCV6usg2F&uV2i%
z?VYXNS%!t|%(~6}{oVapx3zY#_A*}?nqAsKFVyNK7|B}0hG5-Z`S!7|tEscUV-2Dy
zH&By~zEDnj<OX3bG*|4&;FetqpgC!r!bHMYo8G%_AOFCK-t9p0^~64c9W<Jo43QbY
z8+N?0*L$+x7N=#!J=@+{hx$7&#{Q{idyUhLqvxGY4}Q_w+4Aysb#3LB^UCH&qA}^h
zL~m|==N~<p?DV^6rn*L(n}3SU<CHw#{O`Tp{e#2Z|HNA~WF8j;S*YvffTKw9vzxRK
zBE#qJ5HphiuNWj8Ve&}4G#dytVqgJ=_~XV_Rie1G`ay>e=&g`JZnjSm&hbut`)p!)
zc@G<W{k^@ry!<23+e}cL#8idln6G6wN96$m{-|4HH^d>a26{8xvJ031VBYD~;Sr(R
zq=$$<;suYt!6YDxFHPC>y?#hU)&9}4c>nPoGb*%V&g*%101_aXdT%!D;TCwIgjQGp
zFl({NlTNeQIoD7a_|CW{1Pvr8P_&epQ#uaM*$Wl}s_R;0j01dVU1=r56uFiIMb{$i
zAp-9om_h=|NIb4b_Jl>7v?OXVBVs}~@PSvj(dlDT?N@-f`Lap@M!+5{dBJZ=%i`b%
z<{v~=q=;mrKLTH2nna{pl5#=rOGE<L1-{Gv5(Ba^gl0)3Q=E_;hO_w3oQ%xJdKf;n
z+)J{cosO2&a)385r!WXKi3;nA?ojE53fav3RBJZsQe{6mK}Vbh+HV;pBYJDI(|M23
z9@;_S)I#@J|LLR;Gl4Vck|uWAyu_>#B2D<z-h3lXNM9?JvXD@Dc4@Xu&RU**I9n!j
zEzf>8TNeIWo_#c17KT@z{WDgLHBY-d0#f*sp8^?S-_2;i6MH>dK=zQ=0bOXU__~16
z;_CwL@cK<OMuGsJIsa(jjM4=dff{}|B)%lh#5A<xT<LXn?ZxJ@6`4l>PbD59EN?b2
z)Z+)%w>RxqG_TXEB`ZYMDM=(F_T^#Kd<@(?rnEHJYW#Y>Njki#kkQl7f{KCx9>*?4
zJ{!LjL=hJm+<}NtlqQstP=hfU#iF2Sh9SA7`NPAP+dG?whw~-3>|QZ&5?H8pPZ0=)
zP-z-l2&S>U2XESn^*8O3V?0g8J&5~uN^zgsErgo*7vfoiU*M$C#T<E9W?{SU(IF0?
z866P~d1f9HS_F(`^02uF|8k{_^h*Y<H*95ZuHcf*5PIWOAo{v-av}19k}%8%=tKBb
z=CY5PzbsoQCCP~4N4HMZkhyA0)SX29_;^_G9<bXCa#5xRG4p`FHi1s3i`_#2w=3@D
zE_Ali>Z&gQ6#2Dd*65q5$z|l^NKfmXK7*1lXKdd+_3f?-6SkOT&=N5~D2|&Qr~?8=
zVRBw7#GDxe{>Evc(t#=&*NrDenQ4f~xNc%}UE1_`T1V$n-OU&?B{=#7PE2LbGM`rt
zdT`=d?vPSp`D6_KG8DVA;a?Feo<K1m>1n4!G(^<|Cklk|PF1^%6RUC?Fko!Q1MOQM
ziiRAEA}R=v;sSxLqNr#)GnYmv`NzPCiY2XCKuWHKP;@9_;-W*5vmQYM1VJ0lV<>LG
zOBi*-D}F~42%}16E2XCK)hd-u3M$O2|ICTD3%bshPf(f=noWnyT{d{o^$IH60hG~L
zWy`cdk;2wC4g@sNv&4--L;-V6=!;&VBaj9lp8EJj#urhL-?c@|h##%|opWmvvCI<`
zY{!EF@psmRw--t%ns%sG!NTVvpwOjO1wym%RDB4UBlzUjMG=5+IsklOzcVX{bM#F>
zN@XG<ry8kPKsS+gwBo*jixR=RtUk4k14A-(h}=(FXFYnzz-6h_z?lNjW$Ce~f&@@)
zHHIao^&tiZ8f>(M!Cc!U$1k;aIxG2=rfn+t!YX_@_h4nw{qc_u@<&zljE5Qp1^@*=
z9_|}^5DrP`^Ife%FZ7%(;+uhOhqp4l2OX5Tb>>uBN{82XR^&r|jKvPE+^2Nv*%gRr
zl-$ZNVgQnHt#J{2z=F)LFDy>D?Xfx4oiLO{>W+*a;Sw^2OG61X*4!>uDFkz7pE1K3
z!f>2$ocv_m2lHW+b>LuMz<y*2gf&(q`xUOgNJTN#2%_8cCZ~)QyXW#Zk5l)}(x34U
z{=e+LNy}uJWC=r=Xo*~u8;~J-R=&|fTTw+a3^?cU-@q2@iym;bRB1=b*ve-wAPC^`
z;t}~zsTqH6m)5z(L*9Oi)D}^JiOUq06<0Y%G=9>pEY8gQ{M}nGv2SJAkni`k#6-pp
zY$P!pf@#Y5=WX1mx!7=Fg`y!K+PalKZQ~}2KS5>a+=}DjIv!oXgem+$BhR+s)oDv!
zvY-}_RRR`(eJ9w!L$Uzy0{6|se^X|_NjG-Tv1abd8rZ*VC!^iuDA#+xD`85MmHi_e
zei{&!XDp$T^1796Q_WHHqhc{um{E~>oiqi$q7s7b-cH|lp>4ml##BYR({;q=OW$TB
zFg19P&fFlO`8Mxn9{~Fv2mXvO@<W@>3<IMJ1G+i>XX*RLe=g?#SbY5G`*Hlw$R{5i
zOpW7zV0ngZb(|DroD@VQ^R@p{*&oG+?T(XzXq?VCDG2d!e;?46#s6fIUW_&eu;OHo
zpiT3nG)`C}0z-U*I8VmhLn%V`)s+e(>{$rq(3pw1J`w{Ujvq!O9BL9TdCgAZAxTrG
z#;AWu5W)zcdAG^aAUOFXp*;<lm~dzr9iMgdJSj{I{e<2wKu>Fv^?RX-Mqm&{=#to@
z6pRck3GuP+;A3RSg9Q4t5*~z?Q|;EI1tQ3~ECwOO@jd*W3xip&b<bc{84TWemSJF6
zv`>g3%8DV5W@zxxea<<khb%=*6-;=6?->BsMZR<-?a1duzPv;@gg?UOV?NNQ8qkM?
zeBhl}3~|<1<6gj1H<F{iHv`P!oB;MgiJlFp%bRef3&-3R9nJ(N-E$l@;LtG8?lIl7
zvX|0r)kz;mQR4HN5s3%|q9SMg_FxS(&yB7?5u5>j`&$UShzB8&6N@Z}&uk2#yb-Sg
z-`Yn1x^M^<@w+u?{%U2(jNytHv+i3NgnHH2Phb#HBj7pC&(P!Qo51pJ;&AX!wk%TY
z+7P8eJ6YC^?AmRMZ>`#+Vf}imH8G)wHSUjfu_ZtzWNZV&&%HroHHHax!Xml@$7Caz
z4=0Q`dIkfg2z<ltJR$-x2V43GQ}Xp-)YjNQiHr)hkqItW7qn^1iCNJYlO<qvj^RBM
zb|ptT*{_D>F;mrr9?RCGRjt~4wH34+j8I^Y=QuoPCrQ~<&YZr3e0U^PY_w&FoZjgf
z9QeVMkurz5sl0Ovq;`#=Yx?*^;sYaNKt!XF^$FCozJ<5}PlRzPH>328=mB!b<z*s}
zNT?u`k@28zdT~C$QV2*{#)#Wxiye^Ta~uhdKIVFmXda2>@Z$yGFh^4=F;EalzyU;|
z@~41vH8Vg<zAE+P9P*@Jd8%w~chY*)3eO2nADX>cTGT)VG?$suQ68w0I4UuIB@j`S
zQrwJ$fTC%3IsMFnzwp~mSU;0$_&pdtb3Kk=FW19Vq;0xiltPuTpZYmmoki@$vsH_<
zpyk`ZU}#1-Dv1$fK%u};NQOkB0NKSwk@XDks04w?QDEQI8v-^64XBqfJH+IS1nc~`
zR{arEE0in%-7ieWnlyILz){>xxwSe}6et$4`HkzHm?MNt<-y;QdCB8BP{T7>;45-;
zy8@@J3`yT=)AAl{Le4ZAi$Kdv6vH^()H4Ioh`bskqL)8VF=GjYC_X;R0*E`79%Mdc
z37`-F=Q}ym`X>F;0?)JJp$JHQx8j<|6&6zStkenXn$IP!f}^>VU#KsQ18Ecy_xb^w
z^Nc+&lK6rtQ!?c(ErdNOW0hLUZbi#$9s#Yghv&TN$zeUH&QMhMS|Z>0N~c5FKaS2P
zwJr{k>alp?#)qPOribjc#wlJ=ZS<_xpzBj(7Ld&ev7ZPHgB+;^HFF;J;h=ItOGVzi
zb`O~hq5F!w`5@7Ejyc<U(0!18ar%;IFA0c$p?g1T%%Oo3W=Nf-zaKvsb&8e{cM8Zj
z5(+RmtPipRI`B@$&y%wpvVbiu3r^v<O+MBb?~evGo+6TmBJ9v0L<-fWmFdea!r15e
z{c1s<K?Xz**{07dXKID@U&KGfl(Z=a%}zQUYcCUOc?yUFXGOSyP=n@$?;`ZP!TUP-
zrVB)CBKBUEDpsnhDWqz&@{DN<Ws&fQZYUsA?4_T`@PrP}KH}aDgk#K2Z)H)JJ>BAj
z3$vM9ow9zg`lRZLm!W=jp(T8LUEg7@0WE@mBXOqmh;YY+H<xHxw>WRE7BcaM@`%&|
zeBXX6@M<dxg>i`KeBA(=Z|}<ZhgCJ%ERah?2r*%!Gl?U-)$4=O`zYfW5CAXf3HJv4
zF<u*FIy_|%F_$mUJl6;Q8=`Vi-$Ks4El2^@AE3%lBT0{!Av(^8)MjO`pMoZ(E6JQ=
zSi0c48HysIbhrb-hC*49TM`+MrJaTU<Ev4gM&E~S;>xID2;Wm1!^Hr?L5ZJ+bH5--
z!l5Q<wlEpC97iYPKt^lrx&{;b;Q=e|F0>o41$&HPhLa-O8mN-O>GSOT!qqzvXjJ}^
zkKk~>^85{qbc7Qr>OErAWA4Nqt!GR{U3;0HaM44h$_x(+`29&`X4&U1jtNtFdIw41
zGK@-6W0A>>#sk^6VQ$D2-mjX%M1zqHeb_78X#);K4`vOe7~6;D)-|8ej>4sDMgqY-
zS03jixAO2qp5L$NzEL-3{{k1LnTrNT?2x7<M=iR+6e-ErKVuDWJdc7MR2e)3Zs3`~
zPt+*V=NAw%&<BUJ1eq}A(SfE(qgF7%V&BVndX5WGdZNS%;i_&qbPlJz;%S`Q)KE;k
zv@pQ7v13D=!Wvghl$2Dhu$ejdLRC#uSD7NXz{>N(WHf`Ph0mptXdt=x+-JZBLQI6;
z->&xEPCI>^`l^VYIGZCINjHnltPmB>op^Y}Qi1M87xKjP#uQCF1YJ!P&qP925??Kx
z=@V9o-&`lzL?gFga_&t|VEGj$Rw+$y?)-FF{t@THHmlXc{oUPz^3?+E0}IR@HP3GX
z%@hgwkJ|c>JSxn+wSnzJ=OXEjDgxjZ|NnQ77K{G>rH2n6j{X0?ivRx}xAk0j_8~8`
zjQitMA5fCV_kVcGxZl5|Gk(UYJ{&B|v|(s8%lQ5exu)XxbN@#yhhbT{N3M(|Vi5pw
zA9%Xvj*xWIJpZ&p#qW`w<A9fj;CNKhJ%Q8EJPEXSa@Pa(FI)zKwnR&XLx&Ln5?L)=
zzb=Y}>{UsS)H0wHrATc7Uzr%bdQd-L6-95)v2WFE3(_2-5O8dw_pU>|7uf~5oz;e!
zNKoyU(4^#^rqs<@<IrTO12aJ~&BQ#JrLC#OR5Lcv3hSHpCQO4Fx8jJ+K8zZ+(n3|V
zhXm_Mmp7nHNdCdSE|g>3<&)yh54cqE9BWYqYd_$;?&6jPd2yQHt|%O~VVXUABu<@f
zYeTB=V75FT9AiM?kWq5j1wg|X(eDkz<lGL9G8-eu(uAu%0vPVpGlSj3lpo4#n`}QA
zK!D-c%|L#xKyY)ux=b++rHO@GhGM1YT6s!jUO0ZGnR-={=b}jln;=6C?-s(|wS$ev
zJ+2xwg)U^nrXdvYgMq!u<t(yK8e%dmSiQJA){8IL0&<s{T94@q<|uilu{ZZ{>qu<a
z8sQFhkm`Y|bx8<HPd7q{vh{#j;x-FhLzjdkE(c%1<pj8j0KT5gFG06Njn>#RESJV{
zzlm!sqDmHhqmDanqQp|^lSR7p0-;JR`buDXZZchofax?LJN-7~4D};-4lf5X{q}hN
zgZG)>|HpLQHxPq?T{9}?r}nhjIjS{(WC9S}LBl`dwv$z>6v^dt-0X{oHUd~npgjim
z&&j{$W?=%I;%3|IE8GeW!SChh>=6nvz}!#<%_$7HwmYL>X8a29Vvvpy7s9DA(keN&
zhHdy8*IJ!=AIX+LMIa@SNXQ^9mlb>km{GV#h?rPxVZ1L)iV2Fi1SOv~mJ`(ok)Rap
zyyW5QSW!9fM~J2YQ4U<~<E9H)(V!j4w}Q+kEhQu2NI~oiXG;6Rj1a&E<|r;<RY+1Y
z#yah-tYm5vV&pzFx}CN#RSU&{RAjV>gc1DK_y_2?x?@T;NmaRg#0X9EdfyP7-e)v+
z!H>z?)FgSZKcNqafZ;-XKw_XB=$FW0(-$@^jFPb_vF1c6D@On6MafQw0Gfd*VOwys
zH@Zx3AC%Y!NK-O0lW(R$ksc%lBwIQD79C+MqNq{Vm1$(Kh};k9^(3mwUkNMrIw4R#
zGQ3gI1jefPqs&;Yf|E-nRoutym{Bvxeb@D@s3VtX>HY$9j&|hkQ@ddXKYwd6FQXeF
z_B_$#Y0gV@<v@r$WT17>hImUPBp+0(Ja76ss4k3Xgjh3v@jBYV5P>%{aSxa<Vk(%o
zvvH_d!X9-V<USCrc?K<D$#+gp=w#GzF~qNGlwI*X;Ib0G>Gb?cTs}7=*Yf$e)Qy}T
zt{DHpiHl#u)c#fWaS-``wh%Vg>0aEs8|Y^Lk9+j!@%Q=s?@JH={Ahgt`>#ST_h~W_
zOT7LA)-?A202Rc;!Px&Jc!<d3-o6sQ{EYoSWB(87fb{UYO7-q9WgjAk@7E1PMi1-^
zaRr&!$ICSbZva&QvE#%brLaaE&>tilR2mp$gAm&vXh}5#H1`f@P7ZY<V|CmRHC2~8
zZ8_vv<uy6chowYMVgK*FWU@d4C0`opLG6?$;O<klDfYx4fB>#|L>TD4X1W%X#KsI3
zGqWn9YrID-g;g6)wHAPu&AmU|gNBH>vYI(@?YG8Nc@LDDlf?z1>b~_#N0jW~xZkBs
zJhG<1NTSXKJkP`IW3+Nl%|}5`OYl%k%8hHqqeODotyr#jJvl=z^-8A_3@@6Jc-d{k
zBVFeauQbW*|Ja{1Xv%xl;LpK50yJ!)oLtXW;_Xm~%Hy?iX8uPVSk82eJz9z8CD;;I
zaH&s4hPcB7;yB3#;Pb$N5Xc$Kr0sBMi$|SV9EvWiKH`G$I7bT%w#v%LQOa<!t}iCG
zqW=@wX=MI!q;ho8Uw`<+&HDeNKY#zQaR1ZN;`fgqjpM(5jSawk@<=W-`+z5n^?%@k
zco^&diU&^{_xYFj<!7w_kM)1j0qNoQtN)7}zF)-^2#HmG=>gA%$9~CMxw}OZqGZZ}
z?Gf}AAU@ttc&E|eEkV4=2hs2;u1cx)a0{p_>yNVB@iTo=gU09I=ns2SJK`Nl{+0c*
zcj^1a*;#mJzw8}UGF&QaeQAq_`YdT5U!c%^?*m9;vJa4xCHqOr8>{3YuHi;%NFNr5
z8@4qb4zVht=l2ra<L&Q;IBT-X9@CGD){n3_x%n#XU=P-vb*E6tG@y&s5RZTxz7c)E
z_>*DA{#>CsD7(>t4T)KyM+Xhzgb!On0qG7+Nn8q6PN7m1sY2yjPtkZFdkD5dm=1br
ze3Szsy+)7MX|bF<!#8eato*Q07Y>3h+#C{h|52HaN5hn$9VBkYfe1G3@AMV59oK|_
z((sP+jz2;*_^b1eFGeb?R9QsknD8IBhv8c43QvtxzR7iK7X#;E!Ny|x5Z4_15|Q`}
zlb#D4JZw8Laczx2`dWiOZ>f<j39TZ(Z>bZOgI3X>x75j&msYahQp@kLn57rTr)(Bx
z-QHTYy19XCc{l^u@@>DAUmTUI{^$1Ip8T|y+}iWq{R4R-V{qK$VUMTPaCO$+=FZ0E
z&iY@`o<huhnbI6*AN^`pXq?ls$I%n=eSSvbhmMx|3tVn>wyz84zgyR=Uk!jsoZPpL
z8>1L(`j0*iE4z=arb`hB(yG~GIogRZ*lvg6AR5$h>q5s30c5;7Vyrz~X7b2VT4C)m
zIu3t))Js$d%XV5olkGBE(H3~Z**kp|a#XjTdL4wyNwh92$4k>H3x9!iBEFT(a|(|R
zRs+|87gZUYG{uHDa1|dzwKZ>(^d(7#^^yaeCMF=L#&IfS#>q4!EwX`VxMjpuUKHlb
zxQjCsf;|LG;Cno<S)892P&{;=>loS#Z*lPf0#$Hs|3SVM59Hs0PZhXRjx|x5(q3{c
zi}DcZUx1OFN?Z6_Hb5i?!0?AKCp7-a3@z081eO-+d=gU&wXS7r`SIi69j!wCA+aa(
z2)mH*sc%(OIQ$hj<lLu}HlmnYRdNRwbHqVX1(9&T_#<^mGcg6rY>y%o=9(yEBrnmh
zfKD6H(TEMO81|zJHT8)y=Uuu(f`%;MG*~ZbNBq@8mWg|Rva)=RP`1;<<YRJ-O9VUZ
zLxfyv2A<O4$BX|t9QOL~e=a^ALRd@&6CF?Yih1rnEgMlnJq-u0!s08TNjM6Dj4VFL
z8KJYv=@=l&=sUCdQk%myF3fs}le~=&jXGn`>M}(LM&qrWFy4aI)jOC4oUiDg`Kn%>
zRLgr|t{LNmtJ5sR8pngZ9Fap4Xi8yN^If$Ovnod^<l<M2#qOb}Z8^<87!@~6)y&01
zA0RSIFZ>u98SN?|7lEXRVr;RjD}csGQEH@(HiQJuA7jR87H;%ryjJ=tG1Kw1j37FQ
zt`jx>OEma;GpV(O0OT7<pmqYAz8uk33Xt)BHVGVS2cJL$QU9h({6C@r?j)1~{LGA!
z1~97!pj?o|J~We>kg=aB2`)tn|70M-G+Ij`^Cd~;xK)QDHMnDw=vV~JqW#(_<`V8T
zf3C^vL{zG{Shjgc3;QE(K(UIbA&~}rHU98b$(TT`Xn{|GH}QsKD=r6zq*+aBEqB(D
z6Hyl4?XR~b0_=`ge0_%gCFM@83E8m9P0y0DkFW`+ARInn93)l&7}*+nG(&MI#Po_M
z^4AOF%@)6fy+4O(;a#iNeUD*>Q1~PN&~JM`k0e4fpG6k{C}{nmB{KNWpb)gBCs%S4
zdJ9bq%;ack#1A%`kpi_WtK0fFAQna&gUW%$b^Ru&@f#z*MkxV7=o$;pRp3VilhF`@
zLTefE-<i#XmOhuJ$ftDYJCs%F$~SMeGDmWh(Cr<o`k{x({5-ZK{P;&buazTRVLaEf
z)qx%5Fpkz`V(JsW#N{B6@GfkiXJNVHt)L-0G1grPFM){^uS*O^y@lm@n)zyo7?;N5
zw5!e^jhy@PI}E=-#lrDu_QPq|F316?51V#=7xqLRw}XPG+#YR_s2~gw@SKM567FHd
z_DO+vi>}NjQ3Nd^LvMqUkLNkGO8^F1hY7Y-KWyM{VwVsf+WOPHiJB(TKO?mvmKmmw
ze*0JiX<m7S%)~CsYtC}?D_V@j10`q;?a3K~AnwihI_IshL?4mBy(tVuxSf*Z1;tnh
z$xw91#beTvgSeM<S3ja+K6JTfCslwCv2Fu3HXAr$Nf3qz4q1J-S4HJWsfbQR=1Fms
z`kg7?fTXD1=TyB<+tg(m{eA4lzKo=<WsW*MIKM!O#Bx<d^8hr8)I`ugfsz3xU6K9T
z?@K~lOJsiPM@e2-sqCLyhun_cVxlz8%gmxtxL2N)5Z~!RhpiMg54CQ$hQ#E?T4cAa
zyN3o?u}&zuxB9P`IqXwgkYr(8<=Z^4&6adif7tG~LM}3H^;JATBzAGyo5#7qhQWYS
zuxgya?x{%wJOmhFbBsGH42EW9rut@6J^=tq4q-31>816f{5ZqGadgo}4tKz0Xz@1q
z0w}`2JX)2LOZr95*A~2*09~g}=1fvcqd^qxVq1onf+yf#o*>aSM~rcZ>3uGjiJG1Q
zj*!N4HNw-2V3MooOnc_HT?o;$<CbccMf-jmWyuFBVres5w-QhGLnr}1fo1%Q?(r{h
zW(7P>W?@9;CEzk*ytCnH4H=3zmFJAG*k^i&19P(txqMNKu(a30(X&#5MNb~!A3m$w
zYGAtE_<7F$T6`&#?+y5TDS>`z?OZ2d#XYEaZOjh?ruPY~%o>z7$@Sa@HNVH1RNC##
zSO-fT4(~gLqPF0$ZOp0lOR#pHl(C>snoO(LW=qrzNj9+kVgKB5Jig0GZD8^V%{Q4X
z%{&FuSPE-s1URasP=;#V$}@3I=yU<OD{fJ|bOWzt0<D1f5GY73PFMS3<YhYO_5|$a
z?es~8kq#d|&a(0jxX>}@8KmL@4S|;MhvGfGgtrtyegU;P7%XDsL@mw6s1L=eT6q(p
zMG1?;iRWDxMRCG!$e0JmZwy{JE6SCN0M>j5-^j=}#Sop;F+NP15CMr%-XSaCr4KbV
zG+jv;tfox&!18bG#@yc7+Qp)=)d03onm;^zxxKS_csP&y62Z;eT<Qm#)dTlpfA{rX
zr8KV{GNzU5t9&(In(?_t<8B;gNl1!bFA?y#PduA7okaicQs-9F+Y9_z`=ms!f<Qa0
zWTX=i;r&rk*QjTrKt3X3gnB?5p=UbKK|Q`xr5_TI_6m6>m}X@>i4iXhlz8`b%i4n?
z9#O;4*CYuE_Geg%FfcJa402?8Jw~;AE<&t9uuCk$35jlgV9QS9nAwmV*yl#?9HGnC
zwIl#VO$mdMob9luW1SM`*$@f~`BGj=_uf&*Sqn2$IsAEX?%&^jJM+Wzf`?0?&BbCb
zW$ys?HXWtd!SFH>aG7!n-!r5$`H&z@#0(rq9U`dNR1i2`upNgxnGyLfgECb_>i9y_
z*~k$2%#q=PP-+AL>38@Mx&5_)vDH@X;)uzGkT9bMHv!59^&o)cTjJ89{(vBZL%9xw
zfCyFgTV?VX{a{KeQjS3w@!%(h!j}UORA!LsU;U~7dP2))$@r-ahv0#0^g1HPJOSrs
zjM;<*bT|fwz%GzSO(1{!^x=4FM?1AL(ZZMdZDemr;lkye3foGw6kDXz%%sMNll8#`
zA!1s&DxU|Y>Uo(EWgr|1R|_KY3~@pTL5RfIo)Ly|J&~KzffV$l<vR<!AW&A;UKwkJ
z%K}Pd^dXHIZ}rmaGUK%-K-?9T2nGb?>arPStv6O>3frhhejRuqN*lD;jYgL%B_vR~
zEH`=6Gv4q*2xgz7I9mX&Dds{kuKL&88ysG-E7y9@sulOMo7N88TQ|#uxQmY;Ken{I
z58PZ5UPH9g5L5VYIm2S1cZT`ZoXNoX(mYy+7CKPT$KU8Vkpqy$z6Rs~@0nJ?{JaX@
zLg+@b@fP6l!6<X9a_uuuo8-Fm6sm$vw&#u0HWO+!QaxJJGp7vgRu~W>2T7i@-n~i!
zCshPhHzO`>$e-Ss$i-W2vlFT!EUx^F)Cpd$y<377NvN*OG$KvkFv(U=>Hr8XLRm0=
zNI&ADK#Et2GtsUnr|Fa8j)`51)5%>Vy&wD_9!z`n-Ag@Ts)SM24rPMvNPGb(n3=|J
zaw{*W0$?g0Ja`etMWhNMXb>dYH5>){Jgt<tLIyeL%$p5$fF+@3ld;Hz*>((<+{q~?
zjerB-@=}^b#t62Gbug;}8`hUTBC>!EZ3jj+oSWjwBsms^=NCX7U1)I3or-S|`ZNVC
zRJCs7^quN9q;iJfk-zOi?eRKEfoBm0GO56}h}DI^=^)d?PJ6*2#?dHfFuu`O=f(g!
z@E`xE1fk5YYLTm0TN#D0AkJB7P>#g)hUtp6<toE|hZ3Qm0gw#l0P2EuS<3ano5AE_
zILoR*6M;m(Vi#Ymb1j^KfQOHVbSDaJh)^<BrGR*^GGz*r=pFKp5OFk59vN|LY#!~p
zEdrNO<1q4#NZ2s%AOqbM*IJCzH|;-t*2kkE-xfD2h}rZ8f#qevKXEdoyeoZH&wm=y
zROxwg+R(j{ETGV>Twn&i(`#V)MC=DE;TyAPV{0u)lHCKA9Q*@ix3a2CP8B+&(XE%S
zXzQ4mkYb0ui?gIyN-YAu+>{n14=xszXSwFGQXX}2XTrgYjp)N%D^vjrkc(CzZ7C^`
z10dC6qkTYxAniZ?2#xRs;^ytKZdLG1$xNvVL{{)5Xq&wI&a`~NyOu`dwwDJ^55Q5d
zkN2D*?Ba>gsM`R|M6su=wLyFHHSKalY9n(i$_@-3bE@4uG{2&<#%(RpAO&bj+`5C*
zZSPKVcwzU>F=vtzx<fEoc$qKj+&~mjr57Gv6Zhu1z=S}6OA1Rquo`U>k+(1;i@nCl
zh|Fl_ArT1}fitYH*X!$>n;V-Ock4|Z2GW@TmzS~G5Vj;z{BCWA@KP~JOxX5KEQA^n
ze%)%Hm@+nnxl>$4Y>V~vVX!Nb+Wcaeix!M8Ca$o{vNuDj*~I^{LTbm#IjJf}kDx8C
z1YIWsRN?1j@bBOPoON%EjfEvOSgrVk^TC}0|H_=p?UX`5G`5DjIwP|b^t#9}<+c#^
z8d*_tgr40!$rkU3c%q{yaf2kyB82abe`swSUd)=5-Cvef=IfkY+pqT2IH}O)ovjA^
zm|Mlcb6h9O<-Lv_3)q^rZ2UpRxYW-hH@o<gh&hL!8wVZ&BDGOfuhm)uZ!7%NlKwDU
z=ZT7{k9t<7VS#yNz^hh*KvD=tNkNvQI~6cRK6@(}O=W@6XqAxq4Q94mvVPb<zWQ~6
zuOKgbH*~V?oyiY>r-~gr0D6mr?0=6CB-|dwS@heo+?9I1d;6<<W$$1h3lR|=9w5ft
zqvD34<XjkRB>y1S2&h5$m?8}KzzAFMs0B8~Yg5z-IR+u40{n%6y35Ils6@cACR*I>
z_t2fWtI(4SHKPD_5mgo_UvM94p#FEO8E`sS+vp$~NFI|zNP%}X<v#{6P#8Ihe3AUr
z&~X5E!If3?N_hWo-Y+3x0R6M!o(VJq3)1e!F3d>GTAwBBv*dhwA5yP%w!OE$-^V3C
zmsAa?u25zG;BbYJJiE<RCVGxK3aVPR&;nwf))7-$X!sdpzxY{k&wwiyAz89D`Wod$
z4iGHf+*1^eq$m=7K->2sL;M;Tn|Lp9JuUlEF9qjGAeM7eEAH=n_jg$ky3n3Q7q+pW
zilkiYTWbevFAG9QPEFBl&n^uQQrSIq)6X1kL&hL^#!+?;97qm)RRZ*}2A85=XeD@p
z`NY5KRdv%pJmIl2jMIe)tTN?HwFg@O)(pxL>aS!b>$sy9p8`SLZGLqiL`K|#AE4@D
zXjxX5jk?qCaVOIT<Hwt6^gdt0vw5IOa7oNSq79V6vry)4G&OX(jnI}>r(-}KuIBpm
z&ax?S<))0xCOi@x@6Nlpv!RB>?-)=A=ZGur;ME?s)wvd7xO2GT++vU;su#Lk#@**_
z+OSyP<sgBXMS1{*8WqaT;?jvqmVBQPsy?aDsGb-DIjZaW#6YL^U+=i}R~t5oAbiq&
zG!L>y-Hm9~6>KdiZKyjoTGZYZdi|32OSSYQl-0I)^b}MmT%KR1_BYoy+!hX*R{2v_
z92Q`|$4~*OYma~mK9broa^rdVB;3Z7#rcG#l6n3;SFyY2-BZxbDopC&1Ok^{D*r@B
zP?&X&AO~ACf1d<fRL^2XZiJ2f@<R|&)j;G^!E+u;KAzgx-gMhra-7WAFYL-NK6cL=
z64XPx8f<Eu2(>{<!>p=gU`#^=9-b<L#*Sl<y)Ux^>@kKe^f&G5!N%_EgJrl0l&e#%
zXSehp$lJ~R{lZ%eQQso)R#Z9<jSvTbi6~x96D#}23$An$t<~et2LO5rlk>z)@h4(f
zVGgZ9yckkVTvXf~ToFbC`h}Q=0;6c=zoF>#4}(QfvM6r;118=o2K)6%n`mv^r^Er_
zeSN%|`fXsG_)dN!oYTH5aY>j_fwFGXlOC@AaVcg`?&0b}J^8S}OJz-oLLU*aDtl%%
z2diZ?32{v@Xw=GaWBlgFa&XA$etUv}3|*8#mm-s8b!>L=uly6UWIpsfIZ>9(M>!@J
z!TCu{E~+=c<k-n@4h-Wj6p}+SU=}LyHa^Ppgs}OE@a&laOXKrNT*2yuwLZ5*-Vxz2
zyqW%i?17t+$q6_KevO=8aUV2mY~+p#pS9xm_woJa{BQ2jcaN8f`JW#yj_?1x57gh<
z#(kcW)^#HP(u+O5|5HOFU=|qP|Cx(whzR8izxrs2asD?7sC0b)C+O^Vp8qYRS{p(B
z;(=6f))|)3klfE99b7SE^OW2CC@F`KrvtVyq>Hu_a}tQ))A>pU1Vp{lcRrYsWO>=)
zb|YST&y(%^I{&-P1TBcdNcQanJhsTWG|W`8oN8G-l@SVlQtD>wL~M~h1+_kd@=EQS
z=VQV?Y*Ji(xlm!er^VifEvT1^TJ23qo27?aQZ{R<W-aN{H)Gz1CTxZdEU@|<%z(I*
z>7Ww$TYyuy>$jwD*3NH9-YkV=gZ&#Q+P7+AzfA$+ULzRq{o0o>pqur7-1YM4VL|_2
ze7rQy{~Yi)$}dw77W!#-0TB)hNapX(l5X>U6J|yV9vI(vQviGr593Y2u(<JvSiayZ
z@ypM6Q!w5XkPb)>zpG6F^LJJ+(&gnJJ86&JRrn9?(@=x9fD_vch-$7X03N>f$K^E9
z2Q^vsxX2M~JM9g(`!%Ueq21;$cZu(}(N2&vx-EeQaNln4ti#)i6OA0;v%SXY#?kXm
zr-yxP?QD5@ySldW%Xvlj8c7$0ycXymJ(;}bs+g%^cf~lpYIWneeL0}#H^om4)ZlX*
z?>$Y{d9Cc}7QDovC{D8Aj5v-&B<YVETUDI&KD*HB2OU1(0A%2-wY<ECGb)-JdwUnN
zC})N_L?9SvT#*%|hg-zqO{BPmNIdG+*fNnv<#>O0_h1F5loBK|q?tOL-Pqju>9YLe
z+WyXFwR*@>h-!m#4J590-1LwV=r;sosude~cNtItm)Y(<LRuGbIQ_4kKF%{^m%?KN
zaSuLISQpa*3xi_8pX~S9Ti`i^{kk}<0@FgXam0*{^qmcq(24hxx`#`E5oiZQWE1_e
z1Lt&(qPR9T+o#P&3JeonIMpt$z~F8}M|k`VPUD<{bkW!d)(#?0mU&YQml2W~Aa4t)
zL*_Kw&48Zu3QB~JNSZZfG00x)RxqE|A;SSv^G3fcxvyj|;-b{kQg91-oRQ0s_!xyp
zrl$#YB{YLc3s40IlA?4HwpaC8KS_JCwZxzh+$=;DHfq_f5)Bi#n#XvhQvQ$EJKG24
zS$a1}hOEI*m=$e+a0r*-7yU5MUU0$U_{>IQ<Zrwe%J;A1Aq{zb&^n7t6l+&;ju-is
z{ipaE)a76CZ}By!iV=_NI5LQg%Xqy=uoz2=Kja;Z!Q*&Adpg1719&HRxGj)NO7+v)
zX@WiQ>+0HzO&+D-#(18S5Y7H<nAuqy(F~RxI~tG*@-V6zz{w~jH=DBmkN5$`GyHTq
zuF`&m%eN8xfCJH|IGx0-9N6XK0D~w02MD^7@gO?F9BdEbQ*k5`!uKhCg42WXA}}DL
z6Xd7CwclV?9uTBJMFherI8<pKp>0SDAC|=o;{%FNu}mH?_uyZylyxE8ilEBu!fKMe
zx`JOZYyQSrAgd>d?H>IDW00Zy_V5@D@jw>~6o3g!so8;FHm)LX2GO?|)6Kxi1k9X2
z;7WT?O>&DUKM4p!Pd8u+ZxI7U6aiYr4OMIg4$iH@d0cU&jm_t;UzEs$jeKUE&uoD6
znWdkSZsX*FJ>x9OsmS~5sh4=;sut!YK{uP#*DnvM;83U(5aJg;5E%j&^FRq*Uk_BE
zt<V`L3kUi<S<SnQaKh12KOLcWV|_8TL|lpFLJk2M%4*EJGUMOMN<HQZmST7UNjk8q
zKl1_A4GJoWDQ5b%J>ECLOVbm3CK5~J38QuAnFu(M6{m%wWW_x&LpG5#ld$${O@>2V
zKn=iA&Z7kJZ{j{jYBaZl<DNW^DE9^WV0U!;4i(hut7!>%wY$lu6HK`ng9W@UL*<cB
zSBv3vMqG@!b2yw@7t#*7Pg9C94f18C9m+?JM@Hul0qXr4Oy&Ttg``6UDk}<p$n8_B
zEf4e{C-A|1)Zjpf<|g;cPJ>bnCV9#e>5z>v5(H6(Dl`<BthqvYRK)-_c7$~iEY#_C
zP2Sw8E}0(Bpt7P2h3CBd$6D~S?P@KNWW+a%<zaUU4CbuYiSq92w4>=E3Io=<(UAo;
z2L&KAL<5#POGEHMK_l2mHYNBGqm;S%Wwe4NmgG=o5Y>E0?#N}x{@!8d1R!#|sO4oo
zC0F4&Ybz)nr7Qf&Px<K&)RW+jV3w+t($f55$srMEhf#kkrPl{rbN^OyKdhFuf*dh?
zDr=*UP*R<TbmdJcg7HmBW*9UfFXF-Al?RD+_#KZ3A%6-k@LQVagA6HrigC+B{C!he
zEm;VqLX=4;yihh{Y)IGQD>Ci!eA#0<jTAU?d;iI}7dSr@A3P^^EhuM)x@J}+FgWc{
z!+#LA$AH=pQOi0E05XIlur?MWw{UFCc~cXZv++C}q~<L0)l>})=K%~niT-pUOw_9B
zPZk)20;n(w&TA?p)=$KHbw@4h&vw*QGlw%Z)hlf!qcu_CWu^0n=U4nrvdLJ$Eo;B9
z%oPmTpboBcS>`s7dt2x-E|MP_wpENjdRQxb0h!{vq046$GaA&Ve$7v9bCZK42>6fu
zUll|)E~l$ZYVnl`DJhjL6Qtf0fkU#?&@hwQ2iAnJn~*s}*M~s{^_|3(HAd>P655K8
zp{%(u7%2gYLpiS?<h!yMXf8KH0QxbqH3;=I`wH~3YB;TF1_3skRReed6@qxrV&q4}
za#(7Bx3~qrT!JCNEUY?6J!t(@xUzVA$(D2`F=p_lhJo^QLCUO_Ja+C2!od9uAa^TB
zMNoW2WuL+*NH_sh|K3j<Mqtx6d~Qd<Ou|ttk;XNqa|ES>T_f`_G&Nk#jL>YTH<b67
zN6n-G#f1)bC{PLV;0my;S7ZA6RP!Es&5DfQGCxrU>g1%dAE%N7y+R>C_B$GiG)Jx}
zZ)y=3&ce_x>5V8<t|Y&#qCm=?v618rLZ=o`z5uHZsKr^P5vral5F0yeOB+%x5Bi)c
zd6{Z<lr(Xd2rX*E6c;kIfXsX2Xf{kRECEZvjCdAlo{O1dl}{!(U&gW(3kRo7Yf?x#
zi-I}_tgk+O@bmfxtam>vhhcj>xU8jl@Tc_l?dsEosD^P2mXwxZdxXLa&8C<_Apo6g
z+KQv;LIo`aMugp~Cfu>{^Av=xZ(HR#0WU_!>$hZ5R>&jdUQRwDu89@})!B$T-7!T=
z(L#;4cc5xKC5G9=y=fVKV6qhr=RdqPV~`Dm8O*dyd1MI-ZPI{JJ*gNXn74Ougv4Fy
zE|+R<yZ-IBCXEic{m#uG60IP@*@64Bpr0o`l+H4A>2I_Ynqr-p7^1S$V7l=0n~#f&
zbNJ`q@c-xhvX1|6;>*(3+l2)=F~pe|9Q+}M5X2KMDhsp5%qR8+@Y?g70E{@P5w%tp
zB@JY@y(6{ATJibJJ@G&_a0uBXoA|!K?>*fnBVP>o5jLg%Rm>f^TOH2sgnWUUxvU-^
zk%7sTZ~0g9=mtLJ`@T0eMOeV26qJZRkt}oa*!LXvBdiJKKx$IN%NINl^&le#Z!Eho
zmB|xH;koHIgA`;yaPCJTMZ*RN6S6Hw`)LwuARUq9Xr-LfBj}i26nTlwu-tx!oY-(q
z97`VKGi9Ql9z=#|B~j0jChLU850%Odidr<wgmS3CWCAL=O|*%84uYAzw;%^$`-to!
z!zm45fRziS2~($Kqsh%XI2FmQrAK%{iM}foPzZ)n9OYs_&us)pqott%<ixHD#Dvy%
zKrtW;e1;|cg?#Wr5xM5Eo}_pt7Nh+nS|EK6-*?95HW3Oe3Z^X`NBh&4Ud*yr-JP1m
z$hyBbp^-Hy`@G!FG<0v9<9J*I;8)rl6HSeDi>CD5<Kup}3p+=$dt#y_l2%+DvY2m?
zSjZ!qv^pQC#2qzj?f0^*U{W1!>YLLPX2&(XB@>xiX?hY{iD?c~ZV6W_S`yQmqh<C8
zXIpDXQ;I}KN3bL66ib3f6*?ln7XJ1o{nNB$Et?LoKV4c3vM76MTnOz%^#fs3nqH3~
zNyZ#YY(jHG`K&J%loju2n$Uw}HWrnL`S)VkVjY$VhhoikVNx+1a$<`ZD2slAWrb@E
zsa&E3wu<C(I3`V(fmgwT5qu5@B%`7x%t=o?`426$^})@Z<jYKFD?)Y07`j{B2W*y3
z1B?lsJW~mQWCDC1B@?h0G9@UQN5CyzSY7LdvoLDm6SRzoIm<RHh@T-g?z^*exjKU!
zT?h>u@d1V|D8fIn|Aces`;hm=m$!0tVbp<}vyGcLdSKJ}f<suf@yb<6s7Xn2Z>%~1
zd%Xz}+noGL%?yW1{G%WiNeK!$zSr-bVkKsp3G)Qi)D?>}qTD#c8#`1*xbBiqarIlu
zQQdHG;%TfJpoY6m_-*sZ<^!IG5(F1_&SV_Q{|XbWtkrKcjD>;;{GSgLr|KGAN<WfN
z<D28Zzx)2t!^egA@1^e+AOFEEjs%)QqX>Gcbqmiv=O_6WvMT?<|NWdceuFyW`0oZ{
zM_?qC$SRq<@DErom@f3s^G;XxRPjY)&}PE5wYc7<)}@0`;sPcAuIrp*3x~J_IMs_E
zwtIkW=2~?N8uD?1Eg`u(IwFUp4$N>ohC!*>bqzt3C~oIzXB~nm=$v#9=NEHLv)u}%
zM9GRmnQ<44?8AjX)Z-XCm-Ul;JWkHIBL&ng<TR2yh=-s-;%C{cwTb~rxFByCI-<!I
z`)9^O`u(aEquPJ-hwzT#<J%p_e~;t8NnfOg-&Oqg{TVl5?ZoK!YRB&pW{5zbNZN}9
z=pb^LG89K|Gdl7y*y4^k?l!<Cs2h_Bh^@<RZJY&a^?$DV*PY$H>UI@@IOs6$2j;1F
zN%PG8)6E^br^ihQ+@!mTpLp(`BBYq#D|4*!4_p!U6#uL``3c1qao8|2p&b8RopC?U
zp#;qT(09QB59_syboDKs;?5;{ye^WIzdphWhI<D1)e`#g-gN$i*9x^alB53VdaKSS
zJr`V~Xz8i;Nj|(<9LLYQdk5RQJJq+;xKD&t|2#iGFTYU!t&DumSt&*&&9R_+YS_|(
zxYmn}!zRa2YnoKaH!YlZNJ%!+bWf>YOP8$SYv&%apbaLv?8O%q^q9L0n4)i!F15Kj
zrXWdWiYZd!*5l`#{Z|*&|9a{Cy=km0b8(7*G2hGJJ#R`koSR{tAGxQCys2P`4dDDb
z1M=-;LB2OyXNWJz#zppw_MU2k0b;t%lsYAc6s*@D8t{2WxG++68wr9(>M(X8)LiLR
z#4)X|G})gbs0@ZI<n+gx2VSVtO?ZDcY0>T>i(LIODa0fPkeoF;7xQK}mw<jgChCVi
z^m?~=oBfY@_9UdlU_1$*^Cn$ce_88F527X@aG1vd7JOa86UA}xCk$yPPy#|Il31Pb
zTRigVEQ@e?<K6+%qXjAH#erHR%lswY7fE@ET1)e8t&SVaG4;tuY~Z*q=LbXfw?Opq
zxri4D*iCPF`6b-6dQxKj90@7u*KzKrTGvLzUk3oIaQwhCBY%6W;)?}!5(npyYL#bi
z*)aye8i@+=fFLhHg5FYA=+I2@f$zbRkMeSfA)}Ey&1UCZXlYVTq-eXad523Ah8)b8
zaX$<_u;G@m6)pz(-p@G=+6BM#n8pFfS<kX($278MA$x&8)giBBVI)XIKJ4j074^zI
ze07oj(#)#tg_!Q_8O%h;$OiBK1x&*U@6f=7B5F<sZ+yh#H9wG|l%VQIc!*!56VJvN
zJ~59cP`>dWS&ZnzT<o&G=5;=$DiS!|o7Yj@kR-S&BXlKfp1;H>s6XYl3JJCq@{ZPX
zc+Y@TG399eOWIJtx+E{(Wa%}}76{?oD!N!N2rmA(qs)<_pD1;t&gaV=ss2ThM*;Xe
z*&}s7Px@%LvJ{xA0dkk(B3x?<5ok~5D53a@44Kk{bctx@qXc|UpK#vU9zTN(fs$D@
zC$m&qka21+4C0n1tk-KmqIeNl=G<%lwE$M_1PYzNd5=)RMF8{LfV2LK9)#7#sP**|
zvVwhly9QTwnYkiSu}3D+c6&Uu2Sm28!3{U*P3grwl7JrfhB>(#w|#-#Hmm}tbflbj
zA?m=Nct@ygxMk;zNC;e(PU9`05jKU1ps>WxEoJ}|_1CM35imubpsPN`>OVmc7#w*N
zYwwT+9%o}3P3Z64PAkwFyA!@)n5az8*d4LVBEs%7Gw|eu#M-WJy<l(+JUm*UM7^yj
zrFfVSScxwWSjG{s8acB@>{@MjjB#2BlN?f)tlLe$e8fKdZ%yRq)BHUJ7^{?G6Kbo)
z&!`OmO?t(#NnIHZcN*53l~UXu9Xu0LG)JQoR2W`D)2B>7(<CWzD*rnS83%4QC67O`
z%lVI{4L&wQ!Rl;ubpmL8Xu=ll|89K(W0{Jo1e<l{(~`?k4S%5Y4PlXKuw>}e<hZ&$
zz41GD9Xch<9>ZUHmx2w0=r@VO)@0d^VBw0C%od5<aZt6prLa`il+=M}8l;GGf=)kS
zuL=E(v>&b&#q{vD5(G^m;@7TR$gL(Ua;k!UMcuABv#&cT&bI2{Pwgr2Sal>-kYoN%
zhbWXn{As}nGZ;tV8-UZAceYo1NCCd$%KEFUOF_IZjBgIFIrgL;z0PjkU~T&qy@wdU
zrpdRi)erR{xXndWGP`(&E!i);_kiMfo}gcjb$}5_U-+wy;fqxv4l0Yd*)ROZg->)*
z4DwE9e+w;Tq$dWs#Egab$s-l?%WD{U^-jPQf-UIe=kM4(e{Dq_IM84f`TI^4GyKZ+
z%{uBk)eM-oF7@}Fs%BH6o!W0-mtJmsZ24AXLL9D~5LlV76b0^I2Fp_BJ`HOO+d!|Y
zAp9gf>$HVoiqfNrs$`#vlU7=cFH#kjb0WO;v6)XIK8rHgdQ-foZf*a?PY&BOHE0~c
zCIBg35|z0m#nyT~TG-K+ZvMjNfRWS4wS{f4>R~+b)u?ORFFQU0Te~&efbdH#5e63z
zM^1dnwjO&<806)0VuY5_G>^eW)%SCQX3ptG`$Ok_U~Yf~dPIvb3WFmTih5EQEXY6^
zc^emZY3zjJ5QEp95jH`>=5=o*jc}-VETVu-ZHx853d&vy2Xh-I%-KClW~<R{xO&*6
z5T0i{V~0Jhw#{x-yigSlAS+aUGsd9y;~Fgq-lsrF!nPevK@(Ho1G))=_g!mE4RGY%
zPGuNnn$}ElRA0ffOGnpFPA|n`h?o}YTfCX{Drc2B1OSJZJaToF2_ZSV0z82YrpIV{
z%_vN4ARh97OtmuT1ySf7B*@XDU8852iDxV>hArBZ)?l^<Nx=9}gC-b|rSG#{t1>gT
z2#nJgqeLMwjou&=)Jy3>?lu+!VAh2IiqSKq5If;8yP!Mv>`JgMYHQ5WCggyaNnBki
z(i9^?DL_C#xk&Y<XHX8tp+u&O6u9QdP)sIB)*P)bFs+~sEz`WvX`42C3+njND208o
z%%5S<niaB(ddsS!J0XHRd5{q0yel|APP2<C2UI15N8+FckQvo-#E|<T_PTj7glCHh
zbr1Y%#0<w+z?D*X3lm3A{B4-q%-m6fIwJl#%k}_UA8nZ6T(w?}MCoeB$GpWD>HyBS
z;*y6XCZ2m&ieT@c=715%veolPe8L&_gij&g#--|z@OTvwaQ55CO&)0AIW`GFS7(Ee
zY1r^We;oEW|19iCa}ChN!05zD>dL~}k;MWQ&&o65{wuh+gxUirFC;Gz+b(y>(Q-M)
zSz6|z#08LvCpn`tl8-9GI5-14s$?LbhVPehC}8{$vnP|q)#HzpbGqDf9G?k=aaVg=
z%#UHg0j?M(xsDpOAcsI4K%DS98I>6XtRo5rxt$^I4HdU=Hb|DREeYw{%v*SkOVp9{
zC)cH|bMs#Si>HkbNgHJ!&gdQQbR;uf+y^*p_O@Rf`iwE_yE|KEsz>SXqSDxM@VW$9
zEi56|aHGs4D?>d>sV!T$n0Fp{qoAmeNE&#s_=JC-I+<2}|Mpw%ku-dBnppXHy787e
zUP-(!C4Gxfz+Ah&B($BSx2hwjaDg8uN-t1C8?zX#zR^2d8F_gn`FP@{*pc-?Y8!6v
zC0cOL@-?93Ov74~{f4u4RMFxtft83c#fSy66iO00bsw4bLFGtRbzsMaW`fU)vvCX=
zch!N*fa@~y>XJHQCMZ#wM30x)S4SlkS6Ml37PHs7Wz2pHV&l9-1EvJATNZ2y(CF5O
zZE~}AEogOT_aFqVsv*h!>8x@3C;A+JpT5Y+NjoN_l)Lzr2Y(j+Hn-r3id14Be+eV_
zwk77EU1nMI;L0M7%HtXpSt*NenH>dGqxVAEGi!P7hh_y?L4KH)E+!@{#|Ew)&E!FN
zW|wGtGlp+IG}Wtky=F**XMI?yBEbQU_pWh*+rs^TZW$MEA%3yH`+9H4z$R{ktPaS$
z`*R3vMNxO>5qB$eh@A~-G8?YR#W3D*b2DzO;Bp*5WBsTC<PT{R*H&`2L$Get(lt%t
zf?haGYrSEOK{w&6PiZa)@Ii73uRguK>l#B#a-sHZlk0Vb!FK$cAuUb09Zjm?g*NRC
z&?!U^{{!I*PG(RJ^Vo)wc2>0)Q%Ca}2Co;Co!$)^MQ}4oTIBb**FBrVY5DmtmtvjI
z{jjirb(-U^e9ybbjV7`9TJO1iskonGj!jNn+}(g5zs0@{mlZ8Oe*8F&>yKFdH5I|>
zb6}KTZ*P>Z{N2(KcgU9-0s;<O=XB}xP!d1~$wUC8acT^qVG+4S7>p;WoUtF!_q_g!
zM1hhp0&kd&A~beaD>k@iY{j+?peC3VTVm{8X=TJ8Vb<2y%iR|*ws&5*eNB!8e>^X>
zcgN>-9)4f&=!&b17`hed3#!MqB%HInKy>+n`D0I|jDU`(S)485X}EUhTs10v<z*Rp
z--B#V;2%>Ah$%c|D^zt0d)};R({5vH4Aw4n<H*tF6A-9i0lJ=Y>%mRVDoKqoljk+$
ze8ckAmib71Tr{BIJ2d-w87`YJJ6fc3#qe0mBF%K}I5*)&@d1wsXpOcdg3Mh)h&mDY
zqODTsp1QGaoxEli;SP%cY-pYFncRrvl|ec2$dRG?<b;`3y;U_VLs48+qR2u#q<XEM
z0I($S)?lU5w2Hv~P)i@dJ%4?(s2xzJJK|mgfm{OU0cd7Jc7=A#E88Z*+qj~66z#o5
z5G*faj}+Id5G|&}XFe2amdoa1MN<Q(oH$0DX*V3A1X_^Ev)iSWXux50l9TS-DvXE6
z@AtZJyuq25A`wt3U4uVhrVRkio+FK`U&*(Vd6)bXfpwj2()M#^?V?q2StRx4%yYyl
zaw1F|S*ol{GZAzO=a)mI)4}yC#w|=xwirGSGEp?X9I!2MW^lDigJOWnK>I{&ohAs}
z1{H3==5n8)`F6#aBPs<Zl=pOgB7DLVx~*(7?h{CB94ip&AK}Z;sHZhyYhY9j??0r)
zW(Y0b%;zARLSDf6px~Fl^QwKZZJogBowZ(sA!BU9{lGmkX_M9(h(imCoj}hVaPYgE
z<pd1Sgp!vSp6!d5K~3{C64NH5rX6$f!!CHvAO~>JZX=at3Hz5g8e`L}#>=4;62pNe
z$-;XbwC91ES83;edcpQJ$vY3*?^@!K19~It*D6v#yOXgxP{_wZ{|n6@STK^|4oZru
zS0V?G-a!O%sw72pMYn$>C&+sBW)*!|*gMpv7L$%<Cg)$8m7K^f*N>`67Z%X+6{J@z
z%<+aSk!EPvvWk0=GOnJgtM-j<=2nFfAAo`E<HqycCR(aW8OX*^BG;3)rP7m183ix~
zW{NNC5Ib1yFwF+jIE?psc(oNl+C+@#sQ&deI6J^}&ZI7;NO3%K4zSHL>#|?QaVNYH
zeW(fRX5|izD!}Zapwr<Uac9aLI5nf-B`v!mFShFfGmwU|EghL&=iTr_^hJP~L;0Jw
z+z?N_Yx-~n<|hoz^h2tEg|fVDRO5oo1#H@$+}|^x>&a7*fxwQaKKN%q+tUkzuGjVS
zz0#(9pIZfuRo>*xQu-@cZ8!=gQv3^wo^@|>^n$0DGyH4z6fJ86eKpA{bF0jB<Cn>h
zMW9=ATi;j)Q_xo#O{FR8MIfa(9tNv}MB%~KpZR!^hNMR~96WmPJFpjx+g)B3O5I0v
zOtY6(27t!8#3nh{lw;UbMBnlnDcI@uL%Z%;Zk35=i9E_SgI>-I-46Pfer0{FJFDM=
zoVjJ|Qb%gUdr)@I;WGeH1Vvn%Rb5wH#5kORy^NpOPt<wg@jd$@HMa;J8!YISp9qp4
z$-RQ*8~rlSOo@MO@w!}LUj(Hx(=fGn-y`_pjB1yVwO>G(-<yL$+de_VMY$aZ6J`7z
z{X-TsR^Wi(bievF%)i0O?{Sx742&@_#=sZ@V+@QjFvh?b17i$~F)+r!7z1Mrj4?3A
Uz!(E#42&@_#=sZ@|CcfFziX&hYybcN

literal 0
HcmV?d00001

diff --git a/src/e2e/scripts/create_test_db.sql b/src/e2e/scripts/create_test_db.sql
new file mode 100644
index 0000000..cd9298a
--- /dev/null
+++ b/src/e2e/scripts/create_test_db.sql
@@ -0,0 +1,5 @@
+CREATE USER 'hivetest'@'localhost' IDENTIFIED BY 'hivetest';
+CREATE DATABASE hivetestdb DEFAULT CHARACTER SET latin1 DEFAULT COLLATE latin1_swedish_ci;
+GRANT ALL PRIVILEGES ON hivetestdb.* TO 'hivetest'@'localhost' WITH GRANT OPTION;
+GRANT FILE ON *.* TO 'hivetest'@'localhost' IDENTIFIED BY 'hivetest';
+flush privileges;
diff --git a/src/e2e/tests/cmdline.conf b/src/e2e/tests/cmdline.conf
new file mode 100644
index 0000000..8cd6b69
--- /dev/null
+++ b/src/e2e/tests/cmdline.conf
@@ -0,0 +1,56 @@
+#!/usr/bin/env perl
+
+############################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+###############################################################################
+# Nightly tests for hive.
+#
+#
+
+$cfg = {
+  'driver' => 'HiveCmdLine',
+  'groups' => [ {
+      'name' => 'Example',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "describe studenttab10k;",
+          'rc'  => 0,
+          # Don't mess with the tabs in the next few lines, they're important
+          'expected_out' => 'name	string	
+age	int	
+gpa	double	
+',
+          'not_expected_regex_err' => 'FAILED'
+        }, {
+          'num' => 2,
+          'hivecmdargs' => ['-e', 'show tables;'],
+          'expected_regex_out' => 'studenttab10k',
+          'rc'  => 0,
+        }, {
+          'num' => 3,
+          'sql' => "describe nosuchtable;",
+          'rc'  => 0,
+          'expected_regex_out' => 'Table nosuchtable does not exist',
+        }, 
+      ]
+    }
+  ],
+},
+;
+
+
+
diff --git a/src/e2e/tests/nightly.conf b/src/e2e/tests/nightly.conf
new file mode 100644
index 0000000..41c0d1c
--- /dev/null
+++ b/src/e2e/tests/nightly.conf
@@ -0,0 +1,1018 @@
+#!/usr/bin/env perl
+
+############################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+###############################################################################
+# Nightly tests for hive.
+#
+#
+
+$cfg = {
+  'driver' => 'Hive',
+  'groups' => [ {
+      'name' => 'Checkin',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => q\select * from studenttab10k;\,
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+        }, {
+          'num' => 2,
+          'sql' => q\select registration, sum(contributions) s
+                     from studenttab10k s join votertab10k v
+                         on (s.name = v.name and s.age = v.age)
+                     where s.age < 50 and v.age < 50
+                     group by registration
+                     order by s\,
+          'sortArgs' => ['-t', '	', '+1', '-2'],
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+        }, {
+          'num' => 3,
+          'sql' => q\drop table if exists checkin_3;
+                     create table checkin_3 as
+                     select name, count(1)
+                     from studenttab10k 
+                     group by name
+                     having count(1) > 5\,
+          'result_table' => 'checkin_3',
+          'verify_sql' =>q\select name, count(1)
+                     from studenttab10k 
+                     group by name
+                     having count(1) > 5\,
+        }, {
+          'num' => 4,
+          'sql' => q\select avg(gpa) average
+                     from studentparttab30k
+                     where age > 50\,
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+        }
+      ]
+    },{
+      'name' => 'SelectExpression',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select t + 10, t - 10, t * 10, t / 10, t % 10
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 2,
+          'sql' => "select t + 10.10, t - 10.10, t * 10.10, t / 10.0
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 3,
+          'sql' => "select si + 10, si - 10, si * 10, si / 10, si % 10
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 4,
+          'sql' => "select si + 10.10, si - 10.10, si * 10.10, si / 10.0
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 5,
+          'sql' => "select i + 10, i - 10, i * -1, i / 10, i % 10
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 6,
+          'sql' => "select i + 10.10, i - 10.10, i * 10.10, i / 10.0
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{ # division removed because I can't get hive and mysql to do their
+          # floating point arithmetic in the same way.
+          'num' => 7,
+          'sql' => "select b + 10, b - 10, b * -1, b % 10
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+#     },{ has floating point precision issues
+#         'num' => 8,
+#         'sql' => "select b + 10.10, b - 10.10, b * 10.10, b / 10.0
+#                   from all100k;",
+#         'floatpostprocess' => 1,
+#         'delimiter' => '	',
+      },{
+          'num' => 9,
+          'sql' => "select f + 10, f - 10, f * 1.01, f / 10
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 10,
+          'sql' => "select f + 10.10, f - 10.10, f * 10.10, f / 10.0
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 11,
+          'sql' => "select d + 10, d - 10, d * 10, d / 10
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 12,
+          'sql' => "select d + 10.10, d - 10.10, d * 1.01, d / 10.0
+                    from all100k;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },
+    ]
+  },{
+      'name' => 'WhereExpression',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select t
+                    from all100k
+                    where t = -91 and si = -19299 and i = -1591211872 
+                        and b = -4485904205832126464 and bool = false
+                        and s = 'katie young';",
+      },{
+          'num' => 2,
+          'sql' => "select t
+                    from all100k
+                    where f > 48308 and f < 48309;"
+      },{
+          'num' => 3,
+          'sql' => "select t
+                    from all100k
+                    where d = -2806609.87;",
+      },{
+          'num' => 4,
+          'sql' => "select t
+                    from all100k
+                    where t = 87 or si = 4931;",
+      },{
+          'num' => 5,
+          'sql' => "select t
+                    from all100k
+                    where i <> 1096589477;",
+      },{
+          'num' => 6,
+          'sql' => "select t
+                    from all100k
+                    where t > 0 and si > 0 and i > 0 and b > 0 and f > 0.0 and
+                    d > 0.0 and s > 'm';",
+      },{
+          'num' => 7,
+          'sql' => "select t
+                    from all100k
+                    where t >= 0 and si >= 0 and i >= 0 and b >= 0 and f >= 0.0
+                    and d >= 0.0 and s >= 'm';",
+      },{
+          'num' => 8,
+          'sql' => "select t
+                    from all100k
+                    where t < 0 and si < 0 and i < 0 and b < 0 and f < 0.0 and
+                    d < 0.0 and s < 'm';",
+      },{
+          'num' => 9,
+          'sql' => "select t
+                    from all100k
+                    where t <= 0 and si <= 0 and i <= 0 and b <= 0 and f <= 0.0
+                    and d <= 0.0 and s <= 'm';",
+      },{
+          'num' => 10,
+          'sql' => "select name
+                    from studentnull10k
+                    where age is null;",
+          'nullpostprocess' => 1,
+      },{
+          'num' => 11,
+          'sql' => "select name
+                    from studentnull10k
+                    where age is not null;",
+          'nullpostprocess' => 1,
+      },{
+          'num' => 12,
+          'sql' => "select age
+                    from studenttab10k
+                    where name like '_uke king';",
+      },{
+          'num' => 13,
+          'sql' => "select age
+                    from studenttab10k
+                    where name like '% king';",
+      },{
+          'num' => 14,
+          'sql' => "select age
+                    from studenttab10k
+                    where name regexp '.* king';",
+      },{
+          'num' => 15,
+          'sql' => "select age
+                    from studenttab10k
+                    where name rlike '.* king';",
+          'verify_sql' =>"select age
+                    from studenttab10k
+                    where name regexp '.* king';",
+      }
+    ]
+  },{
+      'name' => 'WherePartition',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds = '20110924';",
+      },{
+          'num' => 2,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds = '20110924' or ds = '20110925';",
+      },{
+          'num' => 3,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds > '20110924';",
+      },{
+          'num' => 4,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds >= '20110924';",
+      },{
+          'num' => 5,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds <= '20110926';",
+      },{
+          'num' => 6,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds < '20110926';",
+      },{
+          'num' => 7,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds <> '20110926';",
+      }
+    ]
+  },{
+      'name' => 'Distinct',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select distinct name
+                    from studenttab10k;",
+      },{
+          'num' => 2,
+          'sql' => "select distinct name, age
+                    from studenttab10k;",
+      }
+    ]
+  },{
+      'name' => 'All',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select all name
+                    from studenttab10k;",
+      }
+    ]
+  },{
+      'name' => 'Join',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select registration
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name);",
+      },{
+          'num' => 2,
+          'sql' => "select registration
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name and s.age = v.age);",
+      },{
+          'num' => 3,
+          'sql' => "select registration
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name) join studentparttab30k p
+                        on (p.name = v.name)
+                    where s.age < 25 and v.age < 25 and p.age < 25;",
+      },{
+          'num' => 4,
+          'sql' => "select registration
+                    from studenttab10k s left outer join votertab10k v
+                        on (s.name = v.name);",
+          'nullpostprocess' => 1,
+      },{
+          'num' => 5,
+          'sql' => "select registration
+                    from studenttab10k s right outer join votertab10k v
+                        on (s.name = v.name);",
+          'nullpostprocess' => 1,
+#     },{
+#         'num' => 6,
+#         'sql' => "select registration
+#                   from studenttab10k s full outer join votertab10k v
+#                       on (s.name = v.name);",
+#         'nullpostprocess' => 1,
+#         'verify_sql' => "select registration
+#                          from studenttab10k s left join votertab10k v
+#                              on (s.name = v.name)
+#                          union all
+#                          select registration
+#                          from votertab10k v left join studenttab10k s
+#                              on (s.name = v.name);",
+      },{
+          'num' => 7,
+          'sql' => "select registration
+                    from studenttab10k s join votertab10k v
+                    where s.age < 25 and v.age < 25;",
+      }
+    ]
+  },{
+      'name' => 'GroupBy',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select count(*)
+                    from studentparttab30k;",
+      },{
+          'num' => 2,
+          'sql' => "select name, count(*)
+                    from studenttab10k
+                    group by name;",
+      },{
+          'num' => 3,
+          'sql' => "select name, avg(age)
+                    from studentparttab30k
+                    group by name;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 4,
+          'sql' => "select name, sum(contributions)
+                    from votertab10k 
+                    group by name;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 5,
+          'sql' => "select name, age, max(contributions)
+                    from votertab10k 
+                    where registration = 'democrat'
+                    group by name, age;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 6,
+          'sql' => "select name, min(contributions)
+                    from votertab10k 
+                    where registration = 'green'
+                    group by name;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 7,
+          'sql' => "select name, min(age)
+                    from votertab10k 
+                    group by name;",
+      },{
+          'num' => 8,
+          'sql' => "select name, max(age)
+                    from votertab10k 
+                    group by name;",
+      },{
+          'num' => 9,
+          'sql' => "select age, max(name)
+                    from votertab10k 
+                    group by age;",
+      },{
+          'num' => 10,
+          'sql' => "select age, min(name)
+                    from votertab10k 
+                    group by age;",
+      },{
+          'num' => 11,
+          'sql' => "select registration, sum(contributions)
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name)
+                    group by registration;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      }
+    ]
+  },{
+      'name' => 'GroupByDistinct',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select name, count(distinct registration)
+                    from votertab10k
+                    group by name;",
+        },{
+          'num' => 2,
+          'sql' => "select name, count(distinct registration), count(age)
+                    from votertab10k
+                    group by name;",
+      },{
+          'num' => 3,
+          'sql' => "select name, count(distinct registration), count(distinct age)
+                    from votertab10k
+                    group by name;",
+      },{
+          'num' => 4,
+          'sql' => "select s.name, count(distinct registration)
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name)
+                    group by s.name;",
+      }
+    ]
+  },{
+      'name' => 'Having',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select name, sum(age)
+                    from votertab10k
+                    group by name
+                    having sum(age) > 1000;",
+      },{
+          'num' => 2,
+          'sql' => "select age
+                    from votertab10k
+                    group by age
+                    having sum(age) > 1000;",
+      },{
+          'num' => 3,
+          'sql' => "select age, count(distinct name)
+                    from votertab10k
+                    group by age
+                    having count(distinct name) > 50;",
+      },{
+          'num' => 4,
+          'sql' => "select registration, sum(contributions)
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name)
+                    group by registration
+                    having sum(contributions) > 100.0;",
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      }
+    ]
+  },{
+      'name' => 'OrderBy',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select name
+                    from studenttab10k
+                    order by name;",
+          'sortArgs' => ['-t', '	', '-k', '1,1'],
+      },{
+          'num' => 2,
+          'sql' => "select age
+                    from studenttab10k
+                    order by age;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+      },{
+          'num' => 3,
+          'sql' => "select gpa
+                    from studenttab10k
+                    order by gpa;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 4,
+          'sql' => "select age
+                    from studentnull10k
+                    order by age;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+      },{
+          'num' => 5,
+          'sql' => "select t
+                    from all100k
+                    order by t;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+      },{
+          'num' => 6,
+          'sql' => "select si
+                    from all100k
+                    order by si;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+      },{
+          'num' => 7,
+          'sql' => "select b
+                    from all100k
+                    order by b;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+      },{
+#         'num' => 8,  bools not loaded in mysql correctly
+#         'sql' => "select bool
+#                   from all100k
+#                   order by bool;",
+#     },{
+          'num' => 9,
+          'sql' => "select d
+                    from all100k
+                    order by d;",
+          'sortArgs' => ['-t', '	', '-k', '1n,1n'],
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 10,
+          'sql' => "select name, count(*) cnt
+                    from studenttab10k
+                    group by name
+                    order by cnt;",
+          'sortArgs' => ['-t', '	', '-k', '2n,2n'],
+      },{
+          'num' => 11,
+          'sql' => "select name, age
+                    from studenttab10k
+                    order by name, age;",
+          'sortArgs' => ['-t', '	', '-k', '1,1', '-k', '2n,2n'],
+      },{
+          'num' => 12,
+          'sql' => "select name
+                    from studenttab10k
+                    order by name desc;",
+          'sortArgs' => ['-t', '	', '-r', '-k', '1,1'],
+      },{
+          'num' => 13,
+          'sql' => "select age
+                    from studenttab10k
+                    order by age desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+      },{
+          'num' => 14,
+          'sql' => "select gpa
+                    from studenttab10k
+                    order by gpa desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 15,
+          'sql' => "select age
+                    from studentnull10k
+                    order by age desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+      },{
+          'num' => 16,
+          'sql' => "select t
+                    from all100k
+                    order by t desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+      },{
+          'num' => 17,
+          'sql' => "select si
+                    from all100k
+                    order by si desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+      },{
+          'num' => 18,
+          'sql' => "select b
+                    from all100k
+                    order by b desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+      },{
+#         'num' => 19, bools not loaded into mysql correctly
+#         'sql' => "select bool
+#                   from all100k
+#                   order by bool desc;",
+#     },{
+          'num' => 20,
+          'sql' => "select d
+                    from all100k
+                    order by d desc;",
+          'sortArgs' => ['-t', '	', '-k', '1rn,1rn'],
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+      },{
+          'num' => 21,
+          'sql' => "select name, age
+                    from studenttab10k
+                    order by name, age desc;",
+          'sortArgs' => ['-t', '	', '-k', '1,1', '-k', '2nr,2nr'],
+      },{
+          'num' => 22,
+          'sql' => "select name, age
+                    from studenttab10k
+                    order by name desc, age;",
+          'sortArgs' => ['-t', '	', '-k', '1r,1r', '-k', '2n,2n'],
+      },{
+          'num' => 23,
+          'sql' => "select name, age
+                    from studenttab10k
+                    order by name desc, age desc;",
+          'sortArgs' => ['-t', '	', '-k', '1r,1r', '-k', '2rn,2rn'],
+      },{
+          'num' => 24,
+          'sql' => "select registration, s.name
+                    from studenttab10k s join votertab10k v
+                        on (s.name = v.name)
+                    order by s.name;",
+          'sortArgs' => ['-t', '	', '-k', '2,2'],
+      }
+    ]
+  },{
+      'name' => 'Insert',
+      'tests' => [ {
+          'num' => 1, # insert map only
+          'sql' => "drop table if exists insert_1;
+                    create table insert_1 (
+                       name string,
+                       age int)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+                    insert overwrite table insert_1
+                    select name, age
+                    from studenttab10k
+                    where age > 50;",
+          'result_table' => 'insert_1',
+          'verify_sql' =>"select name, age
+                    from studenttab10k
+                    where age > 50;",
+        },{ 
+          'num' => 2, # insert reduce side
+          'sql' => "drop table if exists insert_2;
+                    create table insert_2 (
+                       name string,
+                       avgage double)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+                    insert overwrite table insert_2
+                    select name, avg(age) as avgage
+                    from studenttab10k
+                    group by name;",
+          'result_table' => 'insert_2',
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+          'verify_sql' =>"select name, avg(age)
+                    from studenttab10k
+                    group by name;",
+#       },{ # Commented out until we switch to Hive 0.8
+#         'num' => 3, # insert map only overwrite
+#         'sql' => "create table if not exists insert_3 (
+#                      name string,
+#                      age int)
+#                   row format delimited
+#                   fields terminated by '\\t'
+#                   stored as textfile;
+#                   insert into table insert_3
+#                   select name, age
+#                   from studenttab10k
+#                   where age > 50;
+#                   insert overwrite table insert_3
+#                   select name, age
+#                   from studenttab10k
+#                   where age > 30;",
+#         'result_table' => 'insert_3',
+#         'verify_sql' =>"select name, age
+#                   from studenttab10k
+#                   where age > 30;",
+#       },{# Commented out until we switch to Hive 0.8
+#         'num' => 4, # insert reduce side overwrite
+#         'sql' => "create table if not exists insert_4 (
+#                      name string,
+#                      age double)
+#                   row format delimited
+#                   fields terminated by '\\t'
+#                   stored as textfile;
+#                   insert into table insert_4
+#                   select name, avg(age) as avgage
+#                   from studenttab10k
+#                   group by name;
+#                   insert overwrite table insert_4
+#                   select name, avg(contributions)
+#                   from votertab10k
+#                   group by name;",
+#         'result_table' => 'insert_4',
+#         'verify_sql' =>"select name, avg(contributions)
+#                         from votertab10k
+#                         group by name;",
+        },{
+          'num' => 5, # insert partition 
+          'sql' => "drop table if exists insert_5;
+                    create table insert_5 (
+                       name string,
+                       age int)
+                    partitioned by (ds string)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+                    insert overwrite table insert_5 partition (ds='20110924')
+                    select name, age
+                    from studentparttab30k
+                    where ds = '20110924'
+                    order by name;",
+          'result_table' => 'insert_5',
+          'verify_sql' =>"select name, age, ds
+                    from studentparttab30k
+                    where ds = '20110924';",
+#       },{# Commented out until we switch to Hive 0.8
+#         'num' => 6, # insert partition overwrite
+#         'sql' => "create table if not exists insert_6 (
+#                      name string,
+#                      age int)
+#                   partitioned by (ds string)
+#                   row format delimited
+#                   fields terminated by '\\t'
+#                   stored as textfile;
+#                   insert into table insert_6 partition (ds='20110925')
+#                   select name, age
+#                   from studenttab10k
+#                   order by name;
+#                   insert overwrite table insert_6 partition (ds='20110925')
+#                   select name, age
+#                   from studentparttab30k
+#                   where ds = '20110925'
+#                   order by name;",
+#         'result_table' => 'insert_6',
+#         'verify_sql' =>"select name, age, ds
+#                         from studentparttab30k
+#                         where ds = '20110925';",
+        },{
+          'num' => 7, # insert multiple partitions
+          'sql' => "drop table if exists insert_7;
+                    create table insert_7 (
+                       name string,
+                       age int)
+                    partitioned by (ds string)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+                    insert overwrite table insert_7 partition (ds)
+                    select name, age, ds
+                    from studentparttab30k
+                    order by name;",
+          'result_table' => 'insert_7',
+          'verify_sql' =>"select name, age, ds
+                          from studentparttab30k;",
+          'hiveconf' => [ "hive.exec.dynamic.partition.mode=nonstrict",
+                            "hive.exec.dynamic.partition=true"],
+        }
+    ]
+  },{
+      'name' => 'MultiInsert',
+      'tests' => [ {
+          'num' => 1, # insert map only
+          'sql' => "drop table if exists multi_insert_1_1;
+                    drop table if exists multi_insert_1_2;
+                    drop table if exists multi_insert_1_3;
+
+                    create table multi_insert_1_1 (
+                       name string,
+                       ds string)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    create table multi_insert_1_2 (
+                       name string,
+                       ds string)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    create table multi_insert_1_3 (
+                       name string,
+                       ds string)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    from studentparttab30k
+                    insert overwrite table multi_insert_1_1
+                    select name, ds
+                    where ds = '20110924'
+
+                    insert overwrite table multi_insert_1_2
+                    select name, ds
+                    where ds = '20110925'
+
+                    insert overwrite table multi_insert_1_3
+                    select name, ds
+                    where ds = '20110926';",
+          'result_table' => ['multi_insert_1_1',
+                             'multi_insert_1_2',
+                             'multi_insert_1_3'],
+          'verify_sql' =>["select name, ds
+                           from studentparttab30k
+                           where ds = '20110924';",
+                          "select name, ds
+                           from studentparttab30k
+                           where ds = '20110925';",
+                          "select name, ds
+                           from studentparttab30k
+                           where ds = '20110926';"]
+        },{ 
+          'num' => 2, # insert reduce side
+          'sql' => "drop table if exists multi_insert_2_1;
+                    drop table if exists multi_insert_2_2;
+                    drop table if exists multi_insert_2_3;
+
+                    create table multi_insert_2_1 (
+                       name string,
+                       avgage double)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    create table multi_insert_2_2 (
+                       name string,
+                       age  int,
+                       sumgpa double)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    create table multi_insert_2_3 (
+                       name string,
+                       distage bigint)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    from studenttab10k
+                    insert overwrite table multi_insert_2_1
+                    select name, avg(age) as avgage
+                    group by name
+                    
+                    insert overwrite table multi_insert_2_2
+                    select name, age, sum(gpa) as sumgpa
+                    group by name, age
+
+                    insert overwrite table multi_insert_2_3
+                    select name, count(distinct age) as distage
+                    group by name;
+                    ",
+          'result_table' => ['multi_insert_2_1',
+                             'multi_insert_2_2',
+                             'multi_insert_2_3'],
+          'floatpostprocess' => 1,
+          'delimiter' => '	',
+          'verify_sql' =>["select name, avg(age)
+                           from studenttab10k
+                           group by name;",
+                          "select name, age, sum(gpa)
+                           from studenttab10k
+                           group by name, age;",
+                          "select name, count(distinct age)
+                           from studenttab10k
+                           group by name;"],
+        },{
+          'num' => 3, # partition
+          'sql' => "drop table if exists multi_insert_3;
+
+                    create table multi_insert_3 (
+                       name string)
+                    partitioned by (ds string)
+                    row format delimited
+                    fields terminated by '\\t'
+                    stored as textfile;
+
+                    from studentparttab30k
+                    insert overwrite table multi_insert_3
+                        partition (ds = '20110924')
+                    select name
+                    where ds = '20110924'
+
+                    insert overwrite table multi_insert_3
+                        partition (ds = '20110925')
+                    select name
+                    where ds = '20110925'
+
+                    insert overwrite table multi_insert_3
+                        partition (ds = '20110926')
+                    select name
+                    where ds = '20110926';",
+          'result_table' => 'multi_insert_3',
+          'verify_sql' =>"select name, ds
+                          from studentparttab30k;",
+        }
+    ]
+  },{
+      'name' => 'Subquery',
+      'tests' => [ {
+          'num' => 1,
+          'sql' => "select name, age
+                    from (select name, age, gpa
+                          from studenttab10k
+                          union all
+                          select name, age, gpa
+                          from studentparttab30k
+                          where ds = '20110924') t1
+                    where age < 25;",
+          'verify_sql' => "select name, age
+                          from studenttab10k
+                          where age < 25
+                          union all
+                          select name, age
+                          from studentparttab30k
+                          where ds = '20110924' and age < 25;"
+        },
+    ]
+  },{
+      'name' => 'Limit',
+      'tests' => [ {
+ 	'num' => 1,
+          'sql' => "select name
+                    from studentparttab30k
+                    where ds = '20110924'
+                    limit 5 ;",
+        },{
+          'num' => 2, #This test fails. Need to investigate more
+          'sql' => "select name,age
+                    from studenttab10k
+                    order by name desc, age limit 10; ",
+      }
+  ]
+  },{ 
+      'name' => 'SortBy',
+      'tests' => [ {
+          'num' => 1, 
+          'sql' => "select name
+                    from studenttab10k
+                    sort by name;",
+          'verify_sql' =>"select name
+                    from studenttab10k
+                    order by name;",
+        }
+    ]
+  },{ 
+      'name' => 'SelectRegex',
+      'tests' => [ {
+         'num' => 1,
+          'sql' => "select `a[g]+e`
+                from studenttab10k
+                order by age;",        
+          'verify_sql' => "select age
+                    from studenttab10k
+                    order by age;", 
+        },{ 
+          'num' => 2,
+          'sql' => "select `n.*` 
+         	from studenttab10k
+                order by name;",	
+          'verify_sql' => "select name
+                    from studenttab10k
+                    order by name;", 
+        },{ 
+          'num' => 3,
+          'sql' => "select `(n|a)+.+`
+                from studenttab10k
+                order by name;",        
+          'verify_sql' => "select name, age
+                    from studenttab10k
+                    order by name;", 
+        },{
+          'num' => 4,
+          'sql' => "select `[l-o]+.+`
+                from studenttab10k
+                order by name;",        
+          'verify_sql' => "select name
+                    from studenttab10k
+                    order by name;", 
+        },{
+          'num' => 5,
+          'sql' => "select `(n|a)?.+e`
+                from studenttab10k
+                order by name;",        
+          'verify_sql' => "select name,age
+                    from studenttab10k
+                    order by name;", 
+      }
+    ]
+ } 
+      # Need to test multiple insert  - Need harness enhancements
+      # Need to test insert into directory - Need harness enhancements
+      # Need to test casts
+      # Need to test all built in expressions and UDF (see https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF)
+      # Need to test xpath functionality
+      # Need to test regular expression based projection
+      # Need to test semi joins - Mysql doesn't support, how do I express semi-join?
+      # Need to test map side group by
+      # Need to test limit
+      # Need to test sort by
+      # Need to test distribute by
+      # Need to test cluster by
+      # Need to test transforms
+      # Need to test lateral transforms
+      # Need to test subqueries
+  ],
+},
+;
+
+
+
diff --git a/src/e2e/tools/generate/generate_data.pl b/src/e2e/tools/generate/generate_data.pl
new file mode 100644
index 0000000..61a8ce8
--- /dev/null
+++ b/src/e2e/tools/generate/generate_data.pl
@@ -0,0 +1,582 @@
+#!/usr/bin/env perl
+############################################################################
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+# A utility to generate test data for hive test harness tests.
+# 
+#
+
+use strict;
+use charnames ();
+use Cwd;
+
+our @firstName = ("alice", "bob", "calvin", "david", "ethan", "fred",
+    "gabriella", "holly", "irene", "jessica", "katie", "luke", "mike", "nick",
+    "oscar", "priscilla", "quinn", "rachel", "sarah", "tom", "ulysses", "victor",
+    "wendy", "xavier", "yuri", "zach");
+
+our @lastName = ("allen", "brown", "carson", "davidson", "ellison", "falkner",
+    "garcia", "hernandez", "ichabod", "johnson", "king", "laertes", "miller",
+    "nixon", "ovid", "polk", "quirinius", "robinson", "steinbeck", "thompson",
+    "underhill", "van buren", "white", "xylophone", "young", "zipper");
+
+sub randomName()
+{
+    return sprintf("%s %s", $firstName[int(rand(26))],
+        $lastName[int(rand(26))]);
+}
+
+our @city = ("albuquerque", "bombay", "calcutta", "danville", "eugene",
+    "frankfurt", "grenoble", "harrisburg", "indianapolis",
+    "jerusalem", "kellogg", "lisbon", "marseilles",
+    "nice", "oklohoma city", "paris", "queensville", "roswell",
+    "san francisco", "twin falls", "umatilla", "vancouver", "wheaton",
+    "xacky", "youngs town", "zippy");
+
+sub randomCity()
+{
+    return $city[int(rand(26))];
+}
+
+our @state = ( "AL", "AK", "AS", "AZ", "AR", "CA", "CO", "CT", "DE", "DC", 
+    "FL", "GA", "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD",
+    "MA", "MI", "MN", "MS", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC",
+    "ND", "OH", "OK", "OR", "RI", "SC", "SD", "TN", "TX", "UT", "VT", "VA",
+    "WA", "WV", "WI", "WY");
+
+sub randomState()
+{
+    return $state[int(rand(50))];
+}
+
+our @classname = ("american history", "biology", "chemistry", "debate",
+    "education", "forestry", "geology", "history", "industrial engineering",
+    "joggying", "kindergarten", "linguistics", "mathematics", "nap time",
+    "opthamology", "philosophy", "quiet hour", "religion", "study skills",
+    "topology", "undecided", "values clariffication", "wind surfing", 
+    "xylophone band", "yard duty", "zync studies");
+
+sub randomClass()
+{
+    return $classname[int(rand(26))];
+}
+
+our @grade = ("A", "A-", "B+", "B", "B-", "C+", "C", "C-", "D+", "D", "D-",
+    "F");
+
+sub randomGrade()
+{
+    return $grade[int(rand(int(@grade)))];
+}
+
+our @registration = ("democrat", "green", "independent", "libertarian",
+    "republican", "socialist");
+
+sub randomRegistration()
+{
+    return $registration[int(rand(int(@registration)))];
+}
+
+sub randomAge()
+{
+    return (int(rand(60)) + 18);
+}
+
+sub randomGpa()
+{
+    return rand(4.0);
+}
+
+our @street = ("A", "B", "C", "D", "E", "F", "G", "H", "I",
+    "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S",
+    "T", "U", "V", "W", "X", "Y", "Z");
+
+sub randomStreet()
+{
+    return sprintf("%d %s st", int(rand(1000)), $street[int(rand(26))]);
+}
+
+sub randomZip()
+{
+    return int(rand(100000));
+}
+
+sub randomContribution()
+{
+    return sprintf("%.2f", rand(1000));
+}
+
+our @numLetter = ("1", "09", "09a");
+
+sub randomNumLetter()
+{
+    return $numLetter[int(rand(int(@numLetter)))];
+}
+
+our @greekLetter = ( "alpha", "beta", "gamma", "delta", "epsilon", "zeta",
+    "eta", "theta", "iota", "kappa", "lambda", "mu", "nu", "xi", "omicron",
+    "pi", "rho", "sigma", "tau", "upsilon", "chi", "phi", "psi", "omega" );
+
+sub randomGreekLetter()
+{
+    return $greekLetter[int(rand(int(@greekLetter)))];
+}
+
+sub randomNameAgeGpaMap()
+{
+    my $size = int(rand(3));
+    my @mapValues = ( "name#" . randomName(), "age#" . randomAge(), "gpa#" . randomGpa() );
+    $size = ($size == 0 ? 1 : $size);
+    my $map;
+    for(my $i = 0; $i <= $size; $i++) {
+        $map .= $mapValues[$i];
+        if($i != $size) {
+            $map .= ",";
+        }
+    }
+    return $map;
+}
+
+sub getMapFields($) {
+    my $mapString = shift;
+    # remove the enclosing square brackets
+    $mapString =~ s/[\[\]]//g;
+    # get individual map fields
+    my @fields = split(/,/, $mapString);
+    # get only the values 
+    my $hash;
+    for my $field (@fields) {
+        if($field =~ /(\S+)#(.*)/) {
+            $hash->{$1} = $2;
+        }
+    }
+    return $hash;
+}
+
+sub randomNameAgeGpaTuple()
+{
+    my $gpa = sprintf("%0.2f", randomGpa());
+    return randomName() . "," . randomAge() . "," . $gpa ;
+}
+
+sub randomList()
+{
+    my $size = int(rand(int(3))) + 1;
+    my $bag;
+    for(my $i = 0; $i <= $size; $i++) {
+        $bag .= randomAge();
+        $bag .= "," if ($i != $size);
+    }
+    return $bag;
+}
+
+sub randomEscape()
+{
+    my $r = rand(1);
+    if ($r < 0.16) {
+        return '\"';
+    } elsif ($r < 0.32) {
+        return '\\\\';
+    } elsif ($r < 0.48) {
+        return '\/';
+    } elsif ($r < 0.64) {
+        return '\n';
+    } elsif ($r < 0.80) {
+        return '\t';
+    } else {
+        return randomUnicodeHex();
+    }
+}
+
+
+sub randomJsonString()
+{
+    my $r = rand(1);
+    if ($r < 0.05) {
+        return "null";
+    } elsif ($r < 0.10) {
+        return '"' . randomName() . randomEscape() . randomName() . '"';
+    } else {
+        return '"' . randomName() . '"';
+    }
+}
+
+sub randomNullBoolean()
+{
+    my $r = rand(1);
+    if ($r < 0.05) {
+        return 'null';
+    } elsif ($r < 0.525) {
+        return 'true';
+    } else {
+        return 'false';
+    }
+}
+
+sub randomJsonMap()
+{
+    if (rand(1) < 0.05) {
+        return 'null';
+    }
+
+    my $str = "[";
+    my $num = rand(5) + 1;
+    for (my $i = 0; $i < $num; $i++) {
+        $str .= "," unless $i == 0;
+        $str .= '"' . randomCity() . '" : "' . randomName() . '"';
+    }
+    $str .= "]";
+}
+
+sub randomJsonBag()
+{
+    if (rand(1) < 0.05) {
+        return 'null';
+    }
+
+    my $str = "[";
+    my $num = rand(5) + 1;
+    for (my $i = 0; $i < $num; $i++) {
+        $str .= "," unless $i == 0;
+        $str .= '{"a":' . int(rand(2**32) - rand(2**31)) . ' "b":' .
+            randomJsonString() . '}';
+    }
+    $str .= "]";
+}
+
+sub usage()
+{
+    warn "Usage: $0 filetype numrows tablename hdfstargetdir\n";
+    warn "\tValid filetypes [studenttab, studentparttab, \n";
+    warn "\t\tstudentnull, allscalars, studentcomplextab, \n";
+    warn "\t\tvoternulltab votertab, unicode, json]\n";
+    warn "hdfstargetdir is the directory in hdfs that data will be copied to for loading into tables\n";
+}
+
+our @greekUnicode = ("\N{U+03b1}", "\N{U+03b2}", "\N{U+03b3}", "\N{U+03b4}",
+    "\N{U+03b5}", "\N{U+03b6}", "\N{U+03b7}", "\N{U+03b8}", "\N{U+03b9}",
+    "\N{U+03ba}", "\N{U+03bb}", "\N{U+03bc}", "\N{U+03bd}", "\N{U+03be}",
+    "\N{U+03bf}", "\N{U+03c0}", "\N{U+03c1}", "\N{U+03c2}", "\N{U+03c3}",
+    "\N{U+03c4}", "\N{U+03c5}", "\N{U+03c6}", "\N{U+03c7}", "\N{U+03c8}",
+    "\N{U+03c9}");
+
+sub randomUnicodeNonAscii()
+{
+    my $name = $firstName[int(rand(int(@firstName)))] .
+         $greekUnicode[int(rand(int(@greekUnicode)))];
+    return $name;
+}
+
+sub randomUnicodeHex()
+{
+    return sprintf "\\u%04x", 0x3b1 + int(rand(25));
+}
+
+my $testvar = "\N{U+03b1}\N{U+03b3}\N{U+03b1}\N{U+03c0}\N{U+03b7}";
+
+sub getBulkCopyCmd($$;$)
+{
+    my ($tableName, $delimeter, $filename) = @_;
+
+    $filename = $tableName if (!defined($filename));
+        
+    return "load data local infile '" . cwd . "/$filename'
+            into table $tableName
+            columns terminated by '$delimeter';" 
+}
+
+
+# main
+{
+    # explicitly call srand so we get the same data every time
+    # we generate it.  However, we set it individually for each table type.
+    # Otherwise we'd be generating the same data sets regardless of size,
+    # and this would really skew our joins.
+
+    my $filetype = shift;
+    my $numRows = shift;
+    my $tableName = shift;
+    my $hdfsTargetDir= shift;
+
+    die usage() if (!defined($filetype) || !defined($numRows) || !defined($tableName) || !defined($hdfsTargetDir));
+
+    if ($numRows <= 0) { usage(); }
+
+    open(HDFS, "> $tableName") or die("Cannot open file $tableName, $!\n");
+    open(MYSQL, "> $tableName.mysql.sql") or die("Cannot open file $tableName.mysql.sql, $!\n");
+    open(HIVE, "> $tableName.hive.sql") or die("Cannot open file $tableName.hive.sql, $!\n");
+
+    if ($filetype eq "studenttab") {
+        srand(3.14159 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (name varchar(100), age integer, gpa float(3));\n";
+        print MYSQL &getBulkCopyCmd($tableName, "\t");
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            name string,
+            age int,
+            gpa double)
+        row format delimited
+        fields terminated by '\\t'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            my $name = randomName();
+            my $age = randomAge();
+            my $gpa = randomGpa();
+            printf HDFS "%s\t%d\t%.2f\n", $name, $age, $gpa;
+        }
+
+    } elsif ($filetype eq "studentparttab") {
+        srand(3.14159 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (name varchar(100), age integer, gpa float(3), ds char(8));\n";
+        print MYSQL &getBulkCopyCmd($tableName, "\t", "$tableName.mysql");
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            name string,
+            age int,
+            gpa double)
+        partitioned by (ds string)
+        row format delimited
+        fields terminated by '\\t'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';
+        alter table $tableName add partition (ds='20110924') location '$hdfsTargetDir/$tableName/$tableName.20110924';
+        alter table $tableName add partition (ds='20110925') location '$hdfsTargetDir/$tableName/$tableName.20110925';
+        alter table $tableName add partition (ds='20110926') location '$hdfsTargetDir/$tableName/$tableName.20110926';
+        ";
+        open(MYSQLDATA, "> $tableName.mysql") or die("Cannot open file $tableName.mysql, $!\n");
+        for (my $ds = 20110924; $ds < 20110927; $ds++) {
+            close(HDFS);
+            open(HDFS, "> $tableName.$ds") or die("Cannot open file $tableName.$ds, $!\n");
+            for (my $i = 0; $i < $numRows; $i++) {
+                my $name = randomName();
+                my $age = randomAge();
+                my $gpa = randomGpa();
+                printf HDFS "%s\t%d\t%.2f\n", $name, $age, $gpa;
+                printf MYSQLDATA "%s\t%d\t%.3f\t%d\n", $name, $age, $gpa, $ds;
+            }
+        }
+        close(MYSQLDATA);
+
+    } elsif ($filetype eq "studentnull") {
+        srand(3.14159 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (name varchar(100), age integer, gpa float(3));\n";
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            name string,
+            age int,
+            gpa double)
+        row format delimited
+        fields terminated by '\\001'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            # generate nulls in a random fashion
+            my $name = rand(1) < 0.05 ? '' : randomName();
+            my $age = rand(1) < 0.05 ? '' : randomAge();
+            my $gpa = rand(1) < 0.05 ? '' : randomGpa();
+            printf MYSQL "insert into $tableName (name, age, gpa) values(";
+            print MYSQL ($name eq ''? "null, " : "'$name', "), ($age eq ''? "null, " : "$age, ");
+            if($gpa eq '') {
+                print MYSQL "null);\n"
+            } else {
+                printf MYSQL "%.2f);\n", $gpa;    
+            }
+            print HDFS "$name$age";
+            if($gpa eq '') {
+                print HDFS "\n"
+            } else {
+                printf HDFS "%.2f\n", $gpa;    
+            }
+            
+        }
+        print MYSQL "commit;\n";
+
+    } elsif ($filetype eq "allscalars") {
+        srand(2.718281828459 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (t tinyint, si smallint, i int, b
+            bigint, bool boolean, f float, d double, s varchar(25));\n";
+        print MYSQL &getBulkCopyCmd($tableName, ':');
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            t tinyint,
+            si smallint,
+            i int,
+            b bigint,
+            bool boolean,
+            f float,
+            d double,
+            s string)
+        row format delimited
+        fields terminated by ':'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            printf HDFS "%d:%d:%d:%ld:%s:%.2f:%.2f:%s\n",
+                (int(rand(2**8) - 2**7)),
+                (int(rand(2**16) - 2**15)),
+                (int(rand(2**32) - 2**31)),
+                (int(rand(2**64) - 2**61)),
+                rand() >= 0.5 ? "true" : "false",
+                rand(100000.0) - 50000.0,
+                rand(10000000.0) - 5000000.0,
+                randomName();
+        }
+    } elsif ($filetype eq "studentcomplextab") {
+        srand(3.14159 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (nameagegpamap varchar(500), nameagegpatuple varchar(500), nameagegpabag varchar(500), nameagegpamap_name varchar(500), nameagegpamap_age integer, nameagegpamap_gpa float(3));\n";
+        print MYSQL "begin transaction;\n";
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            nameagegpamap map<string, string>,
+            struct <name: string, age: int, gpa: float>,
+            array <int>)
+        row format delimited
+        fields terminated by '\\t'
+        collection items terminated by ','
+        map keys terminated by '#'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            # generate nulls in a random fashion
+            my $map = rand(1) < 0.05 ? '' : randomNameAgeGpaMap();
+            my $tuple = rand(1) < 0.05 ? '' : randomNameAgeGpaTuple();
+            my $bag = rand(1) < 0.05 ? '' : randomList();
+            printf MYSQL "insert into $tableName (nameagegpamap, nameagegpatuple, nameagegpabag, nameagegpamap_name, nameagegpamap_age, nameagegpamap_gpa) values(";
+            my $mapHash;
+            if($map ne '') {
+                $mapHash = getMapFields($map);
+            }
+
+            print MYSQL ($map eq ''? "null, " : "'$map', "), 
+                        ($tuple eq ''? "null, " : "'$tuple', "),
+                        ($bag eq '' ? "null, " : "'$bag', "),
+                        ($map eq '' ? "null, " : (exists($mapHash->{'name'}) ? "'".$mapHash->{'name'}."', " : "null, ")),
+                        ($map eq '' ? "null, " : (exists($mapHash->{'age'}) ? "'".$mapHash->{'age'}."', " : "null, ")),
+                        ($map eq '' ? "null);\n" : (exists($mapHash->{'gpa'}) ? "'".$mapHash->{'gpa'}."');\n" : "null);\n"));
+            print HDFS "$map\t$tuple\t$bag\n";
+        }
+        print MYSQL "commit;\n";
+
+    } elsif ($filetype eq "votertab") {
+        srand(299792458 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (name varchar(100), age integer, registration varchar(20), contributions float);\n";
+        print MYSQL &getBulkCopyCmd($tableName, "\t");
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            name string,
+            age int,
+            registration string,
+            contributions float)
+        row format delimited
+        fields terminated by '\\t'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+for (my $i = 0; $i < $numRows; $i++) {
+            my $name = randomName();
+            my $age = randomAge();
+            my $registration = randomRegistration();
+            my $contribution = randomContribution();
+            printf HDFS "%s\t%d\t%s\t%.2f\n", $name, $age,
+                $registration, $contribution;
+        }
+
+    } elsif ($filetype eq "voternulltab") {
+        srand(299792458 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (name varchar(100), age integer, registration varchar(20), contributions float);\n";
+        print MYSQL "begin transaction;\n";
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            name string,
+            age int,
+            registration string,
+            contributions float)
+        row format delimited
+        fields terminated by '\\t'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            # generate nulls in a random fashion
+            my $name = rand(1) < 0.05 ? '' : randomName();
+            my $age = rand(1) < 0.05 ? '' : randomAge();
+            my $registration = rand(1) < 0.05 ? '' : randomRegistration();
+            my $contribution = rand(1) < 0.05 ? '' : randomContribution();
+            printf MYSQL "insert into $tableName (name, age, registration, contributions) values(";
+            print MYSQL ($name eq ''? "null, " : "'$name', "), 
+                            ($age eq ''? "null, " : "$age, "),
+                            ($registration eq ''? "null, " : "'$registration', ");
+            if($contribution eq '') {
+                print MYSQL "null);\n"
+            } else {
+                printf MYSQL "%.2f);\n", $contribution;    
+            }
+            print HDFS "$name\t$age\t$registration\t";
+            if($contribution eq '') {
+                print HDFS "\n"
+            } else {
+                printf HDFS "%.2f\n", $contribution;    
+            }
+        }
+        print MYSQL "commit;\n";
+
+    } elsif ($filetype eq "unicode") {
+        srand(1.41421 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (name varchar(255));\n";
+        print MYSQL "begin transaction;\n";
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            name string)
+        row format delimited
+        fields terminated by '\\t'
+        stored as textfile
+        location '$hdfsTargetDir/$tableName';\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            my $name = randomUnicodeNonAscii(); 
+            printf MYSQL "insert into $tableName (name) values('%s');\n", $name;
+            printf HDFS "%s\n", $name;
+        }
+        print MYSQL "commit;\n";
+    } elsif ($filetype eq "json") {
+        srand(6.0221415 + $numRows);
+        print MYSQL "create table IF NOT EXISTS $tableName (s varchar(200),
+              i int, d double, b boolean, m varchar(2048), 
+              bb varchar(2048));\n";
+        print MYSQL "begin transaction;\n";
+        print HIVE "create external table IF NOT EXISTS $tableName(
+            s string,
+            i int,
+            d double,
+            b boolean,
+            m map<string, string>,
+            bb array<struct<a: int, b: string>>)
+        stored as textfile
+        location '$hdfsTargetDir/$tableName'
+        TBLPROPERTIES (
+            'hcat.isd'='org.apache.hcatalog.json.JsonInputDriver',
+            'hcat.osd'='org.apache.hcatalog.json.JsonOutputDriver'
+        );\n";
+        for (my $i = 0; $i < $numRows; $i++) {
+            my $s = randomJsonString();
+            my $i = rand(1) < 0.05 ? 'null' : (int(rand(2**32) - 2**31)),
+            my $d = rand(1) < 0.05 ? 'null' : (rand(2**10) - 2**9),
+            my $b = randomNullBoolean();
+            my $m = randomJsonMap();
+            my $bb = randomJsonBag();
+
+#           printf MYSQL "insert into $tableName (name) values('%s');\n", $name;
+            print HDFS qq@{"s":$s, "i":$i, "d":$d, "b":$b, "m":$m, "bb":$bb}\n@
+        }
+        print MYSQL "commit;\n";
+
+    } else {
+        warn "Unknown filetype $filetype\n";
+        usage();
+    }
+}
+
+
diff --git a/src/e2e/tools/test/floatpostprocessor.pl b/src/e2e/tools/test/floatpostprocessor.pl
new file mode 100644
index 0000000..8c129cf
--- /dev/null
+++ b/src/e2e/tools/test/floatpostprocessor.pl
@@ -0,0 +1,111 @@
+#!/usr/bin/env perl
+
+############################################################################           
+#  Licensed to the Apache Software Foundation (ASF) under one or more                  
+#  contributor license agreements.  See the NOTICE file distributed with               
+#  this work for additional information regarding copyright ownership.                 
+#  The ASF licenses this file to You under the Apache License, Version 2.0             
+#  (the "License"); you may not use this file except in compliance with                
+#  the License.  You may obtain a copy of the License at                               
+#                                                                                      
+#      http://www.apache.org/licenses/LICENSE-2.0                                      
+#                                                                                      
+#  Unless required by applicable law or agreed to in writing, software                 
+#  distributed under the License is distributed on an "AS IS" BASIS,                   
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.            
+#  See the License for the specific language governing permissions and                 
+#  limitations under the License.                                                      
+                                                                                       
+#
+# A simple tool to make sure all floats in the output are written the same way.
+# It is assumed that the data in question is being read from stdin.
+#
+#
+
+use strict;
+
+our @floats;
+our $delim;
+
+sub parseLine($)
+{
+	my $line = shift;
+	chomp $line;
+	return split(/$delim/, $line);
+}
+
+sub postprocess($)
+{
+	my @fields = parseLine(shift);
+
+	for (my $i = 0; $i < @fields; $i++) {
+		if ($i != 0) { print($delim); }
+		if ($floats[$i]) {
+			printf("%.2f", $fields[$i]);
+		} else {
+			print($fields[$i]);
+		}
+	}
+	print "\n";
+}
+
+sub is_float {
+	my $n = shift;
+	if(!defined $n || $n eq ""){
+		return 0;
+	}
+	if($n =~ /^[+-]?\d+\.\d+([eE][-+]?[0-9]+)?$/){
+		return 1;
+	}
+
+	my $abs = abs($n);
+	if ($abs - int($abs) > 0) {
+		return 1;
+	}
+	return 0;
+}
+
+
+# main
+{
+	$delim = shift;
+	if (!defined($delim)) {
+		die "Usage: $0 delimiter\n";
+	}
+
+	my @sampled;
+    my $line;
+    # read away any empty lines into the sample
+    do {
+	    $line = <STDIN>;
+	    push(@sampled, $line);
+    } while($line && $line =~ /^\s*$/);
+	# Sample the next thousand lines to figure out which columns have floats.
+	for (my $i = 0; $i < 1000 && ($line = <STDIN>); $i++) {
+		push(@sampled, $line);
+	}
+    foreach my $line (@sampled) {
+		my @fields = parseLine($line);
+		for (my $j = 0; $j < @fields; $j++) {
+			if(is_float($fields[$j])){
+				$floats[$j] = 1;				
+			}
+
+
+		}
+    }
+
+	# Now, play each of the sampled lines through the postprocessor
+	foreach my $line (@sampled) {
+		postprocess($line);
+	}
+
+	while (<STDIN>) {
+		postprocess($_);
+	}
+
+}
+
+
+
+	
-- 
1.7.0.4

